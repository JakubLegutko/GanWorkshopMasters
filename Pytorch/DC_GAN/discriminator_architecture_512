digraph {
	graph [size="20.849999999999998,20.849999999999998"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1463365866656 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	1460098692144 [label=SigmoidBackward0]
	1460098692432 -> 1460098692144
	1460098692432 [label=AddmmBackward0]
	1460823155952 -> 1460098692432
	1463365933952 [label="model.18.bias
 (1)" fillcolor=lightblue]
	1463365933952 -> 1460823155952
	1460823155952 [label=AccumulateGrad]
	1460823155088 -> 1460098692432
	1460823155088 [label=ViewBackward0]
	1460823154848 -> 1460823155088
	1460823154848 [label=LeakyReluBackward1]
	1460823154800 -> 1460823154848
	1460823154800 [label=CudnnBatchNormBackward0]
	1463360313952 -> 1460823154800
	1463360313952 [label=ConvolutionBackward0]
	1459364936912 -> 1463360313952
	1459364936912 [label=LeakyReluBackward1]
	1460823182688 -> 1459364936912
	1460823182688 [label=CudnnBatchNormBackward0]
	1460823180672 -> 1460823182688
	1460823180672 [label=ConvolutionBackward0]
	1460823182640 -> 1460823180672
	1460823182640 [label=LeakyReluBackward1]
	1460823180240 -> 1460823182640
	1460823180240 [label=CudnnBatchNormBackward0]
	1459365821360 -> 1460823180240
	1459365821360 [label=ConvolutionBackward0]
	1459365822368 -> 1459365821360
	1459365822368 [label=LeakyReluBackward1]
	1459365822224 -> 1459365822368
	1459365822224 [label=CudnnBatchNormBackward0]
	1460281391568 -> 1459365822224
	1460281391568 [label=ConvolutionBackward0]
	1460281390560 -> 1460281391568
	1460281390560 [label=LeakyReluBackward1]
	1460281390704 -> 1460281390560
	1460281390704 [label=CudnnBatchNormBackward0]
	1459365492288 -> 1460281390704
	1459365492288 [label=ConvolutionBackward0]
	1459365494016 -> 1459365492288
	1459365494016 [label=LeakyReluBackward1]
	1459365493920 -> 1459365494016
	1459365493920 [label=ConvolutionBackward0]
	1459365493056 -> 1459365493920
	1463366016912 [label="model.0.weight
 (64, 3, 4, 4)" fillcolor=lightblue]
	1463366016912 -> 1459365493056
	1459365493056 [label=AccumulateGrad]
	1459365493248 -> 1459365493920
	1463365967200 [label="model.0.bias
 (64)" fillcolor=lightblue]
	1463365967200 -> 1459365493248
	1459365493248 [label=AccumulateGrad]
	1459365491616 -> 1459365492288
	1463365965760 [label="model.2.weight
 (128, 64, 4, 4)" fillcolor=lightblue]
	1463365965760 -> 1459365491616
	1459365491616 [label=AccumulateGrad]
	1459365493632 -> 1459365492288
	1463365967120 [label="model.2.bias
 (128)" fillcolor=lightblue]
	1463365967120 -> 1459365493632
	1459365493632 [label=AccumulateGrad]
	1459365492528 -> 1460281390704
	1463365965520 [label="model.3.weight
 (128)" fillcolor=lightblue]
	1463365965520 -> 1459365492528
	1459365492528 [label=AccumulateGrad]
	1459365491136 -> 1460281390704
	1463365964720 [label="model.3.bias
 (128)" fillcolor=lightblue]
	1463365964720 -> 1459365491136
	1459365491136 [label=AccumulateGrad]
	1460281391760 -> 1460281391568
	1463365967440 [label="model.5.weight
 (256, 128, 4, 4)" fillcolor=lightblue]
	1463365967440 -> 1460281391760
	1460281391760 [label=AccumulateGrad]
	1460281391232 -> 1460281391568
	1463365966880 [label="model.5.bias
 (256)" fillcolor=lightblue]
	1463365966880 -> 1460281391232
	1460281391232 [label=AccumulateGrad]
	1460281392480 -> 1459365822224
	1463365967360 [label="model.6.weight
 (256)" fillcolor=lightblue]
	1463365967360 -> 1460281392480
	1460281392480 [label=AccumulateGrad]
	1460281392960 -> 1459365822224
	1463365965040 [label="model.6.bias
 (256)" fillcolor=lightblue]
	1463365965040 -> 1460281392960
	1460281392960 [label=AccumulateGrad]
	1459365822416 -> 1459365821360
	1463365966560 [label="model.8.weight
 (512, 256, 4, 4)" fillcolor=lightblue]
	1463365966560 -> 1459365822416
	1459365822416 [label=AccumulateGrad]
	1459365821936 -> 1459365821360
	1463365966960 [label="model.8.bias
 (512)" fillcolor=lightblue]
	1463365966960 -> 1459365821936
	1459365821936 [label=AccumulateGrad]
	1459365822176 -> 1460823180240
	1463365967680 [label="model.9.weight
 (512)" fillcolor=lightblue]
	1463365967680 -> 1459365822176
	1459365822176 [label=AccumulateGrad]
	1459365822080 -> 1460823180240
	1463365967600 [label="model.9.bias
 (512)" fillcolor=lightblue]
	1463365967600 -> 1459365822080
	1459365822080 [label=AccumulateGrad]
	1460823183168 -> 1460823180672
	1463365931312 [label="model.11.weight
 (1024, 512, 4, 4)" fillcolor=lightblue]
	1463365931312 -> 1460823183168
	1460823183168 [label=AccumulateGrad]
	1460823182736 -> 1460823180672
	1463365932512 [label="model.11.bias
 (1024)" fillcolor=lightblue]
	1463365932512 -> 1460823182736
	1460823182736 [label=AccumulateGrad]
	1460823182928 -> 1460823182688
	1463365934832 [label="model.12.weight
 (1024)" fillcolor=lightblue]
	1463365934832 -> 1460823182928
	1460823182928 [label=AccumulateGrad]
	1460823183216 -> 1460823182688
	1463365933552 [label="model.12.bias
 (1024)" fillcolor=lightblue]
	1463365933552 -> 1460823183216
	1460823183216 [label=AccumulateGrad]
	1460823183024 -> 1463360313952
	1463365932592 [label="model.14.weight
 (2048, 1024, 4, 4)" fillcolor=lightblue]
	1463365932592 -> 1460823183024
	1460823183024 [label=AccumulateGrad]
	1460823182880 -> 1463360313952
	1463365934992 [label="model.14.bias
 (2048)" fillcolor=lightblue]
	1463365934992 -> 1460823182880
	1460823182880 [label=AccumulateGrad]
	1460823156288 -> 1460823154800
	1463365933472 [label="model.15.weight
 (2048)" fillcolor=lightblue]
	1463365933472 -> 1460823156288
	1460823156288 [label=AccumulateGrad]
	1459364937680 -> 1460823154800
	1463365931552 [label="model.15.bias
 (2048)" fillcolor=lightblue]
	1463365931552 -> 1459364937680
	1459364937680 [label=AccumulateGrad]
	1460823154992 -> 1460098692432
	1460823154992 [label=TBackward0]
	1459364935184 -> 1460823154992
	1463365933072 [label="model.18.weight
 (1, 131072)" fillcolor=lightblue]
	1463365933072 -> 1459364935184
	1459364935184 [label=AccumulateGrad]
	1460098692144 -> 1463365866656
}
