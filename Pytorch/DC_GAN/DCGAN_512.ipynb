{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 0/512] [D loss: 0.6856919527053833] [G loss: 27.00840950012207]\n",
      "[Epoch 0/100] [Batch 1/512] [D loss: 0.007181746885180473] [G loss: 20.93548583984375]\n",
      "[Epoch 0/100] [Batch 2/512] [D loss: 0.00010157356882700697] [G loss: 20.059616088867188]\n",
      "[Epoch 0/100] [Batch 3/512] [D loss: 0.00015276079648174345] [G loss: 17.40479850769043]\n",
      "[Epoch 0/100] [Batch 4/512] [D loss: 2.7923491870751604e-05] [G loss: 12.769508361816406]\n",
      "[Epoch 0/100] [Batch 5/512] [D loss: 0.009468231350183487] [G loss: 24.167055130004883]\n",
      "[Epoch 0/100] [Batch 6/512] [D loss: 0.0035445382818579674] [G loss: 25.056812286376953]\n",
      "[Epoch 0/100] [Batch 7/512] [D loss: 0.0013334851246327162] [G loss: 23.70978355407715]\n",
      "[Epoch 0/100] [Batch 8/512] [D loss: 0.0004327901697251946] [G loss: 22.12247085571289]\n",
      "[Epoch 0/100] [Batch 9/512] [D loss: 6.069765004212968e-05] [G loss: 17.920753479003906]\n",
      "[Epoch 0/100] [Batch 10/512] [D loss: 8.827311103232205e-05] [G loss: 12.435054779052734]\n",
      "[Epoch 0/100] [Batch 11/512] [D loss: 0.02610871195793152] [G loss: 29.60030746459961]\n",
      "[Epoch 0/100] [Batch 12/512] [D loss: 1.449549674987793] [G loss: 2.980232949312267e-08]\n",
      "[Epoch 0/100] [Batch 13/512] [D loss: 42.06360626220703] [G loss: 0.14644590020179749]\n",
      "[Epoch 0/100] [Batch 14/512] [D loss: 30.611251831054688] [G loss: 1.1496145725250244]\n",
      "[Epoch 0/100] [Batch 15/512] [D loss: 18.279129028320312] [G loss: 5.185341835021973]\n",
      "[Epoch 0/100] [Batch 16/512] [D loss: 7.849486827850342] [G loss: 18.298141479492188]\n",
      "[Epoch 0/100] [Batch 17/512] [D loss: 1.8395421504974365] [G loss: 16.068218231201172]\n",
      "[Epoch 0/100] [Batch 18/512] [D loss: 0.1572200059890747] [G loss: 22.710811614990234]\n",
      "[Epoch 0/100] [Batch 19/512] [D loss: 0.258058100938797] [G loss: 16.757511138916016]\n",
      "[Epoch 0/100] [Batch 20/512] [D loss: 0.0048920148983597755] [G loss: 15.098801612854004]\n",
      "[Epoch 0/100] [Batch 21/512] [D loss: 0.1357727348804474] [G loss: 20.557146072387695]\n",
      "[Epoch 0/100] [Batch 22/512] [D loss: 0.09164834022521973] [G loss: 32.955406188964844]\n",
      "[Epoch 0/100] [Batch 23/512] [D loss: 0.0015054072719067335] [G loss: 34.87227249145508]\n",
      "[Epoch 0/100] [Batch 24/512] [D loss: 0.002437130780890584] [G loss: 36.27851104736328]\n",
      "[Epoch 0/100] [Batch 25/512] [D loss: 0.19838421046733856] [G loss: 24.65584945678711]\n",
      "[Epoch 0/100] [Batch 26/512] [D loss: 0.00017368273984175175] [G loss: 0.6894777417182922]\n",
      "[Epoch 0/100] [Batch 27/512] [D loss: 19.490474700927734] [G loss: 36.8668212890625]\n",
      "[Epoch 0/100] [Batch 28/512] [D loss: 0.040308743715286255] [G loss: 36.29286575317383]\n",
      "[Epoch 0/100] [Batch 29/512] [D loss: 3.812068223953247] [G loss: 3.35693359375]\n",
      "[Epoch 0/100] [Batch 30/512] [D loss: 1.2453234195709229] [G loss: 17.069225311279297]\n",
      "[Epoch 0/100] [Batch 31/512] [D loss: 0.0018885767785832286] [G loss: 12.56593132019043]\n",
      "[Epoch 0/100] [Batch 32/512] [D loss: 0.0033973297104239464] [G loss: 11.220464706420898]\n",
      "[Epoch 0/100] [Batch 33/512] [D loss: 0.8568680882453918] [G loss: 27.90740203857422]\n",
      "[Epoch 0/100] [Batch 34/512] [D loss: 0.013180001638829708] [G loss: 29.31265640258789]\n",
      "[Epoch 0/100] [Batch 35/512] [D loss: 0.02689175307750702] [G loss: 27.846649169921875]\n",
      "[Epoch 0/100] [Batch 36/512] [D loss: 0.0040486655198037624] [G loss: 23.785078048706055]\n",
      "[Epoch 0/100] [Batch 37/512] [D loss: 0.6166569590568542] [G loss: 31.52418327331543]\n",
      "[Epoch 0/100] [Batch 38/512] [D loss: 0.03207064047455788] [G loss: 27.407699584960938]\n",
      "[Epoch 0/100] [Batch 39/512] [D loss: 0.09079273790121078] [G loss: 29.93299102783203]\n",
      "[Epoch 0/100] [Batch 40/512] [D loss: 0.007556748576462269] [G loss: 29.818279266357422]\n",
      "[Epoch 0/100] [Batch 41/512] [D loss: 0.22589878737926483] [G loss: 29.71241569519043]\n",
      "[Epoch 0/100] [Batch 42/512] [D loss: 0.09149789065122604] [G loss: 24.592411041259766]\n",
      "[Epoch 0/100] [Batch 43/512] [D loss: 0.242706298828125] [G loss: 29.730979919433594]\n",
      "[Epoch 0/100] [Batch 44/512] [D loss: 0.21405141055583954] [G loss: 26.489830017089844]\n",
      "[Epoch 0/100] [Batch 45/512] [D loss: 0.00022136954066809267] [G loss: 24.099498748779297]\n",
      "[Epoch 0/100] [Batch 46/512] [D loss: 0.0059599122032523155] [G loss: 22.416213989257812]\n",
      "[Epoch 0/100] [Batch 47/512] [D loss: 0.008496090769767761] [G loss: 18.680004119873047]\n",
      "[Epoch 0/100] [Batch 48/512] [D loss: 0.4942185878753662] [G loss: 32.26448059082031]\n",
      "[Epoch 0/100] [Batch 49/512] [D loss: 0.21713781356811523] [G loss: 31.506315231323242]\n",
      "[Epoch 0/100] [Batch 50/512] [D loss: 0.00458851084113121] [G loss: 30.10904312133789]\n",
      "[Epoch 0/100] [Batch 51/512] [D loss: 0.14596834778785706] [G loss: 22.805883407592773]\n",
      "[Epoch 0/100] [Batch 52/512] [D loss: 0.38307899236679077] [G loss: 38.75101852416992]\n",
      "[Epoch 0/100] [Batch 53/512] [D loss: 1.0812972784042358] [G loss: 1.7772561311721802]\n",
      "[Epoch 0/100] [Batch 54/512] [D loss: 17.658788681030273] [G loss: 3.1172759532928467]\n",
      "[Epoch 0/100] [Batch 55/512] [D loss: 1.4784424304962158] [G loss: 15.804621696472168]\n",
      "[Epoch 0/100] [Batch 56/512] [D loss: 1.01616370677948] [G loss: 11.87966537475586]\n",
      "[Epoch 0/100] [Batch 57/512] [D loss: 1.1540641784667969] [G loss: 9.31478500366211]\n",
      "[Epoch 0/100] [Batch 58/512] [D loss: 0.490154892206192] [G loss: 11.148427963256836]\n",
      "[Epoch 0/100] [Batch 59/512] [D loss: 0.770372211933136] [G loss: 9.9249267578125]\n",
      "[Epoch 0/100] [Batch 60/512] [D loss: 1.3065954446792603] [G loss: 6.388087272644043]\n",
      "[Epoch 0/100] [Batch 61/512] [D loss: 0.6978009939193726] [G loss: 16.772266387939453]\n",
      "[Epoch 0/100] [Batch 62/512] [D loss: 0.5364441871643066] [G loss: 23.45553207397461]\n",
      "[Epoch 0/100] [Batch 63/512] [D loss: 0.014082449488341808] [G loss: 23.537504196166992]\n",
      "[Epoch 0/100] [Batch 64/512] [D loss: 0.010724162682890892] [G loss: 26.071630477905273]\n",
      "[Epoch 0/100] [Batch 65/512] [D loss: 0.0016563197132200003] [G loss: 26.149452209472656]\n",
      "[Epoch 0/100] [Batch 66/512] [D loss: 0.8621435761451721] [G loss: 1.321556568145752]\n",
      "[Epoch 0/100] [Batch 67/512] [D loss: 4.289390563964844] [G loss: 23.6558837890625]\n",
      "[Epoch 0/100] [Batch 68/512] [D loss: 0.0395071916282177] [G loss: 22.046646118164062]\n",
      "[Epoch 0/100] [Batch 69/512] [D loss: 0.7711306214332581] [G loss: 6.185161590576172]\n",
      "[Epoch 0/100] [Batch 70/512] [D loss: 4.055271148681641] [G loss: 30.65483283996582]\n",
      "[Epoch 0/100] [Batch 71/512] [D loss: 0.8414400219917297] [G loss: 6.341113090515137]\n",
      "[Epoch 0/100] [Batch 72/512] [D loss: 0.6418219804763794] [G loss: 13.301985740661621]\n",
      "[Epoch 0/100] [Batch 73/512] [D loss: 0.04271567612886429] [G loss: 16.511646270751953]\n",
      "[Epoch 0/100] [Batch 74/512] [D loss: 0.2785288393497467] [G loss: 20.681087493896484]\n",
      "[Epoch 0/100] [Batch 75/512] [D loss: 0.8082985877990723] [G loss: 5.613953113555908]\n",
      "[Epoch 0/100] [Batch 76/512] [D loss: 1.042437195777893] [G loss: 24.716598510742188]\n",
      "[Epoch 0/100] [Batch 77/512] [D loss: 1.199534296989441] [G loss: 1.7065790891647339]\n",
      "[Epoch 0/100] [Batch 78/512] [D loss: 6.157282829284668] [G loss: 7.397544860839844]\n",
      "[Epoch 0/100] [Batch 79/512] [D loss: 0.5860298275947571] [G loss: 11.696937561035156]\n",
      "[Epoch 0/100] [Batch 80/512] [D loss: 4.463746070861816] [G loss: 3.609339714050293]\n",
      "[Epoch 0/100] [Batch 81/512] [D loss: 1.5850375890731812] [G loss: 8.599136352539062]\n",
      "[Epoch 0/100] [Batch 82/512] [D loss: 0.8510364294052124] [G loss: 6.609814167022705]\n",
      "[Epoch 0/100] [Batch 83/512] [D loss: 0.31339332461357117] [G loss: 11.243348121643066]\n",
      "[Epoch 0/100] [Batch 84/512] [D loss: 0.36763256788253784] [G loss: 6.605346202850342]\n",
      "[Epoch 0/100] [Batch 85/512] [D loss: 0.648809552192688] [G loss: 12.456899642944336]\n",
      "[Epoch 0/100] [Batch 86/512] [D loss: 0.15509355068206787] [G loss: 11.466745376586914]\n",
      "[Epoch 0/100] [Batch 87/512] [D loss: 0.073041170835495] [G loss: 15.9423828125]\n",
      "[Epoch 0/100] [Batch 88/512] [D loss: 0.24540948867797852] [G loss: 7.706635475158691]\n",
      "[Epoch 0/100] [Batch 89/512] [D loss: 0.09280332177877426] [G loss: 11.080793380737305]\n",
      "[Epoch 0/100] [Batch 90/512] [D loss: 0.5295944809913635] [G loss: 27.41844367980957]\n",
      "[Epoch 0/100] [Batch 91/512] [D loss: 0.39344415068626404] [G loss: 15.785536766052246]\n",
      "[Epoch 0/100] [Batch 92/512] [D loss: 0.12553930282592773] [G loss: 4.746501922607422]\n",
      "[Epoch 0/100] [Batch 93/512] [D loss: 0.9631885290145874] [G loss: 27.58808135986328]\n",
      "[Epoch 0/100] [Batch 94/512] [D loss: 0.3904608488082886] [G loss: 23.668384552001953]\n",
      "[Epoch 0/100] [Batch 95/512] [D loss: 0.12933863699436188] [G loss: 14.92732048034668]\n",
      "[Epoch 0/100] [Batch 96/512] [D loss: 0.10688662528991699] [G loss: 14.976691246032715]\n",
      "[Epoch 0/100] [Batch 97/512] [D loss: 0.30546101927757263] [G loss: 27.02130126953125]\n",
      "[Epoch 0/100] [Batch 98/512] [D loss: 0.1624951958656311] [G loss: 17.18243408203125]\n",
      "[Epoch 0/100] [Batch 99/512] [D loss: 0.0061256857588887215] [G loss: 9.648409843444824]\n",
      "[Epoch 0/100] [Batch 100/512] [D loss: 0.2601868808269501] [G loss: 24.85087776184082]\n",
      "[Epoch 0/100] [Batch 101/512] [D loss: 0.09382424503564835] [G loss: 11.420271873474121]\n",
      "[Epoch 0/100] [Batch 102/512] [D loss: 0.40951067209243774] [G loss: 36.866878509521484]\n",
      "[Epoch 0/100] [Batch 103/512] [D loss: 4.523223400115967] [G loss: 5.2154071283894154e-08]\n",
      "[Epoch 0/100] [Batch 104/512] [D loss: 31.06879997253418] [G loss: 0.001554892398416996]\n",
      "[Epoch 0/100] [Batch 105/512] [D loss: 25.323467254638672] [G loss: 0.705917477607727]\n",
      "[Epoch 0/100] [Batch 106/512] [D loss: 9.290750503540039] [G loss: 11.794994354248047]\n",
      "[Epoch 0/100] [Batch 107/512] [D loss: 3.618551254272461] [G loss: 9.826837539672852]\n",
      "[Epoch 0/100] [Batch 108/512] [D loss: 3.846669912338257] [G loss: 2.195603847503662]\n",
      "[Epoch 0/100] [Batch 109/512] [D loss: 1.506681203842163] [G loss: 2.036006212234497]\n",
      "[Epoch 0/100] [Batch 110/512] [D loss: 1.6171507835388184] [G loss: 4.572254180908203]\n",
      "[Epoch 0/100] [Batch 111/512] [D loss: 1.3835645914077759] [G loss: 6.75678825378418]\n",
      "[Epoch 0/100] [Batch 112/512] [D loss: 1.016033411026001] [G loss: 4.362099647521973]\n",
      "[Epoch 0/100] [Batch 113/512] [D loss: 0.9598627686500549] [G loss: 3.521226406097412]\n",
      "[Epoch 0/100] [Batch 114/512] [D loss: 1.0979337692260742] [G loss: 3.486358642578125]\n",
      "[Epoch 0/100] [Batch 115/512] [D loss: 0.4122486710548401] [G loss: 4.6607346534729]\n",
      "[Epoch 0/100] [Batch 116/512] [D loss: 4.76296329498291] [G loss: 3.072690010070801]\n",
      "[Epoch 0/100] [Batch 117/512] [D loss: 0.7305755019187927] [G loss: 6.618952751159668]\n",
      "[Epoch 0/100] [Batch 118/512] [D loss: 2.0548267364501953] [G loss: 3.0296335220336914]\n",
      "[Epoch 0/100] [Batch 119/512] [D loss: 1.7782762050628662] [G loss: 1.2561941146850586]\n",
      "[Epoch 0/100] [Batch 120/512] [D loss: 4.3616461753845215] [G loss: 3.141392230987549]\n",
      "[Epoch 0/100] [Batch 121/512] [D loss: 1.4403645992279053] [G loss: 7.046492576599121]\n",
      "[Epoch 0/100] [Batch 122/512] [D loss: 1.2436710596084595] [G loss: 1.3707869052886963]\n",
      "[Epoch 0/100] [Batch 123/512] [D loss: 0.643686056137085] [G loss: 3.6373300552368164]\n",
      "[Epoch 0/100] [Batch 124/512] [D loss: 0.35210415720939636] [G loss: 3.991617202758789]\n",
      "[Epoch 0/100] [Batch 125/512] [D loss: 0.3348616659641266] [G loss: 4.2248735427856445]\n",
      "[Epoch 0/100] [Batch 126/512] [D loss: 0.6795838475227356] [G loss: 7.106069564819336]\n",
      "[Epoch 0/100] [Batch 127/512] [D loss: 0.8735702633857727] [G loss: 1.23341965675354]\n",
      "[Epoch 0/100] [Batch 128/512] [D loss: 1.5079551935195923] [G loss: 6.7802228927612305]\n",
      "[Epoch 0/100] [Batch 129/512] [D loss: 0.2784191966056824] [G loss: 5.624134540557861]\n",
      "[Epoch 0/100] [Batch 130/512] [D loss: 0.44110816717147827] [G loss: 3.575974702835083]\n",
      "[Epoch 0/100] [Batch 131/512] [D loss: 0.3858397305011749] [G loss: 4.380537986755371]\n",
      "[Epoch 0/100] [Batch 132/512] [D loss: 0.46411532163619995] [G loss: 6.4097676277160645]\n",
      "[Epoch 0/100] [Batch 133/512] [D loss: 0.3315657377243042] [G loss: 4.920976638793945]\n",
      "[Epoch 0/100] [Batch 134/512] [D loss: 0.4162210524082184] [G loss: 3.9515838623046875]\n",
      "[Epoch 0/100] [Batch 135/512] [D loss: 0.28264474868774414] [G loss: 4.427336692810059]\n",
      "[Epoch 0/100] [Batch 136/512] [D loss: 0.17137812077999115] [G loss: 6.989169120788574]\n",
      "[Epoch 0/100] [Batch 137/512] [D loss: 0.20299503207206726] [G loss: 4.357274532318115]\n",
      "[Epoch 0/100] [Batch 138/512] [D loss: 0.17871147394180298] [G loss: 4.217674732208252]\n",
      "[Epoch 0/100] [Batch 139/512] [D loss: 0.21925586462020874] [G loss: 5.874159812927246]\n",
      "[Epoch 0/100] [Batch 140/512] [D loss: 0.16309767961502075] [G loss: 7.502103805541992]\n",
      "[Epoch 0/100] [Batch 141/512] [D loss: 0.27138715982437134] [G loss: 2.277703046798706]\n",
      "[Epoch 0/100] [Batch 142/512] [D loss: 0.21370333433151245] [G loss: 5.701491355895996]\n",
      "[Epoch 0/100] [Batch 143/512] [D loss: 0.23740726709365845] [G loss: 7.368476390838623]\n",
      "[Epoch 0/100] [Batch 144/512] [D loss: 0.3121580183506012] [G loss: 3.826089382171631]\n",
      "[Epoch 0/100] [Batch 145/512] [D loss: 0.15490281581878662] [G loss: 2.8294568061828613]\n",
      "[Epoch 0/100] [Batch 146/512] [D loss: 0.29788196086883545] [G loss: 8.115478515625]\n",
      "[Epoch 0/100] [Batch 147/512] [D loss: 0.04327314347028732] [G loss: 6.5725884437561035]\n",
      "[Epoch 0/100] [Batch 148/512] [D loss: 0.3338626027107239] [G loss: 7.720357894897461]\n",
      "[Epoch 0/100] [Batch 149/512] [D loss: 0.1103370413184166] [G loss: 1.798492431640625]\n",
      "[Epoch 0/100] [Batch 150/512] [D loss: 1.1597020626068115] [G loss: 7.4884161949157715]\n",
      "[Epoch 0/100] [Batch 151/512] [D loss: 1.5355308055877686] [G loss: 0.16114076972007751]\n",
      "[Epoch 0/100] [Batch 152/512] [D loss: 2.5073728561401367] [G loss: 5.170992374420166]\n",
      "[Epoch 0/100] [Batch 153/512] [D loss: 0.9669443964958191] [G loss: 1.2409822940826416]\n",
      "[Epoch 0/100] [Batch 154/512] [D loss: 1.0027685165405273] [G loss: 2.5072226524353027]\n",
      "[Epoch 0/100] [Batch 155/512] [D loss: 0.4291084408760071] [G loss: 3.778266668319702]\n",
      "[Epoch 0/100] [Batch 156/512] [D loss: 0.9046775102615356] [G loss: 3.318225860595703]\n",
      "[Epoch 0/100] [Batch 157/512] [D loss: 0.3527987003326416] [G loss: 3.651231288909912]\n",
      "[Epoch 0/100] [Batch 158/512] [D loss: 0.3359677195549011] [G loss: 2.7782788276672363]\n",
      "[Epoch 0/100] [Batch 159/512] [D loss: 0.152846097946167] [G loss: 3.899179220199585]\n",
      "[Epoch 0/100] [Batch 160/512] [D loss: 0.08377503603696823] [G loss: 4.138816833496094]\n",
      "[Epoch 0/100] [Batch 161/512] [D loss: 0.2660944163799286] [G loss: 3.4499974250793457]\n",
      "[Epoch 0/100] [Batch 162/512] [D loss: 0.2885890305042267] [G loss: 6.710928916931152]\n",
      "[Epoch 0/100] [Batch 163/512] [D loss: 0.4283563792705536] [G loss: 1.6476824283599854]\n",
      "[Epoch 0/100] [Batch 164/512] [D loss: 0.2635856866836548] [G loss: 5.62388801574707]\n",
      "[Epoch 0/100] [Batch 165/512] [D loss: 0.05358448624610901] [G loss: 5.710371017456055]\n",
      "[Epoch 0/100] [Batch 166/512] [D loss: 0.05458204820752144] [G loss: 5.227283477783203]\n",
      "[Epoch 0/100] [Batch 167/512] [D loss: 0.0349050797522068] [G loss: 5.49894905090332]\n",
      "[Epoch 0/100] [Batch 168/512] [D loss: 0.08152804523706436] [G loss: 4.3003716468811035]\n",
      "[Epoch 0/100] [Batch 169/512] [D loss: 0.02470937743782997] [G loss: 5.124924659729004]\n",
      "[Epoch 0/100] [Batch 170/512] [D loss: 0.11576956510543823] [G loss: 7.469691753387451]\n",
      "[Epoch 0/100] [Batch 171/512] [D loss: 0.22579067945480347] [G loss: 2.5543980598449707]\n",
      "[Epoch 0/100] [Batch 172/512] [D loss: 0.15663936734199524] [G loss: 5.796905994415283]\n",
      "[Epoch 0/100] [Batch 173/512] [D loss: 0.139507457613945] [G loss: 7.864175796508789]\n",
      "[Epoch 0/100] [Batch 174/512] [D loss: 0.10861246287822723] [G loss: 7.2418365478515625]\n",
      "[Epoch 0/100] [Batch 175/512] [D loss: 0.05212614685297012] [G loss: 5.803825378417969]\n",
      "[Epoch 0/100] [Batch 176/512] [D loss: 0.35642147064208984] [G loss: 5.8650288581848145]\n",
      "[Epoch 0/100] [Batch 177/512] [D loss: 0.07544122636318207] [G loss: 5.224398612976074]\n",
      "[Epoch 0/100] [Batch 178/512] [D loss: 0.12193967401981354] [G loss: 5.02736759185791]\n",
      "[Epoch 0/100] [Batch 179/512] [D loss: 0.1886216104030609] [G loss: 3.038771867752075]\n",
      "[Epoch 0/100] [Batch 180/512] [D loss: 0.20048142969608307] [G loss: 4.079853534698486]\n",
      "[Epoch 0/100] [Batch 181/512] [D loss: 0.3266151547431946] [G loss: 1.9642223119735718]\n",
      "[Epoch 0/100] [Batch 182/512] [D loss: 0.7208248972892761] [G loss: 12.434111595153809]\n",
      "[Epoch 0/100] [Batch 183/512] [D loss: 2.432912826538086] [G loss: 0.5183860063552856]\n",
      "[Epoch 0/100] [Batch 184/512] [D loss: 2.0194225311279297] [G loss: 7.255308628082275]\n",
      "[Epoch 0/100] [Batch 185/512] [D loss: 0.2534927427768707] [G loss: 7.536093711853027]\n",
      "[Epoch 0/100] [Batch 186/512] [D loss: 0.3954261541366577] [G loss: 3.8477840423583984]\n",
      "[Epoch 0/100] [Batch 187/512] [D loss: 0.7098779678344727] [G loss: 3.534696578979492]\n",
      "[Epoch 0/100] [Batch 188/512] [D loss: 0.4868318438529968] [G loss: 5.210942268371582]\n",
      "[Epoch 0/100] [Batch 189/512] [D loss: 0.20524442195892334] [G loss: 6.825993537902832]\n",
      "[Epoch 0/100] [Batch 190/512] [D loss: 0.14649546146392822] [G loss: 6.090445041656494]\n",
      "[Epoch 0/100] [Batch 191/512] [D loss: 0.03829227015376091] [G loss: 5.80792760848999]\n",
      "[Epoch 0/100] [Batch 192/512] [D loss: 0.11370814591646194] [G loss: 4.066075325012207]\n",
      "[Epoch 0/100] [Batch 193/512] [D loss: 0.04646127671003342] [G loss: 5.467249870300293]\n",
      "[Epoch 0/100] [Batch 194/512] [D loss: 0.3126378059387207] [G loss: 11.173891067504883]\n",
      "[Epoch 0/100] [Batch 195/512] [D loss: 1.0228877067565918] [G loss: 2.846872329711914]\n",
      "[Epoch 0/100] [Batch 196/512] [D loss: 0.6825850605964661] [G loss: 7.445202827453613]\n",
      "[Epoch 0/100] [Batch 197/512] [D loss: 0.13074982166290283] [G loss: 7.498380661010742]\n",
      "[Epoch 0/100] [Batch 198/512] [D loss: 0.06403243541717529] [G loss: 9.37636947631836]\n",
      "[Epoch 0/100] [Batch 199/512] [D loss: 0.1602320671081543] [G loss: 5.889581680297852]\n",
      "[Epoch 0/100] [Batch 200/512] [D loss: 0.15782669186592102] [G loss: 7.636082172393799]\n",
      "[Epoch 0/100] [Batch 201/512] [D loss: 0.04621691629290581] [G loss: 7.934380531311035]\n",
      "[Epoch 0/100] [Batch 202/512] [D loss: 0.028078019618988037] [G loss: 6.345210552215576]\n",
      "[Epoch 0/100] [Batch 203/512] [D loss: 0.17103326320648193] [G loss: 6.1174702644348145]\n",
      "[Epoch 0/100] [Batch 204/512] [D loss: 0.05321420729160309] [G loss: 7.741955757141113]\n",
      "[Epoch 0/100] [Batch 205/512] [D loss: 0.3844040632247925] [G loss: 6.122857093811035]\n",
      "[Epoch 0/100] [Batch 206/512] [D loss: 0.23267433047294617] [G loss: 9.925113677978516]\n",
      "[Epoch 0/100] [Batch 207/512] [D loss: 0.6524020433425903] [G loss: 0.14517053961753845]\n",
      "[Epoch 0/100] [Batch 208/512] [D loss: 2.7685205936431885] [G loss: 11.471816062927246]\n",
      "[Epoch 0/100] [Batch 209/512] [D loss: 0.8875621557235718] [G loss: 6.40736198425293]\n",
      "[Epoch 0/100] [Batch 210/512] [D loss: 0.05346017703413963] [G loss: 4.313344955444336]\n",
      "[Epoch 0/100] [Batch 211/512] [D loss: 0.6348488330841064] [G loss: 6.779305458068848]\n",
      "[Epoch 0/100] [Batch 212/512] [D loss: 0.06219111382961273] [G loss: 7.544453144073486]\n",
      "[Epoch 0/100] [Batch 213/512] [D loss: 0.3047351539134979] [G loss: 5.340502738952637]\n",
      "[Epoch 0/100] [Batch 214/512] [D loss: 0.695705771446228] [G loss: 8.492531776428223]\n",
      "[Epoch 0/100] [Batch 215/512] [D loss: 0.24487143754959106] [G loss: 3.4903194904327393]\n",
      "[Epoch 0/100] [Batch 216/512] [D loss: 0.6092960238456726] [G loss: 3.6989054679870605]\n",
      "[Epoch 0/100] [Batch 217/512] [D loss: 0.4822940230369568] [G loss: 9.689020156860352]\n",
      "[Epoch 0/100] [Batch 218/512] [D loss: 0.4842439889907837] [G loss: 1.499462366104126]\n",
      "[Epoch 0/100] [Batch 219/512] [D loss: 0.5863934755325317] [G loss: 7.242038726806641]\n",
      "[Epoch 0/100] [Batch 220/512] [D loss: 0.08178599178791046] [G loss: 7.978957176208496]\n",
      "[Epoch 0/100] [Batch 221/512] [D loss: 0.19177567958831787] [G loss: 3.1754403114318848]\n",
      "[Epoch 0/100] [Batch 222/512] [D loss: 0.08110839873552322] [G loss: 5.776366233825684]\n",
      "[Epoch 0/100] [Batch 223/512] [D loss: 0.08713576197624207] [G loss: 5.630048751831055]\n",
      "[Epoch 0/100] [Batch 224/512] [D loss: 0.18172934651374817] [G loss: 7.699577331542969]\n",
      "[Epoch 0/100] [Batch 225/512] [D loss: 0.20859499275684357] [G loss: 1.606584906578064]\n",
      "[Epoch 0/100] [Batch 226/512] [D loss: 0.43188175559043884] [G loss: 14.552665710449219]\n",
      "[Epoch 0/100] [Batch 227/512] [D loss: 2.0362799167633057] [G loss: 0.315969318151474]\n",
      "[Epoch 0/100] [Batch 228/512] [D loss: 2.8522191047668457] [G loss: 4.440487861633301]\n",
      "[Epoch 0/100] [Batch 229/512] [D loss: 0.7066925168037415] [G loss: 9.774778366088867]\n",
      "[Epoch 0/100] [Batch 230/512] [D loss: 2.633570671081543] [G loss: 3.2231321334838867]\n",
      "[Epoch 0/100] [Batch 231/512] [D loss: 0.7101912498474121] [G loss: 3.534519910812378]\n",
      "[Epoch 0/100] [Batch 232/512] [D loss: 0.4778137803077698] [G loss: 5.590757369995117]\n",
      "[Epoch 0/100] [Batch 233/512] [D loss: 0.7362082004547119] [G loss: 4.2332234382629395]\n",
      "[Epoch 0/100] [Batch 234/512] [D loss: 0.5630332231521606] [G loss: 1.7592970132827759]\n",
      "[Epoch 0/100] [Batch 235/512] [D loss: 0.6975436806678772] [G loss: 7.832403182983398]\n",
      "[Epoch 0/100] [Batch 236/512] [D loss: 1.156583309173584] [G loss: 5.643655776977539]\n",
      "[Epoch 0/100] [Batch 237/512] [D loss: 0.5173801779747009] [G loss: 2.01939058303833]\n",
      "[Epoch 0/100] [Batch 238/512] [D loss: 0.7295802235603333] [G loss: 6.56902551651001]\n",
      "[Epoch 0/100] [Batch 239/512] [D loss: 0.4400462210178375] [G loss: 4.384079933166504]\n",
      "[Epoch 0/100] [Batch 240/512] [D loss: 0.07295213639736176] [G loss: 4.613669395446777]\n",
      "[Epoch 0/100] [Batch 241/512] [D loss: 0.5546509623527527] [G loss: 3.067788600921631]\n",
      "[Epoch 0/100] [Batch 242/512] [D loss: 0.4983423948287964] [G loss: 9.794365882873535]\n",
      "[Epoch 0/100] [Batch 243/512] [D loss: 1.445554494857788] [G loss: 2.5672147274017334]\n",
      "[Epoch 0/100] [Batch 244/512] [D loss: 0.6956935524940491] [G loss: 3.0364139080047607]\n",
      "[Epoch 0/100] [Batch 245/512] [D loss: 0.419916570186615] [G loss: 7.907928466796875]\n",
      "[Epoch 0/100] [Batch 246/512] [D loss: 0.31945356726646423] [G loss: 5.00861120223999]\n",
      "[Epoch 0/100] [Batch 247/512] [D loss: 0.4115660786628723] [G loss: 1.9307832717895508]\n",
      "[Epoch 0/100] [Batch 248/512] [D loss: 0.8840591907501221] [G loss: 8.616609573364258]\n",
      "[Epoch 0/100] [Batch 249/512] [D loss: 0.6123217344284058] [G loss: 5.784390926361084]\n",
      "[Epoch 0/100] [Batch 250/512] [D loss: 1.3594974279403687] [G loss: 0.13484901189804077]\n",
      "[Epoch 0/100] [Batch 251/512] [D loss: 3.160919189453125] [G loss: 8.85525131225586]\n",
      "[Epoch 0/100] [Batch 252/512] [D loss: 0.5212575197219849] [G loss: 8.041836738586426]\n",
      "[Epoch 0/100] [Batch 253/512] [D loss: 1.6633416414260864] [G loss: 1.2317085266113281]\n",
      "[Epoch 0/100] [Batch 254/512] [D loss: 2.54433536529541] [G loss: 7.066079139709473]\n",
      "[Epoch 0/100] [Batch 255/512] [D loss: 0.349786639213562] [G loss: 6.040828704833984]\n",
      "[Epoch 0/100] [Batch 256/512] [D loss: 0.496585488319397] [G loss: 2.7861852645874023]\n",
      "[Epoch 0/100] [Batch 257/512] [D loss: 1.0207819938659668] [G loss: 2.9040493965148926]\n",
      "[Epoch 0/100] [Batch 258/512] [D loss: 0.5929288864135742] [G loss: 7.559366226196289]\n",
      "[Epoch 0/100] [Batch 259/512] [D loss: 1.205255150794983] [G loss: 3.8906242847442627]\n",
      "[Epoch 0/100] [Batch 260/512] [D loss: 0.5063221454620361] [G loss: 2.1269495487213135]\n",
      "[Epoch 0/100] [Batch 261/512] [D loss: 0.36254844069480896] [G loss: 5.52284574508667]\n",
      "[Epoch 0/100] [Batch 262/512] [D loss: 0.35779833793640137] [G loss: 4.572969436645508]\n",
      "[Epoch 0/100] [Batch 263/512] [D loss: 0.28403347730636597] [G loss: 3.883883476257324]\n",
      "[Epoch 0/100] [Batch 264/512] [D loss: 0.35393601655960083] [G loss: 3.5665574073791504]\n",
      "[Epoch 0/100] [Batch 265/512] [D loss: 0.22824442386627197] [G loss: 4.367721080780029]\n",
      "[Epoch 0/100] [Batch 266/512] [D loss: 0.21370455622673035] [G loss: 5.092443466186523]\n",
      "[Epoch 0/100] [Batch 267/512] [D loss: 0.2953844964504242] [G loss: 3.381007194519043]\n",
      "[Epoch 0/100] [Batch 268/512] [D loss: 0.12384215742349625] [G loss: 4.124129295349121]\n",
      "[Epoch 0/100] [Batch 269/512] [D loss: 0.3612615466117859] [G loss: 2.6027913093566895]\n",
      "[Epoch 0/100] [Batch 270/512] [D loss: 0.44825559854507446] [G loss: 1.653306245803833]\n",
      "[Epoch 0/100] [Batch 271/512] [D loss: 0.5922635793685913] [G loss: 4.761838436126709]\n",
      "[Epoch 0/100] [Batch 272/512] [D loss: 0.15589022636413574] [G loss: 6.632637977600098]\n",
      "[Epoch 0/100] [Batch 273/512] [D loss: 0.14567384123802185] [G loss: 5.00181770324707]\n",
      "[Epoch 0/100] [Batch 274/512] [D loss: 0.5479219555854797] [G loss: 3.6926016807556152]\n",
      "[Epoch 0/100] [Batch 275/512] [D loss: 0.5356835126876831] [G loss: 2.9729578495025635]\n",
      "[Epoch 0/100] [Batch 276/512] [D loss: 0.6167507767677307] [G loss: 1.1709156036376953]\n",
      "[Epoch 0/100] [Batch 277/512] [D loss: 1.1026049852371216] [G loss: 13.55921745300293]\n",
      "[Epoch 0/100] [Batch 278/512] [D loss: 1.5439491271972656] [G loss: 1.1983449459075928]\n",
      "[Epoch 0/100] [Batch 279/512] [D loss: 1.6541807651519775] [G loss: 10.120052337646484]\n",
      "[Epoch 0/100] [Batch 280/512] [D loss: 0.22721445560455322] [G loss: 5.632728576660156]\n",
      "[Epoch 0/100] [Batch 281/512] [D loss: 0.6066200137138367] [G loss: 0.9979060292243958]\n",
      "[Epoch 0/100] [Batch 282/512] [D loss: 1.006488561630249] [G loss: 8.200456619262695]\n",
      "[Epoch 0/100] [Batch 283/512] [D loss: 0.78988116979599] [G loss: 3.738783121109009]\n",
      "[Epoch 0/100] [Batch 284/512] [D loss: 0.2547280788421631] [G loss: 4.745147705078125]\n",
      "[Epoch 0/100] [Batch 285/512] [D loss: 0.48812225461006165] [G loss: 3.6114227771759033]\n",
      "[Epoch 0/100] [Batch 286/512] [D loss: 0.17634451389312744] [G loss: 3.57314395904541]\n",
      "[Epoch 0/100] [Batch 287/512] [D loss: 0.7186592817306519] [G loss: 2.8532586097717285]\n",
      "[Epoch 0/100] [Batch 288/512] [D loss: 0.5894904136657715] [G loss: 6.021862983703613]\n",
      "[Epoch 0/100] [Batch 289/512] [D loss: 0.3563339412212372] [G loss: 3.5017006397247314]\n",
      "[Epoch 0/100] [Batch 290/512] [D loss: 0.3786270022392273] [G loss: 6.077847480773926]\n",
      "[Epoch 0/100] [Batch 291/512] [D loss: 0.27299764752388] [G loss: 2.107909917831421]\n",
      "[Epoch 0/100] [Batch 292/512] [D loss: 0.615971565246582] [G loss: 7.39205265045166]\n",
      "[Epoch 0/100] [Batch 293/512] [D loss: 0.2662864625453949] [G loss: 4.563955307006836]\n",
      "[Epoch 0/100] [Batch 294/512] [D loss: 0.48985421657562256] [G loss: 7.5395731925964355]\n",
      "[Epoch 0/100] [Batch 295/512] [D loss: 0.21418094635009766] [G loss: 4.660123348236084]\n",
      "[Epoch 0/100] [Batch 296/512] [D loss: 0.07482513785362244] [G loss: 7.095208168029785]\n",
      "[Epoch 0/100] [Batch 297/512] [D loss: 0.12438073754310608] [G loss: 7.972055912017822]\n",
      "[Epoch 0/100] [Batch 298/512] [D loss: 0.41418421268463135] [G loss: 2.7038726806640625]\n",
      "[Epoch 0/100] [Batch 299/512] [D loss: 0.3525483310222626] [G loss: 11.64833927154541]\n",
      "[Epoch 0/100] [Batch 300/512] [D loss: 0.6980189085006714] [G loss: 1.0093309879302979]\n",
      "[Epoch 0/100] [Batch 301/512] [D loss: 1.7433735132217407] [G loss: 18.077070236206055]\n",
      "[Epoch 0/100] [Batch 302/512] [D loss: 1.8187202215194702] [G loss: 3.8225717544555664]\n",
      "[Epoch 0/100] [Batch 303/512] [D loss: 0.5950698852539062] [G loss: 10.842475891113281]\n",
      "[Epoch 0/100] [Batch 304/512] [D loss: 1.3674163818359375] [G loss: 1.9931323528289795]\n",
      "[Epoch 0/100] [Batch 305/512] [D loss: 0.9110590219497681] [G loss: 11.221711158752441]\n",
      "[Epoch 0/100] [Batch 306/512] [D loss: 1.2635364532470703] [G loss: 1.28090238571167]\n",
      "[Epoch 0/100] [Batch 307/512] [D loss: 1.256799340248108] [G loss: 9.971040725708008]\n",
      "[Epoch 0/100] [Batch 308/512] [D loss: 0.3258262574672699] [G loss: 13.727773666381836]\n",
      "[Epoch 0/100] [Batch 309/512] [D loss: 1.8095693588256836] [G loss: 4.560626983642578]\n",
      "[Epoch 0/100] [Batch 310/512] [D loss: 0.33892327547073364] [G loss: 4.178231239318848]\n",
      "[Epoch 0/100] [Batch 311/512] [D loss: 1.0691335201263428] [G loss: 5.567408561706543]\n",
      "[Epoch 0/100] [Batch 312/512] [D loss: 0.2503886818885803] [G loss: 8.342082977294922]\n",
      "[Epoch 0/100] [Batch 313/512] [D loss: 1.7222754955291748] [G loss: 0.870521068572998]\n",
      "[Epoch 0/100] [Batch 314/512] [D loss: 0.7291918396949768] [G loss: 4.041058540344238]\n",
      "[Epoch 0/100] [Batch 315/512] [D loss: 0.8235946297645569] [G loss: 9.506157875061035]\n",
      "[Epoch 0/100] [Batch 316/512] [D loss: 1.3498539924621582] [G loss: 3.0654702186584473]\n",
      "[Epoch 0/100] [Batch 317/512] [D loss: 0.825682520866394] [G loss: 3.8895621299743652]\n",
      "[Epoch 0/100] [Batch 318/512] [D loss: 0.43357160687446594] [G loss: 4.33215856552124]\n",
      "[Epoch 0/100] [Batch 319/512] [D loss: 0.4333498179912567] [G loss: 7.2333550453186035]\n",
      "[Epoch 0/100] [Batch 320/512] [D loss: 0.3157765865325928] [G loss: 4.4918928146362305]\n",
      "[Epoch 0/100] [Batch 321/512] [D loss: 0.4313212037086487] [G loss: 3.7122907638549805]\n",
      "[Epoch 0/100] [Batch 322/512] [D loss: 0.20755432546138763] [G loss: 4.158085823059082]\n",
      "[Epoch 0/100] [Batch 323/512] [D loss: 0.38691166043281555] [G loss: 6.261547088623047]\n",
      "[Epoch 0/100] [Batch 324/512] [D loss: 1.020914077758789] [G loss: 3.7179903984069824]\n",
      "[Epoch 0/100] [Batch 325/512] [D loss: 0.23894718289375305] [G loss: 3.2867743968963623]\n",
      "[Epoch 0/100] [Batch 326/512] [D loss: 0.24636980891227722] [G loss: 4.552297592163086]\n",
      "[Epoch 0/100] [Batch 327/512] [D loss: 0.31884658336639404] [G loss: 1.3491839170455933]\n",
      "[Epoch 0/100] [Batch 328/512] [D loss: 1.1143364906311035] [G loss: 20.445598602294922]\n",
      "[Epoch 0/100] [Batch 329/512] [D loss: 5.0765156745910645] [G loss: 1.7525596618652344]\n",
      "[Epoch 0/100] [Batch 330/512] [D loss: 0.4714306592941284] [G loss: 2.5488204956054688]\n",
      "[Epoch 0/100] [Batch 331/512] [D loss: 1.179308533668518] [G loss: 11.050941467285156]\n",
      "[Epoch 0/100] [Batch 332/512] [D loss: 0.7987251877784729] [G loss: 3.886662483215332]\n",
      "[Epoch 0/100] [Batch 333/512] [D loss: 0.14545361697673798] [G loss: 3.1795616149902344]\n",
      "[Epoch 0/100] [Batch 334/512] [D loss: 0.2490171194076538] [G loss: 6.343220233917236]\n",
      "[Epoch 0/100] [Batch 335/512] [D loss: 0.5675994753837585] [G loss: 1.9507731199264526]\n",
      "[Epoch 0/100] [Batch 336/512] [D loss: 0.818553626537323] [G loss: 10.205368041992188]\n",
      "[Epoch 0/100] [Batch 337/512] [D loss: 2.036644697189331] [G loss: 1.2168015241622925]\n",
      "[Epoch 0/100] [Batch 338/512] [D loss: 0.4283131957054138] [G loss: 5.895212173461914]\n",
      "[Epoch 0/100] [Batch 339/512] [D loss: 0.44622182846069336] [G loss: 5.033938884735107]\n",
      "[Epoch 0/100] [Batch 340/512] [D loss: 0.3016236424446106] [G loss: 3.8187434673309326]\n",
      "[Epoch 0/100] [Batch 341/512] [D loss: 0.28136327862739563] [G loss: 2.4949145317077637]\n",
      "[Epoch 0/100] [Batch 342/512] [D loss: 0.1493024230003357] [G loss: 5.737189292907715]\n",
      "[Epoch 0/100] [Batch 343/512] [D loss: 0.2938348650932312] [G loss: 5.715555191040039]\n",
      "[Epoch 0/100] [Batch 344/512] [D loss: 1.0029724836349487] [G loss: 0.28427278995513916]\n",
      "[Epoch 0/100] [Batch 345/512] [D loss: 1.7987550497055054] [G loss: 14.613332748413086]\n",
      "[Epoch 0/100] [Batch 346/512] [D loss: 1.924708366394043] [G loss: 1.0448412895202637]\n",
      "[Epoch 0/100] [Batch 347/512] [D loss: 0.8700903654098511] [G loss: 8.79558277130127]\n",
      "[Epoch 0/100] [Batch 348/512] [D loss: 0.32170966267585754] [G loss: 9.351303100585938]\n",
      "[Epoch 0/100] [Batch 349/512] [D loss: 0.3088907301425934] [G loss: 4.0926055908203125]\n",
      "[Epoch 0/100] [Batch 350/512] [D loss: 0.07620742917060852] [G loss: 4.110203742980957]\n",
      "[Epoch 0/100] [Batch 351/512] [D loss: 0.41100674867630005] [G loss: 10.605188369750977]\n",
      "[Epoch 0/100] [Batch 352/512] [D loss: 0.4575381875038147] [G loss: 5.857422828674316]\n",
      "[Epoch 0/100] [Batch 353/512] [D loss: 0.16584035754203796] [G loss: 2.6610331535339355]\n",
      "[Epoch 0/100] [Batch 354/512] [D loss: 1.298316240310669] [G loss: 15.19810676574707]\n",
      "[Epoch 0/100] [Batch 355/512] [D loss: 4.003290176391602] [G loss: 0.08632368594408035]\n",
      "[Epoch 0/100] [Batch 356/512] [D loss: 2.3787074089050293] [G loss: 9.042362213134766]\n",
      "[Epoch 0/100] [Batch 357/512] [D loss: 0.41541895270347595] [G loss: 3.9068572521209717]\n",
      "[Epoch 0/100] [Batch 358/512] [D loss: 0.5446360111236572] [G loss: 4.545906066894531]\n",
      "[Epoch 0/100] [Batch 359/512] [D loss: 0.6427350044250488] [G loss: 2.620332717895508]\n",
      "[Epoch 0/100] [Batch 360/512] [D loss: 1.332534909248352] [G loss: 1.556295394897461]\n",
      "[Epoch 0/100] [Batch 361/512] [D loss: 0.7494461536407471] [G loss: 4.565410614013672]\n",
      "[Epoch 0/100] [Batch 362/512] [D loss: 0.7052996158599854] [G loss: 5.953065872192383]\n",
      "[Epoch 0/100] [Batch 363/512] [D loss: 0.925201416015625] [G loss: 2.603175401687622]\n",
      "[Epoch 0/100] [Batch 364/512] [D loss: 0.43256676197052] [G loss: 4.490644454956055]\n",
      "[Epoch 0/100] [Batch 365/512] [D loss: 0.8990946412086487] [G loss: 4.75395393371582]\n",
      "[Epoch 0/100] [Batch 366/512] [D loss: 0.18997547030448914] [G loss: 4.9976725578308105]\n",
      "[Epoch 0/100] [Batch 367/512] [D loss: 0.41820743680000305] [G loss: 3.5197439193725586]\n",
      "[Epoch 0/100] [Batch 368/512] [D loss: 0.07687994837760925] [G loss: 3.3515799045562744]\n",
      "[Epoch 0/100] [Batch 369/512] [D loss: 0.47491002082824707] [G loss: 3.086294651031494]\n",
      "[Epoch 0/100] [Batch 370/512] [D loss: 0.6492831707000732] [G loss: 10.245973587036133]\n",
      "[Epoch 0/100] [Batch 371/512] [D loss: 1.7694121599197388] [G loss: 0.08440124243497849]\n",
      "[Epoch 0/100] [Batch 372/512] [D loss: 1.155932068824768] [G loss: 6.533904075622559]\n",
      "[Epoch 0/100] [Batch 373/512] [D loss: 0.5461464524269104] [G loss: 4.154550552368164]\n",
      "[Epoch 0/100] [Batch 374/512] [D loss: 0.12470538914203644] [G loss: 5.716105937957764]\n",
      "[Epoch 0/100] [Batch 375/512] [D loss: 0.41700804233551025] [G loss: 7.183867931365967]\n",
      "[Epoch 0/100] [Batch 376/512] [D loss: 1.2420859336853027] [G loss: 1.178126335144043]\n",
      "[Epoch 0/100] [Batch 377/512] [D loss: 0.9191919565200806] [G loss: 7.592763900756836]\n",
      "[Epoch 0/100] [Batch 378/512] [D loss: 0.35475462675094604] [G loss: 5.39937686920166]\n",
      "[Epoch 0/100] [Batch 379/512] [D loss: 0.10866150259971619] [G loss: 4.151361465454102]\n",
      "[Epoch 0/100] [Batch 380/512] [D loss: 0.35941746830940247] [G loss: 7.947426795959473]\n",
      "[Epoch 0/100] [Batch 381/512] [D loss: 0.3635624647140503] [G loss: 3.4966883659362793]\n",
      "[Epoch 0/100] [Batch 382/512] [D loss: 0.8113261461257935] [G loss: 8.539595603942871]\n",
      "[Epoch 0/100] [Batch 383/512] [D loss: 0.771015465259552] [G loss: 1.7951364517211914]\n",
      "[Epoch 0/100] [Batch 384/512] [D loss: 0.6073137521743774] [G loss: 5.856041431427002]\n",
      "[Epoch 0/100] [Batch 385/512] [D loss: 0.4604395627975464] [G loss: 7.680511951446533]\n",
      "[Epoch 0/100] [Batch 386/512] [D loss: 0.23216232657432556] [G loss: 4.700120449066162]\n",
      "[Epoch 0/100] [Batch 387/512] [D loss: 0.6335517764091492] [G loss: 0.8225876688957214]\n",
      "[Epoch 0/100] [Batch 388/512] [D loss: 0.7933661341667175] [G loss: 6.526106834411621]\n",
      "[Epoch 0/100] [Batch 389/512] [D loss: 1.4910435676574707] [G loss: 0.7895628213882446]\n",
      "[Epoch 0/100] [Batch 390/512] [D loss: 4.295310020446777] [G loss: 7.431084632873535]\n",
      "[Epoch 0/100] [Batch 391/512] [D loss: 0.6635870337486267] [G loss: 5.923632621765137]\n",
      "[Epoch 0/100] [Batch 392/512] [D loss: 0.5145112872123718] [G loss: 2.990255355834961]\n",
      "[Epoch 0/100] [Batch 393/512] [D loss: 0.2658461928367615] [G loss: 6.373815536499023]\n",
      "[Epoch 0/100] [Batch 394/512] [D loss: 0.314660906791687] [G loss: 5.866433620452881]\n",
      "[Epoch 0/100] [Batch 395/512] [D loss: 0.3831941783428192] [G loss: 3.444204807281494]\n",
      "[Epoch 0/100] [Batch 396/512] [D loss: 0.15807971358299255] [G loss: 3.7276782989501953]\n",
      "[Epoch 0/100] [Batch 397/512] [D loss: 0.4380268454551697] [G loss: 5.452337265014648]\n",
      "[Epoch 0/100] [Batch 398/512] [D loss: 0.01563243940472603] [G loss: 6.097597122192383]\n",
      "[Epoch 0/100] [Batch 399/512] [D loss: 0.3028930425643921] [G loss: 1.3566620349884033]\n",
      "[Epoch 0/100] [Batch 400/512] [D loss: 0.6223595142364502] [G loss: 9.468607902526855]\n",
      "[Epoch 0/100] [Batch 401/512] [D loss: 1.3075724840164185] [G loss: 0.22114059329032898]\n",
      "[Epoch 0/100] [Batch 402/512] [D loss: 1.050410509109497] [G loss: 10.632603645324707]\n",
      "[Epoch 0/100] [Batch 403/512] [D loss: 0.44227659702301025] [G loss: 4.828967094421387]\n",
      "[Epoch 0/100] [Batch 404/512] [D loss: 0.042048025876283646] [G loss: 3.7339024543762207]\n",
      "[Epoch 0/100] [Batch 405/512] [D loss: 0.4515998363494873] [G loss: 4.8347601890563965]\n",
      "[Epoch 0/100] [Batch 406/512] [D loss: 0.36895886063575745] [G loss: 7.195147514343262]\n",
      "[Epoch 0/100] [Batch 407/512] [D loss: 0.7479792237281799] [G loss: 0.3549291789531708]\n",
      "[Epoch 0/100] [Batch 408/512] [D loss: 1.1453840732574463] [G loss: 7.330755710601807]\n",
      "[Epoch 0/100] [Batch 409/512] [D loss: 1.3396273851394653] [G loss: 0.181955486536026]\n",
      "[Epoch 0/100] [Batch 410/512] [D loss: 2.0430760383605957] [G loss: 7.0301971435546875]\n",
      "[Epoch 0/100] [Batch 411/512] [D loss: 0.9411386251449585] [G loss: 4.5882649421691895]\n",
      "[Epoch 0/100] [Batch 412/512] [D loss: 0.6629383563995361] [G loss: 4.3113484382629395]\n",
      "[Epoch 0/100] [Batch 413/512] [D loss: 0.655863344669342] [G loss: 1.2404426336288452]\n",
      "[Epoch 0/100] [Batch 414/512] [D loss: 0.9312580227851868] [G loss: 5.724349021911621]\n",
      "[Epoch 0/100] [Batch 415/512] [D loss: 0.3154851198196411] [G loss: 7.635224342346191]\n",
      "[Epoch 0/100] [Batch 416/512] [D loss: 0.5680835843086243] [G loss: 4.736611366271973]\n",
      "[Epoch 0/100] [Batch 417/512] [D loss: 0.4382781386375427] [G loss: 1.526526689529419]\n",
      "[Epoch 0/100] [Batch 418/512] [D loss: 0.7496782541275024] [G loss: 6.037185192108154]\n",
      "[Epoch 0/100] [Batch 419/512] [D loss: 0.058796972036361694] [G loss: 7.835204124450684]\n",
      "[Epoch 0/100] [Batch 420/512] [D loss: 0.418160080909729] [G loss: 3.5143861770629883]\n",
      "[Epoch 0/100] [Batch 421/512] [D loss: 0.19137822091579437] [G loss: 2.789844036102295]\n",
      "[Epoch 0/100] [Batch 422/512] [D loss: 1.2848892211914062] [G loss: 6.57633113861084]\n",
      "[Epoch 0/100] [Batch 423/512] [D loss: 0.1259729266166687] [G loss: 6.9632062911987305]\n",
      "[Epoch 0/100] [Batch 424/512] [D loss: 0.43828025460243225] [G loss: 4.483804702758789]\n",
      "[Epoch 0/100] [Batch 425/512] [D loss: 0.23061445355415344] [G loss: 5.483275413513184]\n",
      "[Epoch 0/100] [Batch 426/512] [D loss: 0.730962336063385] [G loss: 1.395259141921997]\n",
      "[Epoch 0/100] [Batch 427/512] [D loss: 0.9731262922286987] [G loss: 7.934152126312256]\n",
      "[Epoch 0/100] [Batch 428/512] [D loss: 0.17105278372764587] [G loss: 7.666460990905762]\n",
      "[Epoch 0/100] [Batch 429/512] [D loss: 0.14083178341388702] [G loss: 4.18258810043335]\n",
      "[Epoch 0/100] [Batch 430/512] [D loss: 0.4098045825958252] [G loss: 7.118250846862793]\n",
      "[Epoch 0/100] [Batch 431/512] [D loss: 0.6311281323432922] [G loss: 3.0406551361083984]\n",
      "[Epoch 0/100] [Batch 432/512] [D loss: 0.5055810809135437] [G loss: 3.9475183486938477]\n",
      "[Epoch 0/100] [Batch 433/512] [D loss: 0.14412692189216614] [G loss: 6.133722305297852]\n",
      "[Epoch 0/100] [Batch 434/512] [D loss: 0.653160810470581] [G loss: 1.330834984779358]\n",
      "[Epoch 0/100] [Batch 435/512] [D loss: 0.5549344420433044] [G loss: 7.551626682281494]\n",
      "[Epoch 0/100] [Batch 436/512] [D loss: 0.6083330512046814] [G loss: 2.5366950035095215]\n",
      "[Epoch 0/100] [Batch 437/512] [D loss: 0.7077732682228088] [G loss: 9.366720199584961]\n",
      "[Epoch 0/100] [Batch 438/512] [D loss: 0.9458199143409729] [G loss: 1.8787851333618164]\n",
      "[Epoch 0/100] [Batch 439/512] [D loss: 0.644425094127655] [G loss: 5.061130523681641]\n",
      "[Epoch 0/100] [Batch 440/512] [D loss: 0.49979105591773987] [G loss: 9.630184173583984]\n",
      "[Epoch 0/100] [Batch 441/512] [D loss: 0.21776437759399414] [G loss: 9.177783966064453]\n",
      "[Epoch 0/100] [Batch 442/512] [D loss: 0.053102754056453705] [G loss: 6.244194030761719]\n",
      "[Epoch 0/100] [Batch 443/512] [D loss: 0.22092460095882416] [G loss: 2.777708053588867]\n",
      "[Epoch 0/100] [Batch 444/512] [D loss: 0.49755415320396423] [G loss: 6.3705244064331055]\n",
      "[Epoch 0/100] [Batch 445/512] [D loss: 0.2577207088470459] [G loss: 3.3472561836242676]\n",
      "[Epoch 0/100] [Batch 446/512] [D loss: 0.16278469562530518] [G loss: 5.790858268737793]\n",
      "[Epoch 0/100] [Batch 447/512] [D loss: 0.26640215516090393] [G loss: 4.905858516693115]\n",
      "[Epoch 0/100] [Batch 448/512] [D loss: 0.6859360933303833] [G loss: 11.757861137390137]\n",
      "[Epoch 0/100] [Batch 449/512] [D loss: 0.5015029907226562] [G loss: 3.518402576446533]\n",
      "[Epoch 0/100] [Batch 450/512] [D loss: 0.28719109296798706] [G loss: 4.0671234130859375]\n",
      "[Epoch 0/100] [Batch 451/512] [D loss: 0.20376496016979218] [G loss: 8.758118629455566]\n",
      "[Epoch 0/100] [Batch 452/512] [D loss: 0.4805287718772888] [G loss: 0.8062175512313843]\n",
      "[Epoch 0/100] [Batch 453/512] [D loss: 1.3695746660232544] [G loss: 17.083524703979492]\n",
      "[Epoch 0/100] [Batch 454/512] [D loss: 1.397296667098999] [G loss: 0.7703369855880737]\n",
      "[Epoch 0/100] [Batch 455/512] [D loss: 1.111478328704834] [G loss: 12.901857376098633]\n",
      "[Epoch 0/100] [Batch 456/512] [D loss: 1.9440503120422363] [G loss: 0.5915422439575195]\n",
      "[Epoch 0/100] [Batch 457/512] [D loss: 1.353588581085205] [G loss: 6.995185852050781]\n",
      "[Epoch 0/100] [Batch 458/512] [D loss: 0.2439107596874237] [G loss: 7.225318908691406]\n",
      "[Epoch 0/100] [Batch 459/512] [D loss: 0.6496891379356384] [G loss: 1.7525336742401123]\n",
      "[Epoch 0/100] [Batch 460/512] [D loss: 0.6709101796150208] [G loss: 7.93399715423584]\n",
      "[Epoch 0/100] [Batch 461/512] [D loss: 1.1752328872680664] [G loss: 8.683831214904785]\n",
      "[Epoch 0/100] [Batch 462/512] [D loss: 1.4311610460281372] [G loss: 2.355498790740967]\n",
      "[Epoch 0/100] [Batch 463/512] [D loss: 0.8501235246658325] [G loss: 5.169468879699707]\n",
      "[Epoch 0/100] [Batch 464/512] [D loss: 0.14010801911354065] [G loss: 4.670047760009766]\n",
      "[Epoch 0/100] [Batch 465/512] [D loss: 0.2866300344467163] [G loss: 5.998425483703613]\n",
      "[Epoch 0/100] [Batch 466/512] [D loss: 0.1293337345123291] [G loss: 8.13532829284668]\n",
      "[Epoch 0/100] [Batch 467/512] [D loss: 0.6559494733810425] [G loss: 1.1128389835357666]\n",
      "[Epoch 0/100] [Batch 468/512] [D loss: 0.6342712640762329] [G loss: 6.888713359832764]\n",
      "[Epoch 0/100] [Batch 469/512] [D loss: 0.14326727390289307] [G loss: 7.453128814697266]\n",
      "[Epoch 0/100] [Batch 470/512] [D loss: 0.2921346127986908] [G loss: 3.960231065750122]\n",
      "[Epoch 0/100] [Batch 471/512] [D loss: 0.23828503489494324] [G loss: 3.4193572998046875]\n",
      "[Epoch 0/100] [Batch 472/512] [D loss: 0.5913033485412598] [G loss: 8.79763412475586]\n",
      "[Epoch 0/100] [Batch 473/512] [D loss: 1.3706886768341064] [G loss: 0.5637689828872681]\n",
      "[Epoch 0/100] [Batch 474/512] [D loss: 0.708849310874939] [G loss: 7.140753746032715]\n",
      "[Epoch 0/100] [Batch 475/512] [D loss: 0.45319807529449463] [G loss: 3.444195508956909]\n",
      "[Epoch 0/100] [Batch 476/512] [D loss: 0.795080304145813] [G loss: 1.4805617332458496]\n",
      "[Epoch 0/100] [Batch 477/512] [D loss: 1.5707231760025024] [G loss: 11.519813537597656]\n",
      "[Epoch 0/100] [Batch 478/512] [D loss: 2.3798677921295166] [G loss: 4.623616695404053]\n",
      "[Epoch 0/100] [Batch 479/512] [D loss: 0.7573286890983582] [G loss: 3.201535224914551]\n",
      "[Epoch 0/100] [Batch 480/512] [D loss: 0.999962329864502] [G loss: 4.857027053833008]\n",
      "[Epoch 0/100] [Batch 481/512] [D loss: 0.5525510907173157] [G loss: 2.7494308948516846]\n",
      "[Epoch 0/100] [Batch 482/512] [D loss: 0.7348957061767578] [G loss: 6.832320213317871]\n",
      "[Epoch 0/100] [Batch 483/512] [D loss: 0.12475695461034775] [G loss: 7.057320594787598]\n",
      "[Epoch 0/100] [Batch 484/512] [D loss: 0.3796544075012207] [G loss: 3.310213088989258]\n",
      "[Epoch 0/100] [Batch 485/512] [D loss: 0.49602019786834717] [G loss: 4.069664001464844]\n",
      "[Epoch 0/100] [Batch 486/512] [D loss: 0.6660439968109131] [G loss: 5.469204425811768]\n",
      "[Epoch 0/100] [Batch 487/512] [D loss: 0.6319350004196167] [G loss: 3.2365381717681885]\n",
      "[Epoch 0/100] [Batch 488/512] [D loss: 0.16232171654701233] [G loss: 3.9622762203216553]\n",
      "[Epoch 0/100] [Batch 489/512] [D loss: 0.22170418500900269] [G loss: 3.7267889976501465]\n",
      "[Epoch 0/100] [Batch 490/512] [D loss: 0.2398257553577423] [G loss: 6.966375350952148]\n",
      "[Epoch 0/100] [Batch 491/512] [D loss: 0.5049095153808594] [G loss: 3.002335786819458]\n",
      "[Epoch 0/100] [Batch 492/512] [D loss: 0.22111517190933228] [G loss: 2.3238067626953125]\n",
      "[Epoch 0/100] [Batch 493/512] [D loss: 0.12250541895627975] [G loss: 4.687121868133545]\n",
      "[Epoch 0/100] [Batch 494/512] [D loss: 0.7884699106216431] [G loss: 8.375565528869629]\n",
      "[Epoch 0/100] [Batch 495/512] [D loss: 0.7391913533210754] [G loss: 2.750654697418213]\n",
      "[Epoch 0/100] [Batch 496/512] [D loss: 2.2223763465881348] [G loss: 8.65786361694336]\n",
      "[Epoch 0/100] [Batch 497/512] [D loss: 1.267033338546753] [G loss: 2.793074131011963]\n",
      "[Epoch 0/100] [Batch 498/512] [D loss: 0.5735104084014893] [G loss: 3.404010772705078]\n",
      "[Epoch 0/100] [Batch 499/512] [D loss: 0.8670933246612549] [G loss: 6.420429229736328]\n",
      "[Epoch 0/100] [Batch 500/512] [D loss: 2.2607855796813965] [G loss: 0.8871718049049377]\n",
      "[Epoch 0/100] [Batch 501/512] [D loss: 0.8271846175193787] [G loss: 2.409278154373169]\n",
      "[Epoch 0/100] [Batch 502/512] [D loss: 0.6633676290512085] [G loss: 7.534451961517334]\n",
      "[Epoch 0/100] [Batch 503/512] [D loss: 4.289541244506836] [G loss: 2.12772798538208]\n",
      "[Epoch 0/100] [Batch 504/512] [D loss: 0.39412346482276917] [G loss: 2.6733155250549316]\n",
      "[Epoch 0/100] [Batch 505/512] [D loss: 0.9637066125869751] [G loss: 4.861849308013916]\n",
      "[Epoch 0/100] [Batch 506/512] [D loss: 0.31286686658859253] [G loss: 7.177885055541992]\n",
      "[Epoch 0/100] [Batch 507/512] [D loss: 0.3854169547557831] [G loss: 5.484414100646973]\n",
      "[Epoch 0/100] [Batch 508/512] [D loss: 0.16461420059204102] [G loss: 4.946622848510742]\n",
      "[Epoch 0/100] [Batch 509/512] [D loss: 0.29741278290748596] [G loss: 4.927553653717041]\n",
      "[Epoch 0/100] [Batch 510/512] [D loss: 1.1263887882232666] [G loss: 0.10670965909957886]\n",
      "[Epoch 0/100] [Batch 511/512] [D loss: 2.6955509185791016] [G loss: 14.282341957092285]\n",
      "[Epoch 1/100] [Batch 0/512] [D loss: 1.264054298400879] [G loss: 4.500324726104736]\n",
      "[Epoch 1/100] [Batch 1/512] [D loss: 0.8046207427978516] [G loss: 9.36717700958252]\n",
      "[Epoch 1/100] [Batch 2/512] [D loss: 1.2232658863067627] [G loss: 0.5144959688186646]\n",
      "[Epoch 1/100] [Batch 3/512] [D loss: 0.7777277827262878] [G loss: 8.36208724975586]\n",
      "[Epoch 1/100] [Batch 4/512] [D loss: 0.6261978149414062] [G loss: 3.503037929534912]\n",
      "[Epoch 1/100] [Batch 5/512] [D loss: 0.545758843421936] [G loss: 5.840147018432617]\n",
      "[Epoch 1/100] [Batch 6/512] [D loss: 0.48177337646484375] [G loss: 5.068487167358398]\n",
      "[Epoch 1/100] [Batch 7/512] [D loss: 0.029206007719039917] [G loss: 6.009314060211182]\n",
      "[Epoch 1/100] [Batch 8/512] [D loss: 0.141012504696846] [G loss: 5.7786407470703125]\n",
      "[Epoch 1/100] [Batch 9/512] [D loss: 0.3854357898235321] [G loss: 1.9566950798034668]\n",
      "[Epoch 1/100] [Batch 10/512] [D loss: 1.2057745456695557] [G loss: 5.37360954284668]\n",
      "[Epoch 1/100] [Batch 11/512] [D loss: 0.47126221656799316] [G loss: 3.1450815200805664]\n",
      "[Epoch 1/100] [Batch 12/512] [D loss: 0.48088690638542175] [G loss: 8.669296264648438]\n",
      "[Epoch 1/100] [Batch 13/512] [D loss: 1.4067665338516235] [G loss: 0.35274261236190796]\n",
      "[Epoch 1/100] [Batch 14/512] [D loss: 1.4698233604431152] [G loss: 8.731100082397461]\n",
      "[Epoch 1/100] [Batch 15/512] [D loss: 0.4540695548057556] [G loss: 5.654847621917725]\n",
      "[Epoch 1/100] [Batch 16/512] [D loss: 1.3971165418624878] [G loss: 0.21148449182510376]\n",
      "[Epoch 1/100] [Batch 17/512] [D loss: 2.2284224033355713] [G loss: 9.409948348999023]\n",
      "[Epoch 1/100] [Batch 18/512] [D loss: 1.8127267360687256] [G loss: 1.261516809463501]\n",
      "[Epoch 1/100] [Batch 19/512] [D loss: 0.7405451536178589] [G loss: 5.839033603668213]\n",
      "[Epoch 1/100] [Batch 20/512] [D loss: 0.6283915042877197] [G loss: 2.6597342491149902]\n",
      "[Epoch 1/100] [Batch 21/512] [D loss: 0.571256697177887] [G loss: 1.3501808643341064]\n",
      "[Epoch 1/100] [Batch 22/512] [D loss: 1.0052326917648315] [G loss: 8.536215782165527]\n",
      "[Epoch 1/100] [Batch 23/512] [D loss: 0.5477865934371948] [G loss: 2.8245153427124023]\n",
      "[Epoch 1/100] [Batch 24/512] [D loss: 0.5293439626693726] [G loss: 2.7324633598327637]\n",
      "[Epoch 1/100] [Batch 25/512] [D loss: 0.603295087814331] [G loss: 4.317925453186035]\n",
      "[Epoch 1/100] [Batch 26/512] [D loss: 0.8952986001968384] [G loss: 3.3889400959014893]\n",
      "[Epoch 1/100] [Batch 27/512] [D loss: 0.17814256250858307] [G loss: 7.0001020431518555]\n",
      "[Epoch 1/100] [Batch 28/512] [D loss: 0.5037564039230347] [G loss: 2.3481369018554688]\n",
      "[Epoch 1/100] [Batch 29/512] [D loss: 0.18275034427642822] [G loss: 6.926703453063965]\n",
      "[Epoch 1/100] [Batch 30/512] [D loss: 0.412354975938797] [G loss: 4.7451090812683105]\n",
      "[Epoch 1/100] [Batch 31/512] [D loss: 0.11101032793521881] [G loss: 6.525062561035156]\n",
      "[Epoch 1/100] [Batch 32/512] [D loss: 0.2960882782936096] [G loss: 9.900812149047852]\n",
      "[Epoch 1/100] [Batch 33/512] [D loss: 1.5356227159500122] [G loss: 0.0018800246762111783]\n",
      "[Epoch 1/100] [Batch 34/512] [D loss: 5.413384914398193] [G loss: 2.5751118659973145]\n",
      "[Epoch 1/100] [Batch 35/512] [D loss: 0.8915271759033203] [G loss: 11.141006469726562]\n",
      "[Epoch 1/100] [Batch 36/512] [D loss: 2.949345111846924] [G loss: 4.340107440948486]\n",
      "[Epoch 1/100] [Batch 37/512] [D loss: 0.47562581300735474] [G loss: 1.411665678024292]\n",
      "[Epoch 1/100] [Batch 38/512] [D loss: 1.0472304821014404] [G loss: 4.2671284675598145]\n",
      "[Epoch 1/100] [Batch 39/512] [D loss: 0.2799382209777832] [G loss: 5.5865797996521]\n",
      "[Epoch 1/100] [Batch 40/512] [D loss: 0.9889411330223083] [G loss: 0.6461659073829651]\n",
      "[Epoch 1/100] [Batch 41/512] [D loss: 1.2854483127593994] [G loss: 1.4101861715316772]\n",
      "[Epoch 1/100] [Batch 42/512] [D loss: 0.6104730367660522] [G loss: 3.664247989654541]\n",
      "[Epoch 1/100] [Batch 43/512] [D loss: 1.4514610767364502] [G loss: 5.987550258636475]\n",
      "[Epoch 1/100] [Batch 44/512] [D loss: 2.0012905597686768] [G loss: 3.9407248497009277]\n",
      "[Epoch 1/100] [Batch 45/512] [D loss: 0.7993012070655823] [G loss: 1.0554118156433105]\n",
      "[Epoch 1/100] [Batch 46/512] [D loss: 2.1210219860076904] [G loss: 3.511068344116211]\n",
      "[Epoch 1/100] [Batch 47/512] [D loss: 4.736567497253418] [G loss: 1.7019460201263428]\n",
      "[Epoch 1/100] [Batch 48/512] [D loss: 1.2020797729492188] [G loss: 2.508744955062866]\n",
      "[Epoch 1/100] [Batch 49/512] [D loss: 0.934686541557312] [G loss: 1.5952541828155518]\n",
      "[Epoch 1/100] [Batch 50/512] [D loss: 0.8276410698890686] [G loss: 3.7458839416503906]\n",
      "[Epoch 1/100] [Batch 51/512] [D loss: 1.151012659072876] [G loss: 3.462508201599121]\n",
      "[Epoch 1/100] [Batch 52/512] [D loss: 0.9187899231910706] [G loss: 2.5422258377075195]\n",
      "[Epoch 1/100] [Batch 53/512] [D loss: 1.094922423362732] [G loss: 3.7155001163482666]\n",
      "[Epoch 1/100] [Batch 54/512] [D loss: 1.187416672706604] [G loss: 0.8035825490951538]\n",
      "[Epoch 1/100] [Batch 55/512] [D loss: 1.0603055953979492] [G loss: 1.5247676372528076]\n",
      "[Epoch 1/100] [Batch 56/512] [D loss: 0.5031654238700867] [G loss: 5.872241020202637]\n",
      "[Epoch 1/100] [Batch 57/512] [D loss: 0.7383752465248108] [G loss: 4.030291557312012]\n",
      "[Epoch 1/100] [Batch 58/512] [D loss: 0.6344931125640869] [G loss: 1.7097818851470947]\n",
      "[Epoch 1/100] [Batch 59/512] [D loss: 0.4796363115310669] [G loss: 5.046013832092285]\n",
      "[Epoch 1/100] [Batch 60/512] [D loss: 0.29048898816108704] [G loss: 3.4776804447174072]\n",
      "[Epoch 1/100] [Batch 61/512] [D loss: 0.31047195196151733] [G loss: 1.974051833152771]\n",
      "[Epoch 1/100] [Batch 62/512] [D loss: 0.7640946507453918] [G loss: 10.437806129455566]\n",
      "[Epoch 1/100] [Batch 63/512] [D loss: 0.3018670082092285] [G loss: 6.384945869445801]\n",
      "[Epoch 1/100] [Batch 64/512] [D loss: 0.39908555150032043] [G loss: 0.6245676279067993]\n",
      "[Epoch 1/100] [Batch 65/512] [D loss: 1.4477360248565674] [G loss: 7.449295997619629]\n",
      "[Epoch 1/100] [Batch 66/512] [D loss: 1.0750012397766113] [G loss: 1.5475356578826904]\n",
      "[Epoch 1/100] [Batch 67/512] [D loss: 0.6795879602432251] [G loss: 2.1069719791412354]\n",
      "[Epoch 1/100] [Batch 68/512] [D loss: 0.757953405380249] [G loss: 7.484062194824219]\n",
      "[Epoch 1/100] [Batch 69/512] [D loss: 1.7653591632843018] [G loss: 0.3000122010707855]\n",
      "[Epoch 1/100] [Batch 70/512] [D loss: 1.2807602882385254] [G loss: 5.64908504486084]\n",
      "[Epoch 1/100] [Batch 71/512] [D loss: 0.8444607257843018] [G loss: 1.9160385131835938]\n",
      "[Epoch 1/100] [Batch 72/512] [D loss: 0.9028496146202087] [G loss: 7.80451774597168]\n",
      "[Epoch 1/100] [Batch 73/512] [D loss: 0.17959436774253845] [G loss: 5.233451843261719]\n",
      "[Epoch 1/100] [Batch 74/512] [D loss: 0.5444362163543701] [G loss: 0.044468410313129425]\n",
      "[Epoch 1/100] [Batch 75/512] [D loss: 1.8134509325027466] [G loss: 10.850982666015625]\n",
      "[Epoch 1/100] [Batch 76/512] [D loss: 1.0563043355941772] [G loss: 2.133713722229004]\n",
      "[Epoch 1/100] [Batch 77/512] [D loss: 0.31016266345977783] [G loss: 4.220961570739746]\n",
      "[Epoch 1/100] [Batch 78/512] [D loss: 0.9488250017166138] [G loss: 7.882465839385986]\n",
      "[Epoch 1/100] [Batch 79/512] [D loss: 1.5657371282577515] [G loss: 1.4144564867019653]\n",
      "[Epoch 1/100] [Batch 80/512] [D loss: 1.3430660963058472] [G loss: 3.927493095397949]\n",
      "[Epoch 1/100] [Batch 81/512] [D loss: 0.28104445338249207] [G loss: 8.127076148986816]\n",
      "[Epoch 1/100] [Batch 82/512] [D loss: 0.844373345375061] [G loss: 0.9712976217269897]\n",
      "[Epoch 1/100] [Batch 83/512] [D loss: 0.7997008562088013] [G loss: 8.319215774536133]\n",
      "[Epoch 1/100] [Batch 84/512] [D loss: 0.17362989485263824] [G loss: 7.1425323486328125]\n",
      "[Epoch 1/100] [Batch 85/512] [D loss: 0.6234436631202698] [G loss: 0.5283859968185425]\n",
      "[Epoch 1/100] [Batch 86/512] [D loss: 1.2162283658981323] [G loss: 12.371576309204102]\n",
      "[Epoch 1/100] [Batch 87/512] [D loss: 0.5926454067230225] [G loss: 4.698766708374023]\n",
      "[Epoch 1/100] [Batch 88/512] [D loss: 0.7694132924079895] [G loss: 1.4028778076171875]\n",
      "[Epoch 1/100] [Batch 89/512] [D loss: 0.6244259476661682] [G loss: 8.813740730285645]\n",
      "[Epoch 1/100] [Batch 90/512] [D loss: 1.1138724088668823] [G loss: 0.5981866717338562]\n",
      "[Epoch 1/100] [Batch 91/512] [D loss: 1.1448131799697876] [G loss: 7.923701286315918]\n",
      "[Epoch 1/100] [Batch 92/512] [D loss: 0.11134932935237885] [G loss: 9.198225975036621]\n",
      "[Epoch 1/100] [Batch 93/512] [D loss: 1.4237233400344849] [G loss: 1.431121826171875]\n",
      "[Epoch 1/100] [Batch 94/512] [D loss: 2.792914390563965] [G loss: 6.345633029937744]\n",
      "[Epoch 1/100] [Batch 95/512] [D loss: 0.8682050108909607] [G loss: 2.379878044128418]\n",
      "[Epoch 1/100] [Batch 96/512] [D loss: 1.299720287322998] [G loss: 2.5121583938598633]\n",
      "[Epoch 1/100] [Batch 97/512] [D loss: 0.8115103840827942] [G loss: 7.147545337677002]\n",
      "[Epoch 1/100] [Batch 98/512] [D loss: 2.1288840770721436] [G loss: 0.364764541387558]\n",
      "[Epoch 1/100] [Batch 99/512] [D loss: 0.8934884071350098] [G loss: 3.126345634460449]\n",
      "[Epoch 1/100] [Batch 100/512] [D loss: 0.3640919327735901] [G loss: 3.821938991546631]\n",
      "[Epoch 1/100] [Batch 101/512] [D loss: 0.22764047980308533] [G loss: 4.533285140991211]\n",
      "[Epoch 1/100] [Batch 102/512] [D loss: 0.21964114904403687] [G loss: 4.133199691772461]\n",
      "[Epoch 1/100] [Batch 103/512] [D loss: 0.7484649419784546] [G loss: 0.4831138253211975]\n",
      "[Epoch 1/100] [Batch 104/512] [D loss: 0.862808346748352] [G loss: 8.72427749633789]\n",
      "[Epoch 1/100] [Batch 105/512] [D loss: 1.1939367055892944] [G loss: 1.8249388933181763]\n",
      "[Epoch 1/100] [Batch 106/512] [D loss: 0.5410176515579224] [G loss: 6.756539821624756]\n",
      "[Epoch 1/100] [Batch 107/512] [D loss: 0.2059410959482193] [G loss: 5.239741325378418]\n",
      "[Epoch 1/100] [Batch 108/512] [D loss: 0.3663533627986908] [G loss: 4.436271667480469]\n",
      "[Epoch 1/100] [Batch 109/512] [D loss: 0.46078741550445557] [G loss: 8.012483596801758]\n",
      "[Epoch 1/100] [Batch 110/512] [D loss: 0.190748929977417] [G loss: 8.526344299316406]\n",
      "[Epoch 1/100] [Batch 111/512] [D loss: 0.9986787438392639] [G loss: 2.237393379211426]\n",
      "[Epoch 1/100] [Batch 112/512] [D loss: 0.4253270626068115] [G loss: 5.095108985900879]\n",
      "[Epoch 1/100] [Batch 113/512] [D loss: 0.33669131994247437] [G loss: 5.235211372375488]\n",
      "[Epoch 1/100] [Batch 114/512] [D loss: 0.16301140189170837] [G loss: 5.853078842163086]\n",
      "[Epoch 1/100] [Batch 115/512] [D loss: 0.11707411706447601] [G loss: 3.0960192680358887]\n",
      "[Epoch 1/100] [Batch 116/512] [D loss: 0.2964363396167755] [G loss: 10.48603630065918]\n",
      "[Epoch 1/100] [Batch 117/512] [D loss: 0.6108935475349426] [G loss: 0.5870020389556885]\n",
      "[Epoch 1/100] [Batch 118/512] [D loss: 1.828168511390686] [G loss: 9.801446914672852]\n",
      "[Epoch 1/100] [Batch 119/512] [D loss: 0.8951759934425354] [G loss: 1.245357871055603]\n",
      "[Epoch 1/100] [Batch 120/512] [D loss: 2.1197447776794434] [G loss: 11.700611114501953]\n",
      "[Epoch 1/100] [Batch 121/512] [D loss: 2.1153526306152344] [G loss: 0.36437588930130005]\n",
      "[Epoch 1/100] [Batch 122/512] [D loss: 1.3842177391052246] [G loss: 7.321969985961914]\n",
      "[Epoch 1/100] [Batch 123/512] [D loss: 0.39254030585289] [G loss: 5.299788951873779]\n",
      "[Epoch 1/100] [Batch 124/512] [D loss: 0.869971513748169] [G loss: 0.8736016750335693]\n",
      "[Epoch 1/100] [Batch 125/512] [D loss: 0.9804654717445374] [G loss: 7.916171073913574]\n",
      "[Epoch 1/100] [Batch 126/512] [D loss: 0.708579421043396] [G loss: 4.6499223709106445]\n",
      "[Epoch 1/100] [Batch 127/512] [D loss: 0.376129150390625] [G loss: 2.630581855773926]\n",
      "[Epoch 1/100] [Batch 128/512] [D loss: 0.587230920791626] [G loss: 8.583640098571777]\n",
      "[Epoch 1/100] [Batch 129/512] [D loss: 1.5537692308425903] [G loss: 0.08209294825792313]\n",
      "[Epoch 1/100] [Batch 130/512] [D loss: 1.9369374513626099] [G loss: 10.1497802734375]\n",
      "[Epoch 1/100] [Batch 131/512] [D loss: 0.38248491287231445] [G loss: 9.686859130859375]\n",
      "[Epoch 1/100] [Batch 132/512] [D loss: 1.0128564834594727] [G loss: 4.083844184875488]\n",
      "[Epoch 1/100] [Batch 133/512] [D loss: 1.4438987970352173] [G loss: 3.8631699085235596]\n",
      "[Epoch 1/100] [Batch 134/512] [D loss: 0.7666879892349243] [G loss: 7.360522747039795]\n",
      "[Epoch 1/100] [Batch 135/512] [D loss: 0.7883750796318054] [G loss: 2.952758312225342]\n",
      "[Epoch 1/100] [Batch 136/512] [D loss: 0.23676224052906036] [G loss: 6.603156566619873]\n",
      "[Epoch 1/100] [Batch 137/512] [D loss: 0.6530559659004211] [G loss: 3.9102723598480225]\n",
      "[Epoch 1/100] [Batch 138/512] [D loss: 0.20336686074733734] [G loss: 4.778962135314941]\n",
      "[Epoch 1/100] [Batch 139/512] [D loss: 0.24692094326019287] [G loss: 6.643866062164307]\n",
      "[Epoch 1/100] [Batch 140/512] [D loss: 0.5331399440765381] [G loss: 3.197366237640381]\n",
      "[Epoch 1/100] [Batch 141/512] [D loss: 1.0889549255371094] [G loss: 10.709066390991211]\n",
      "[Epoch 1/100] [Batch 142/512] [D loss: 1.543386459350586] [G loss: 0.25008997321128845]\n",
      "[Epoch 1/100] [Batch 143/512] [D loss: 2.0538270473480225] [G loss: 8.857255935668945]\n",
      "[Epoch 1/100] [Batch 144/512] [D loss: 0.9979842305183411] [G loss: 3.721129894256592]\n",
      "[Epoch 1/100] [Batch 145/512] [D loss: 0.31751638650894165] [G loss: 3.1133980751037598]\n",
      "[Epoch 1/100] [Batch 146/512] [D loss: 0.30578720569610596] [G loss: 6.703620910644531]\n",
      "[Epoch 1/100] [Batch 147/512] [D loss: 0.8029235005378723] [G loss: 3.5797276496887207]\n",
      "[Epoch 1/100] [Batch 148/512] [D loss: 0.5557082295417786] [G loss: 2.905651092529297]\n",
      "[Epoch 1/100] [Batch 149/512] [D loss: 0.6229839324951172] [G loss: 9.315361022949219]\n",
      "[Epoch 1/100] [Batch 150/512] [D loss: 2.4798953533172607] [G loss: 0.7128195762634277]\n",
      "[Epoch 1/100] [Batch 151/512] [D loss: 2.0671865940093994] [G loss: 11.553424835205078]\n",
      "[Epoch 1/100] [Batch 152/512] [D loss: 1.3022449016571045] [G loss: 2.388749122619629]\n",
      "[Epoch 1/100] [Batch 153/512] [D loss: 0.39597195386886597] [G loss: 3.542304039001465]\n",
      "[Epoch 1/100] [Batch 154/512] [D loss: 1.0574640035629272] [G loss: 11.509177207946777]\n",
      "[Epoch 1/100] [Batch 155/512] [D loss: 2.7714216709136963] [G loss: 0.8507503271102905]\n",
      "[Epoch 1/100] [Batch 156/512] [D loss: 0.9776444435119629] [G loss: 6.107895851135254]\n",
      "[Epoch 1/100] [Batch 157/512] [D loss: 0.5374579429626465] [G loss: 3.3657095432281494]\n",
      "[Epoch 1/100] [Batch 158/512] [D loss: 0.7436063289642334] [G loss: 0.9039632081985474]\n",
      "[Epoch 1/100] [Batch 159/512] [D loss: 1.0969158411026] [G loss: 7.474684715270996]\n",
      "[Epoch 1/100] [Batch 160/512] [D loss: 0.1842954456806183] [G loss: 6.699587821960449]\n",
      "[Epoch 1/100] [Batch 161/512] [D loss: 0.5922653675079346] [G loss: 2.573302745819092]\n",
      "[Epoch 1/100] [Batch 162/512] [D loss: 0.7730687260627747] [G loss: 4.404748916625977]\n",
      "[Epoch 1/100] [Batch 163/512] [D loss: 0.8421733379364014] [G loss: 2.890512466430664]\n",
      "[Epoch 1/100] [Batch 164/512] [D loss: 0.472952663898468] [G loss: 2.498993396759033]\n",
      "[Epoch 1/100] [Batch 165/512] [D loss: 0.6394028067588806] [G loss: 3.720001220703125]\n",
      "[Epoch 1/100] [Batch 166/512] [D loss: 0.6624734401702881] [G loss: 2.0872273445129395]\n",
      "[Epoch 1/100] [Batch 167/512] [D loss: 0.3994123339653015] [G loss: 1.8088210821151733]\n",
      "[Epoch 1/100] [Batch 168/512] [D loss: 0.5415904521942139] [G loss: 7.387948989868164]\n",
      "[Epoch 1/100] [Batch 169/512] [D loss: 1.7667313814163208] [G loss: 0.006115172524005175]\n",
      "[Epoch 1/100] [Batch 170/512] [D loss: 2.54435396194458] [G loss: 4.910638809204102]\n",
      "[Epoch 1/100] [Batch 171/512] [D loss: 0.6089432239532471] [G loss: 4.616401195526123]\n",
      "[Epoch 1/100] [Batch 172/512] [D loss: 2.0438387393951416] [G loss: 0.24705743789672852]\n",
      "[Epoch 1/100] [Batch 173/512] [D loss: 2.8597559928894043] [G loss: 3.0086870193481445]\n",
      "[Epoch 1/100] [Batch 174/512] [D loss: 0.37559545040130615] [G loss: 3.9605371952056885]\n",
      "[Epoch 1/100] [Batch 175/512] [D loss: 1.0518426895141602] [G loss: 0.7899414300918579]\n",
      "[Epoch 1/100] [Batch 176/512] [D loss: 0.5514678955078125] [G loss: 4.551119804382324]\n",
      "[Epoch 1/100] [Batch 177/512] [D loss: 1.0782159566879272] [G loss: 0.956601619720459]\n",
      "[Epoch 1/100] [Batch 178/512] [D loss: 0.9603997468948364] [G loss: 2.0147523880004883]\n",
      "[Epoch 1/100] [Batch 179/512] [D loss: 0.6162132620811462] [G loss: 5.49958610534668]\n",
      "[Epoch 1/100] [Batch 180/512] [D loss: 0.4304841160774231] [G loss: 1.7473993301391602]\n",
      "[Epoch 1/100] [Batch 181/512] [D loss: 0.8690284490585327] [G loss: 7.88562536239624]\n",
      "[Epoch 1/100] [Batch 182/512] [D loss: 0.7301872372627258] [G loss: 0.6152881383895874]\n",
      "[Epoch 1/100] [Batch 183/512] [D loss: 2.307316780090332] [G loss: 8.759801864624023]\n",
      "[Epoch 1/100] [Batch 184/512] [D loss: 3.412436008453369] [G loss: 1.2717269659042358]\n",
      "[Epoch 1/100] [Batch 185/512] [D loss: 2.062046527862549] [G loss: 2.18816876411438]\n",
      "[Epoch 1/100] [Batch 186/512] [D loss: 0.7538821697235107] [G loss: 3.4915614128112793]\n",
      "[Epoch 1/100] [Batch 187/512] [D loss: 1.1284621953964233] [G loss: 0.9641766548156738]\n",
      "[Epoch 1/100] [Batch 188/512] [D loss: 1.0834989547729492] [G loss: 2.1286685466766357]\n",
      "[Epoch 1/100] [Batch 189/512] [D loss: 0.9341421723365784] [G loss: 1.393479347229004]\n",
      "[Epoch 1/100] [Batch 190/512] [D loss: 0.7885820269584656] [G loss: 3.2235093116760254]\n",
      "[Epoch 1/100] [Batch 191/512] [D loss: 0.9313554167747498] [G loss: 1.4197971820831299]\n",
      "[Epoch 1/100] [Batch 192/512] [D loss: 1.1647043228149414] [G loss: 2.2303380966186523]\n",
      "[Epoch 1/100] [Batch 193/512] [D loss: 0.6208590865135193] [G loss: 2.985513925552368]\n",
      "[Epoch 1/100] [Batch 194/512] [D loss: 1.2020175457000732] [G loss: 1.8392891883850098]\n",
      "[Epoch 1/100] [Batch 195/512] [D loss: 0.7888926863670349] [G loss: 2.088052749633789]\n",
      "[Epoch 1/100] [Batch 196/512] [D loss: 0.6632720828056335] [G loss: 4.202734470367432]\n",
      "[Epoch 1/100] [Batch 197/512] [D loss: 0.47445327043533325] [G loss: 1.621477723121643]\n",
      "[Epoch 1/100] [Batch 198/512] [D loss: 0.9957349300384521] [G loss: 4.852980136871338]\n",
      "[Epoch 1/100] [Batch 199/512] [D loss: 0.8942916989326477] [G loss: 1.9181169271469116]\n",
      "[Epoch 1/100] [Batch 200/512] [D loss: 1.0358976125717163] [G loss: 4.634035110473633]\n",
      "[Epoch 1/100] [Batch 201/512] [D loss: 0.7714287042617798] [G loss: 3.590498924255371]\n",
      "[Epoch 1/100] [Batch 202/512] [D loss: 0.980119526386261] [G loss: 0.4588235020637512]\n",
      "[Epoch 1/100] [Batch 203/512] [D loss: 1.7552242279052734] [G loss: 6.255115509033203]\n",
      "[Epoch 1/100] [Batch 204/512] [D loss: 1.1551618576049805] [G loss: 2.2814011573791504]\n",
      "[Epoch 1/100] [Batch 205/512] [D loss: 0.4287947714328766] [G loss: 2.7458927631378174]\n",
      "[Epoch 1/100] [Batch 206/512] [D loss: 0.7729518413543701] [G loss: 2.0134005546569824]\n",
      "[Epoch 1/100] [Batch 207/512] [D loss: 0.7902592420578003] [G loss: 4.347243309020996]\n",
      "[Epoch 1/100] [Batch 208/512] [D loss: 0.8174682259559631] [G loss: 3.345365524291992]\n",
      "[Epoch 1/100] [Batch 209/512] [D loss: 0.4166490435600281] [G loss: 1.1701650619506836]\n",
      "[Epoch 1/100] [Batch 210/512] [D loss: 0.5899434685707092] [G loss: 4.955345153808594]\n",
      "[Epoch 1/100] [Batch 211/512] [D loss: 0.36740225553512573] [G loss: 3.8870954513549805]\n",
      "[Epoch 1/100] [Batch 212/512] [D loss: 0.4058920741081238] [G loss: 1.7739733457565308]\n",
      "[Epoch 1/100] [Batch 213/512] [D loss: 0.8883945345878601] [G loss: 11.199518203735352]\n",
      "[Epoch 1/100] [Batch 214/512] [D loss: 3.886131525039673] [G loss: 1.0049138069152832]\n",
      "[Epoch 1/100] [Batch 215/512] [D loss: 0.7104670405387878] [G loss: 2.168304920196533]\n",
      "[Epoch 1/100] [Batch 216/512] [D loss: 0.6325787305831909] [G loss: 3.438713788986206]\n",
      "[Epoch 1/100] [Batch 217/512] [D loss: 0.703667163848877] [G loss: 1.045281171798706]\n",
      "[Epoch 1/100] [Batch 218/512] [D loss: 0.6190205812454224] [G loss: 4.029428005218506]\n",
      "[Epoch 1/100] [Batch 219/512] [D loss: 0.45890355110168457] [G loss: 3.286055088043213]\n",
      "[Epoch 1/100] [Batch 220/512] [D loss: 0.33725178241729736] [G loss: 1.7891125679016113]\n",
      "[Epoch 1/100] [Batch 221/512] [D loss: 0.8354578018188477] [G loss: 0.9065558910369873]\n",
      "[Epoch 1/100] [Batch 222/512] [D loss: 1.0781171321868896] [G loss: 3.3410425186157227]\n",
      "[Epoch 1/100] [Batch 223/512] [D loss: 0.250578910112381] [G loss: 4.276409149169922]\n",
      "[Epoch 1/100] [Batch 224/512] [D loss: 0.7963147759437561] [G loss: 1.5374550819396973]\n",
      "[Epoch 1/100] [Batch 225/512] [D loss: 1.2483617067337036] [G loss: 3.277365207672119]\n",
      "[Epoch 1/100] [Batch 226/512] [D loss: 0.4225369691848755] [G loss: 2.7839765548706055]\n",
      "[Epoch 1/100] [Batch 227/512] [D loss: 0.6381005048751831] [G loss: 1.4082995653152466]\n",
      "[Epoch 1/100] [Batch 228/512] [D loss: 0.6816047430038452] [G loss: 4.260691165924072]\n",
      "[Epoch 1/100] [Batch 229/512] [D loss: 0.3971365690231323] [G loss: 4.194734573364258]\n",
      "[Epoch 1/100] [Batch 230/512] [D loss: 0.3568190336227417] [G loss: 2.6250064373016357]\n",
      "[Epoch 1/100] [Batch 231/512] [D loss: 0.52031409740448] [G loss: 1.3727378845214844]\n",
      "[Epoch 1/100] [Batch 232/512] [D loss: 1.0874111652374268] [G loss: 6.657905101776123]\n",
      "[Epoch 1/100] [Batch 233/512] [D loss: 0.7581203579902649] [G loss: 2.5734634399414062]\n",
      "[Epoch 1/100] [Batch 234/512] [D loss: 0.7334430813789368] [G loss: 0.5494270920753479]\n",
      "[Epoch 1/100] [Batch 235/512] [D loss: 2.3984053134918213] [G loss: 6.918890953063965]\n",
      "[Epoch 1/100] [Batch 236/512] [D loss: 0.9260832667350769] [G loss: 3.338271141052246]\n",
      "[Epoch 1/100] [Batch 237/512] [D loss: 0.6353576183319092] [G loss: 0.7034550309181213]\n",
      "[Epoch 1/100] [Batch 238/512] [D loss: 0.47836828231811523] [G loss: 4.119169235229492]\n",
      "[Epoch 1/100] [Batch 239/512] [D loss: 0.9021833539009094] [G loss: 1.7463445663452148]\n",
      "[Epoch 1/100] [Batch 240/512] [D loss: 0.7387571334838867] [G loss: 6.240861892700195]\n",
      "[Epoch 1/100] [Batch 241/512] [D loss: 1.0860066413879395] [G loss: 1.4671356678009033]\n",
      "[Epoch 1/100] [Batch 242/512] [D loss: 0.42001110315322876] [G loss: 3.2676844596862793]\n",
      "[Epoch 1/100] [Batch 243/512] [D loss: 0.3345516324043274] [G loss: 5.1436967849731445]\n",
      "[Epoch 1/100] [Batch 244/512] [D loss: 1.1595914363861084] [G loss: 1.0317498445510864]\n",
      "[Epoch 1/100] [Batch 245/512] [D loss: 0.7512543201446533] [G loss: 4.086822986602783]\n",
      "[Epoch 1/100] [Batch 246/512] [D loss: 0.6097380518913269] [G loss: 5.526968002319336]\n",
      "[Epoch 1/100] [Batch 247/512] [D loss: 0.6853636503219604] [G loss: 0.7212048172950745]\n",
      "[Epoch 1/100] [Batch 248/512] [D loss: 1.335343360900879] [G loss: 8.949254989624023]\n",
      "[Epoch 1/100] [Batch 249/512] [D loss: 1.3781688213348389] [G loss: 0.6545549631118774]\n",
      "[Epoch 1/100] [Batch 250/512] [D loss: 1.089566707611084] [G loss: 3.9303698539733887]\n",
      "[Epoch 1/100] [Batch 251/512] [D loss: 0.4067692458629608] [G loss: 2.681396722793579]\n",
      "[Epoch 1/100] [Batch 252/512] [D loss: 0.36772510409355164] [G loss: 4.480724334716797]\n",
      "[Epoch 1/100] [Batch 253/512] [D loss: 0.5228763818740845] [G loss: 1.1418921947479248]\n",
      "[Epoch 1/100] [Batch 254/512] [D loss: 0.7048908472061157] [G loss: 7.380003929138184]\n",
      "[Epoch 1/100] [Batch 255/512] [D loss: 1.3828647136688232] [G loss: 0.1308879405260086]\n",
      "[Epoch 1/100] [Batch 256/512] [D loss: 1.6306581497192383] [G loss: 7.552803039550781]\n",
      "[Epoch 1/100] [Batch 257/512] [D loss: 1.3665648698806763] [G loss: 0.4370775818824768]\n",
      "[Epoch 1/100] [Batch 258/512] [D loss: 1.5703964233398438] [G loss: 9.119905471801758]\n",
      "[Epoch 1/100] [Batch 259/512] [D loss: 1.1260948181152344] [G loss: 1.5221164226531982]\n",
      "[Epoch 1/100] [Batch 260/512] [D loss: 0.8809722661972046] [G loss: 4.662672519683838]\n",
      "[Epoch 1/100] [Batch 261/512] [D loss: 0.7742840051651001] [G loss: 0.9364392757415771]\n",
      "[Epoch 1/100] [Batch 262/512] [D loss: 0.9491317868232727] [G loss: 6.403005123138428]\n",
      "[Epoch 1/100] [Batch 263/512] [D loss: 1.2413808107376099] [G loss: 0.579293429851532]\n",
      "[Epoch 1/100] [Batch 264/512] [D loss: 1.1028600931167603] [G loss: 5.838247299194336]\n",
      "[Epoch 1/100] [Batch 265/512] [D loss: 0.3690173327922821] [G loss: 4.62753438949585]\n",
      "[Epoch 1/100] [Batch 266/512] [D loss: 0.520802915096283] [G loss: 2.5266594886779785]\n",
      "[Epoch 1/100] [Batch 267/512] [D loss: 0.894474983215332] [G loss: 4.8717942237854]\n",
      "[Epoch 1/100] [Batch 268/512] [D loss: 0.486770361661911] [G loss: 2.964235782623291]\n",
      "[Epoch 1/100] [Batch 269/512] [D loss: 0.48117661476135254] [G loss: 2.554868698120117]\n",
      "[Epoch 1/100] [Batch 270/512] [D loss: 0.3344348669052124] [G loss: 2.7406935691833496]\n",
      "[Epoch 1/100] [Batch 271/512] [D loss: 0.13202957808971405] [G loss: 3.3471391201019287]\n",
      "[Epoch 1/100] [Batch 272/512] [D loss: 0.2855421304702759] [G loss: 3.548502206802368]\n",
      "[Epoch 1/100] [Batch 273/512] [D loss: 0.13568015396595] [G loss: 3.716413736343384]\n",
      "[Epoch 1/100] [Batch 274/512] [D loss: 0.13284973800182343] [G loss: 3.73836088180542]\n",
      "[Epoch 1/100] [Batch 275/512] [D loss: 0.1571887731552124] [G loss: 5.056867599487305]\n",
      "[Epoch 1/100] [Batch 276/512] [D loss: 0.14033876359462738] [G loss: 3.6704649925231934]\n",
      "[Epoch 1/100] [Batch 277/512] [D loss: 0.07272617518901825] [G loss: 2.896688461303711]\n",
      "[Epoch 1/100] [Batch 278/512] [D loss: 0.06778363138437271] [G loss: 5.481398105621338]\n",
      "[Epoch 1/100] [Batch 279/512] [D loss: 0.05972012132406235] [G loss: 5.537733554840088]\n",
      "[Epoch 1/100] [Batch 280/512] [D loss: 0.17124952375888824] [G loss: 2.0933566093444824]\n",
      "[Epoch 1/100] [Batch 281/512] [D loss: 0.5766010880470276] [G loss: 12.670547485351562]\n",
      "[Epoch 1/100] [Batch 282/512] [D loss: 2.4110639095306396] [G loss: 0.23759455978870392]\n",
      "[Epoch 1/100] [Batch 283/512] [D loss: 1.9534327983856201] [G loss: 5.506802558898926]\n",
      "[Epoch 1/100] [Batch 284/512] [D loss: 0.6701772809028625] [G loss: 1.9278620481491089]\n",
      "[Epoch 1/100] [Batch 285/512] [D loss: 0.5969690680503845] [G loss: 3.9367618560791016]\n",
      "[Epoch 1/100] [Batch 286/512] [D loss: 0.23668172955513] [G loss: 4.043117523193359]\n",
      "[Epoch 1/100] [Batch 287/512] [D loss: 0.32861319184303284] [G loss: 1.6009232997894287]\n",
      "[Epoch 1/100] [Batch 288/512] [D loss: 0.6404514312744141] [G loss: 7.48079776763916]\n",
      "[Epoch 1/100] [Batch 289/512] [D loss: 0.46742355823516846] [G loss: 2.2877185344696045]\n",
      "[Epoch 1/100] [Batch 290/512] [D loss: 0.3486640751361847] [G loss: 3.6477365493774414]\n",
      "[Epoch 1/100] [Batch 291/512] [D loss: 0.14241938292980194] [G loss: 4.723747730255127]\n",
      "[Epoch 1/100] [Batch 292/512] [D loss: 0.12994059920310974] [G loss: 3.5894615650177]\n",
      "[Epoch 1/100] [Batch 293/512] [D loss: 0.3275761902332306] [G loss: 6.145971298217773]\n",
      "[Epoch 1/100] [Batch 294/512] [D loss: 0.3867996335029602] [G loss: 2.8171772956848145]\n",
      "[Epoch 1/100] [Batch 295/512] [D loss: 0.4547344744205475] [G loss: 6.828052520751953]\n",
      "[Epoch 1/100] [Batch 296/512] [D loss: 0.1812705397605896] [G loss: 5.195916175842285]\n",
      "[Epoch 1/100] [Batch 297/512] [D loss: 0.31453144550323486] [G loss: 2.6348698139190674]\n",
      "[Epoch 1/100] [Batch 298/512] [D loss: 0.4129914343357086] [G loss: 9.532327651977539]\n",
      "[Epoch 1/100] [Batch 299/512] [D loss: 0.5847311019897461] [G loss: 0.7489220499992371]\n",
      "[Epoch 1/100] [Batch 300/512] [D loss: 1.075875163078308] [G loss: 15.17303466796875]\n",
      "[Epoch 1/100] [Batch 301/512] [D loss: 1.4638272523880005] [G loss: 0.5892037153244019]\n",
      "[Epoch 1/100] [Batch 302/512] [D loss: 1.8969159126281738] [G loss: 11.940065383911133]\n",
      "[Epoch 1/100] [Batch 303/512] [D loss: 2.2744102478027344] [G loss: 0.9011553525924683]\n",
      "[Epoch 1/100] [Batch 304/512] [D loss: 1.5305598974227905] [G loss: 4.011549949645996]\n",
      "[Epoch 1/100] [Batch 305/512] [D loss: 0.38373705744743347] [G loss: 2.88775897026062]\n",
      "[Epoch 1/100] [Batch 306/512] [D loss: 0.3380965292453766] [G loss: 2.498149871826172]\n",
      "[Epoch 1/100] [Batch 307/512] [D loss: 0.4507477581501007] [G loss: 3.004667043685913]\n",
      "[Epoch 1/100] [Batch 308/512] [D loss: 0.2165287435054779] [G loss: 4.891593933105469]\n",
      "[Epoch 1/100] [Batch 309/512] [D loss: 0.2588581144809723] [G loss: 5.806130886077881]\n",
      "[Epoch 1/100] [Batch 310/512] [D loss: 0.2167169749736786] [G loss: 3.313910484313965]\n",
      "[Epoch 1/100] [Batch 311/512] [D loss: 0.3827744722366333] [G loss: 2.2094202041625977]\n",
      "[Epoch 1/100] [Batch 312/512] [D loss: 0.5725191831588745] [G loss: 9.071151733398438]\n",
      "[Epoch 1/100] [Batch 313/512] [D loss: 1.7891656160354614] [G loss: 0.25045570731163025]\n",
      "[Epoch 1/100] [Batch 314/512] [D loss: 1.015060305595398] [G loss: 7.919514179229736]\n",
      "[Epoch 1/100] [Batch 315/512] [D loss: 0.8965834975242615] [G loss: 1.167952537536621]\n",
      "[Epoch 1/100] [Batch 316/512] [D loss: 0.3057466447353363] [G loss: 4.315513610839844]\n",
      "[Epoch 1/100] [Batch 317/512] [D loss: 0.31115055084228516] [G loss: 6.665745735168457]\n",
      "[Epoch 1/100] [Batch 318/512] [D loss: 1.7137876749038696] [G loss: 0.2179889976978302]\n",
      "[Epoch 1/100] [Batch 319/512] [D loss: 2.477248191833496] [G loss: 6.592775821685791]\n",
      "[Epoch 1/100] [Batch 320/512] [D loss: 0.5881097316741943] [G loss: 4.304576873779297]\n",
      "[Epoch 1/100] [Batch 321/512] [D loss: 0.7611727714538574] [G loss: 2.642895221710205]\n",
      "[Epoch 1/100] [Batch 322/512] [D loss: 0.5689857006072998] [G loss: 4.19498348236084]\n",
      "[Epoch 1/100] [Batch 323/512] [D loss: 0.35856860876083374] [G loss: 1.5270750522613525]\n",
      "[Epoch 1/100] [Batch 324/512] [D loss: 0.6123639941215515] [G loss: 7.296184539794922]\n",
      "[Epoch 1/100] [Batch 325/512] [D loss: 0.43775415420532227] [G loss: 2.022914409637451]\n",
      "[Epoch 1/100] [Batch 326/512] [D loss: 0.25534918904304504] [G loss: 3.6345016956329346]\n",
      "[Epoch 1/100] [Batch 327/512] [D loss: 0.5293574929237366] [G loss: 5.120853900909424]\n",
      "[Epoch 1/100] [Batch 328/512] [D loss: 0.7597185373306274] [G loss: 0.9356387257575989]\n",
      "[Epoch 1/100] [Batch 329/512] [D loss: 1.0619670152664185] [G loss: 10.085601806640625]\n",
      "[Epoch 1/100] [Batch 330/512] [D loss: 0.4987770915031433] [G loss: 5.012187480926514]\n",
      "[Epoch 1/100] [Batch 331/512] [D loss: 0.1397724598646164] [G loss: 3.213235855102539]\n",
      "[Epoch 1/100] [Batch 332/512] [D loss: 0.36943256855010986] [G loss: 4.955645561218262]\n",
      "[Epoch 1/100] [Batch 333/512] [D loss: 0.6272574663162231] [G loss: 7.141217231750488]\n",
      "[Epoch 1/100] [Batch 334/512] [D loss: 0.39764583110809326] [G loss: 4.6204118728637695]\n",
      "[Epoch 1/100] [Batch 335/512] [D loss: 0.7330882549285889] [G loss: 1.9448630809783936]\n",
      "[Epoch 1/100] [Batch 336/512] [D loss: 0.44017380475997925] [G loss: 11.169254302978516]\n",
      "[Epoch 1/100] [Batch 337/512] [D loss: 1.3172574043273926] [G loss: 0.5502233505249023]\n",
      "[Epoch 1/100] [Batch 338/512] [D loss: 1.4847790002822876] [G loss: 11.922819137573242]\n",
      "[Epoch 1/100] [Batch 339/512] [D loss: 2.2062602043151855] [G loss: 1.7898285388946533]\n",
      "[Epoch 1/100] [Batch 340/512] [D loss: 0.8934212327003479] [G loss: 6.547841548919678]\n",
      "[Epoch 1/100] [Batch 341/512] [D loss: 0.4935322105884552] [G loss: 3.539885997772217]\n",
      "[Epoch 1/100] [Batch 342/512] [D loss: 0.813642144203186] [G loss: 7.216675758361816]\n",
      "[Epoch 1/100] [Batch 343/512] [D loss: 0.5609506964683533] [G loss: 1.6199021339416504]\n",
      "[Epoch 1/100] [Batch 344/512] [D loss: 0.8854471445083618] [G loss: 10.718172073364258]\n",
      "[Epoch 1/100] [Batch 345/512] [D loss: 1.6508740186691284] [G loss: 0.264460027217865]\n",
      "[Epoch 1/100] [Batch 346/512] [D loss: 1.5591586828231812] [G loss: 6.4756340980529785]\n",
      "[Epoch 1/100] [Batch 347/512] [D loss: 0.5617516040802002] [G loss: 2.334601879119873]\n",
      "[Epoch 1/100] [Batch 348/512] [D loss: 0.4438372850418091] [G loss: 6.249548435211182]\n",
      "[Epoch 1/100] [Batch 349/512] [D loss: 0.3611385226249695] [G loss: 7.256958961486816]\n",
      "[Epoch 1/100] [Batch 350/512] [D loss: 1.0073657035827637] [G loss: 1.253960371017456]\n",
      "[Epoch 1/100] [Batch 351/512] [D loss: 0.5822575688362122] [G loss: 6.4149041175842285]\n",
      "[Epoch 1/100] [Batch 352/512] [D loss: 0.7420721650123596] [G loss: 3.8456814289093018]\n",
      "[Epoch 1/100] [Batch 353/512] [D loss: 1.08015775680542] [G loss: 7.360839366912842]\n",
      "[Epoch 1/100] [Batch 354/512] [D loss: 1.0991045236587524] [G loss: 2.149824380874634]\n",
      "[Epoch 1/100] [Batch 355/512] [D loss: 1.214306354522705] [G loss: 4.892058372497559]\n",
      "[Epoch 1/100] [Batch 356/512] [D loss: 0.9559417963027954] [G loss: 0.9488025307655334]\n",
      "[Epoch 1/100] [Batch 357/512] [D loss: 1.491496205329895] [G loss: 10.071053504943848]\n",
      "[Epoch 1/100] [Batch 358/512] [D loss: 1.8841552734375] [G loss: 2.7697079181671143]\n",
      "[Epoch 1/100] [Batch 359/512] [D loss: 0.7063064575195312] [G loss: 5.091581344604492]\n",
      "[Epoch 1/100] [Batch 360/512] [D loss: 0.26903295516967773] [G loss: 5.724183082580566]\n",
      "[Epoch 1/100] [Batch 361/512] [D loss: 0.33177945017814636] [G loss: 1.964461088180542]\n",
      "[Epoch 1/100] [Batch 362/512] [D loss: 0.7288017272949219] [G loss: 6.071800231933594]\n",
      "[Epoch 1/100] [Batch 363/512] [D loss: 1.0342721939086914] [G loss: 0.5731552839279175]\n",
      "[Epoch 1/100] [Batch 364/512] [D loss: 1.9136372804641724] [G loss: 10.619925498962402]\n",
      "[Epoch 1/100] [Batch 365/512] [D loss: 1.7741187810897827] [G loss: 2.539289712905884]\n",
      "[Epoch 1/100] [Batch 366/512] [D loss: 0.632911741733551] [G loss: 4.843487739562988]\n",
      "[Epoch 1/100] [Batch 367/512] [D loss: 0.4056587219238281] [G loss: 4.210912704467773]\n",
      "[Epoch 1/100] [Batch 368/512] [D loss: 0.540861189365387] [G loss: 6.682092666625977]\n",
      "[Epoch 1/100] [Batch 369/512] [D loss: 1.497684359550476] [G loss: 0.6028366684913635]\n",
      "[Epoch 1/100] [Batch 370/512] [D loss: 1.6382278203964233] [G loss: 7.57891845703125]\n",
      "[Epoch 1/100] [Batch 371/512] [D loss: 1.222428798675537] [G loss: 3.0634210109710693]\n",
      "[Epoch 1/100] [Batch 372/512] [D loss: 0.4550301432609558] [G loss: 2.2870569229125977]\n",
      "[Epoch 1/100] [Batch 373/512] [D loss: 0.4009842574596405] [G loss: 5.17677116394043]\n",
      "[Epoch 1/100] [Batch 374/512] [D loss: 0.23978102207183838] [G loss: 4.616406440734863]\n",
      "[Epoch 1/100] [Batch 375/512] [D loss: 0.4042155146598816] [G loss: 3.9470436573028564]\n",
      "[Epoch 1/100] [Batch 376/512] [D loss: 0.3390616476535797] [G loss: 5.983245372772217]\n",
      "[Epoch 1/100] [Batch 377/512] [D loss: 0.1904984414577484] [G loss: 5.0530805587768555]\n",
      "[Epoch 1/100] [Batch 378/512] [D loss: 0.12883803248405457] [G loss: 4.354990005493164]\n",
      "[Epoch 1/100] [Batch 379/512] [D loss: 0.15228362381458282] [G loss: 5.277523040771484]\n",
      "[Epoch 1/100] [Batch 380/512] [D loss: 0.2167075276374817] [G loss: 5.377819538116455]\n",
      "[Epoch 1/100] [Batch 381/512] [D loss: 0.08436287939548492] [G loss: 4.878220558166504]\n",
      "[Epoch 1/100] [Batch 382/512] [D loss: 0.3366042673587799] [G loss: 3.7660775184631348]\n",
      "[Epoch 1/100] [Batch 383/512] [D loss: 0.37583306431770325] [G loss: 7.539898872375488]\n",
      "[Epoch 1/100] [Batch 384/512] [D loss: 0.5549775958061218] [G loss: 0.7088662981987]\n",
      "[Epoch 1/100] [Batch 385/512] [D loss: 1.4641340970993042] [G loss: 12.410503387451172]\n",
      "[Epoch 1/100] [Batch 386/512] [D loss: 1.5431512594223022] [G loss: 3.030177116394043]\n",
      "[Epoch 1/100] [Batch 387/512] [D loss: 0.825790524482727] [G loss: 9.883932113647461]\n",
      "[Epoch 1/100] [Batch 388/512] [D loss: 1.1347553730010986] [G loss: 1.438938021659851]\n",
      "[Epoch 1/100] [Batch 389/512] [D loss: 1.0692716836929321] [G loss: 7.8782453536987305]\n",
      "[Epoch 1/100] [Batch 390/512] [D loss: 0.5213204026222229] [G loss: 3.402796506881714]\n",
      "[Epoch 1/100] [Batch 391/512] [D loss: 0.1687416434288025] [G loss: 4.687633037567139]\n",
      "[Epoch 1/100] [Batch 392/512] [D loss: 0.35044044256210327] [G loss: 5.599855899810791]\n",
      "[Epoch 1/100] [Batch 393/512] [D loss: 0.6318677663803101] [G loss: 0.9574652910232544]\n",
      "[Epoch 1/100] [Batch 394/512] [D loss: 1.3516991138458252] [G loss: 7.992778778076172]\n",
      "[Epoch 1/100] [Batch 395/512] [D loss: 0.8371081948280334] [G loss: 2.642758369445801]\n",
      "[Epoch 1/100] [Batch 396/512] [D loss: 1.0193581581115723] [G loss: 4.336379528045654]\n",
      "[Epoch 1/100] [Batch 397/512] [D loss: 0.20296306908130646] [G loss: 3.750736713409424]\n",
      "[Epoch 1/100] [Batch 398/512] [D loss: 0.4491267204284668] [G loss: 1.4461947679519653]\n",
      "[Epoch 1/100] [Batch 399/512] [D loss: 0.8553982973098755] [G loss: 9.992446899414062]\n",
      "[Epoch 1/100] [Batch 400/512] [D loss: 1.8690440654754639] [G loss: 0.753698468208313]\n",
      "[Epoch 1/100] [Batch 401/512] [D loss: 0.899307370185852] [G loss: 8.214702606201172]\n",
      "[Epoch 1/100] [Batch 402/512] [D loss: 0.857396125793457] [G loss: 2.0806097984313965]\n",
      "[Epoch 1/100] [Batch 403/512] [D loss: 1.4669982194900513] [G loss: 7.151096343994141]\n",
      "[Epoch 1/100] [Batch 404/512] [D loss: 1.119314432144165] [G loss: 2.913947582244873]\n",
      "[Epoch 1/100] [Batch 405/512] [D loss: 0.49495893716812134] [G loss: 4.312071800231934]\n",
      "[Epoch 1/100] [Batch 406/512] [D loss: 0.6282123923301697] [G loss: 1.9296746253967285]\n",
      "[Epoch 1/100] [Batch 407/512] [D loss: 0.33040452003479004] [G loss: 4.562626838684082]\n",
      "[Epoch 1/100] [Batch 408/512] [D loss: 0.3066558241844177] [G loss: 6.766630172729492]\n",
      "[Epoch 1/100] [Batch 409/512] [D loss: 0.7665854096412659] [G loss: 1.372801661491394]\n",
      "[Epoch 1/100] [Batch 410/512] [D loss: 0.45489299297332764] [G loss: 5.433279037475586]\n",
      "[Epoch 1/100] [Batch 411/512] [D loss: 0.4532063901424408] [G loss: 7.203229904174805]\n",
      "[Epoch 1/100] [Batch 412/512] [D loss: 1.2974203824996948] [G loss: 0.3532382845878601]\n",
      "[Epoch 1/100] [Batch 413/512] [D loss: 2.6188175678253174] [G loss: 5.377164840698242]\n",
      "[Epoch 1/100] [Batch 414/512] [D loss: 1.0393261909484863] [G loss: 1.5492987632751465]\n",
      "[Epoch 1/100] [Batch 415/512] [D loss: 0.7245566844940186] [G loss: 4.78271484375]\n",
      "[Epoch 1/100] [Batch 416/512] [D loss: 1.388289213180542] [G loss: 1.0222889184951782]\n",
      "[Epoch 1/100] [Batch 417/512] [D loss: 0.5596343278884888] [G loss: 4.160519599914551]\n",
      "[Epoch 1/100] [Batch 418/512] [D loss: 0.6366198062896729] [G loss: 4.071408748626709]\n",
      "[Epoch 1/100] [Batch 419/512] [D loss: 1.0024718046188354] [G loss: 0.8041633367538452]\n",
      "[Epoch 1/100] [Batch 420/512] [D loss: 1.0604604482650757] [G loss: 5.28688383102417]\n",
      "[Epoch 1/100] [Batch 421/512] [D loss: 0.6865005493164062] [G loss: 1.5804609060287476]\n",
      "[Epoch 1/100] [Batch 422/512] [D loss: 0.44079431891441345] [G loss: 3.596355676651001]\n",
      "[Epoch 1/100] [Batch 423/512] [D loss: 0.4421354830265045] [G loss: 4.034246444702148]\n",
      "[Epoch 1/100] [Batch 424/512] [D loss: 0.24446961283683777] [G loss: 3.23991060256958]\n",
      "[Epoch 1/100] [Batch 425/512] [D loss: 0.2752833962440491] [G loss: 1.9242510795593262]\n",
      "[Epoch 1/100] [Batch 426/512] [D loss: 0.5878430604934692] [G loss: 2.2525460720062256]\n",
      "[Epoch 1/100] [Batch 427/512] [D loss: 0.9158161878585815] [G loss: 6.163609981536865]\n",
      "[Epoch 1/100] [Batch 428/512] [D loss: 1.3192933797836304] [G loss: 0.7289224863052368]\n",
      "[Epoch 1/100] [Batch 429/512] [D loss: 1.2774009704589844] [G loss: 4.4131550788879395]\n",
      "[Epoch 1/100] [Batch 430/512] [D loss: 0.25377157330513] [G loss: 3.928292751312256]\n",
      "[Epoch 1/100] [Batch 431/512] [D loss: 0.6263907551765442] [G loss: 1.6940195560455322]\n",
      "[Epoch 1/100] [Batch 432/512] [D loss: 0.3458365201950073] [G loss: 3.1821422576904297]\n",
      "[Epoch 1/100] [Batch 433/512] [D loss: 0.8282269239425659] [G loss: 1.8583149909973145]\n",
      "[Epoch 1/100] [Batch 434/512] [D loss: 0.5336888432502747] [G loss: 4.790514945983887]\n",
      "[Epoch 1/100] [Batch 435/512] [D loss: 0.5719641447067261] [G loss: 2.560791015625]\n",
      "[Epoch 1/100] [Batch 436/512] [D loss: 0.6027065515518188] [G loss: 5.9127960205078125]\n",
      "[Epoch 1/100] [Batch 437/512] [D loss: 0.8438569903373718] [G loss: 0.3287721574306488]\n",
      "[Epoch 1/100] [Batch 438/512] [D loss: 1.4146666526794434] [G loss: 3.922025680541992]\n",
      "[Epoch 1/100] [Batch 439/512] [D loss: 0.3959764838218689] [G loss: 3.926988124847412]\n",
      "[Epoch 1/100] [Batch 440/512] [D loss: 0.5116691589355469] [G loss: 3.629725456237793]\n",
      "[Epoch 1/100] [Batch 441/512] [D loss: 0.39110130071640015] [G loss: 2.146883487701416]\n",
      "[Epoch 1/100] [Batch 442/512] [D loss: 0.6267149448394775] [G loss: 5.1329264640808105]\n",
      "[Epoch 1/100] [Batch 443/512] [D loss: 0.6788678169250488] [G loss: 1.5514923334121704]\n",
      "[Epoch 1/100] [Batch 444/512] [D loss: 0.7205101251602173] [G loss: 6.758408069610596]\n",
      "[Epoch 1/100] [Batch 445/512] [D loss: 2.148742437362671] [G loss: 0.21760499477386475]\n",
      "[Epoch 1/100] [Batch 446/512] [D loss: 1.7032228708267212] [G loss: 6.065381050109863]\n",
      "[Epoch 1/100] [Batch 447/512] [D loss: 0.8051918148994446] [G loss: 2.7293500900268555]\n",
      "[Epoch 1/100] [Batch 448/512] [D loss: 0.5320053100585938] [G loss: 1.7794528007507324]\n",
      "[Epoch 1/100] [Batch 449/512] [D loss: 0.6805610656738281] [G loss: 4.480790615081787]\n",
      "[Epoch 1/100] [Batch 450/512] [D loss: 0.6998703479766846] [G loss: 1.4806249141693115]\n",
      "[Epoch 1/100] [Batch 451/512] [D loss: 0.5020365715026855] [G loss: 4.554510593414307]\n",
      "[Epoch 1/100] [Batch 452/512] [D loss: 0.6586529016494751] [G loss: 2.6176071166992188]\n",
      "[Epoch 1/100] [Batch 453/512] [D loss: 1.009346842765808] [G loss: 1.45515775680542]\n",
      "[Epoch 1/100] [Batch 454/512] [D loss: 0.7425144910812378] [G loss: 4.598066329956055]\n",
      "[Epoch 1/100] [Batch 455/512] [D loss: 0.462867796421051] [G loss: 0.9152119159698486]\n",
      "[Epoch 1/100] [Batch 456/512] [D loss: 1.156079888343811] [G loss: 7.461755752563477]\n",
      "[Epoch 1/100] [Batch 457/512] [D loss: 1.8266336917877197] [G loss: 1.234253168106079]\n",
      "[Epoch 1/100] [Batch 458/512] [D loss: 0.6089625358581543] [G loss: 2.5426695346832275]\n",
      "[Epoch 1/100] [Batch 459/512] [D loss: 0.35729312896728516] [G loss: 3.2262911796569824]\n",
      "[Epoch 1/100] [Batch 460/512] [D loss: 0.43487483263015747] [G loss: 3.0048322677612305]\n",
      "[Epoch 1/100] [Batch 461/512] [D loss: 0.41574472188949585] [G loss: 4.808372974395752]\n",
      "[Epoch 1/100] [Batch 462/512] [D loss: 0.49435535073280334] [G loss: 1.1295901536941528]\n",
      "[Epoch 1/100] [Batch 463/512] [D loss: 1.0879147052764893] [G loss: 4.316998481750488]\n",
      "[Epoch 1/100] [Batch 464/512] [D loss: 0.8880161046981812] [G loss: 0.41065019369125366]\n",
      "[Epoch 1/100] [Batch 465/512] [D loss: 0.8562426567077637] [G loss: 6.966284275054932]\n",
      "[Epoch 1/100] [Batch 466/512] [D loss: 1.3741708993911743] [G loss: 0.3275587260723114]\n",
      "[Epoch 1/100] [Batch 467/512] [D loss: 1.288957118988037] [G loss: 6.0773820877075195]\n",
      "[Epoch 1/100] [Batch 468/512] [D loss: 0.5194190144538879] [G loss: 2.6983768939971924]\n",
      "[Epoch 1/100] [Batch 469/512] [D loss: 0.28210628032684326] [G loss: 1.7240691184997559]\n",
      "[Epoch 1/100] [Batch 470/512] [D loss: 0.5869285464286804] [G loss: 6.765787124633789]\n",
      "[Epoch 1/100] [Batch 471/512] [D loss: 0.8367014527320862] [G loss: 0.927666187286377]\n",
      "[Epoch 1/100] [Batch 472/512] [D loss: 0.8193923830986023] [G loss: 6.933769702911377]\n",
      "[Epoch 1/100] [Batch 473/512] [D loss: 0.6850090622901917] [G loss: 1.893831729888916]\n",
      "[Epoch 1/100] [Batch 474/512] [D loss: 0.45405513048171997] [G loss: 4.791836738586426]\n",
      "[Epoch 1/100] [Batch 475/512] [D loss: 0.7292740345001221] [G loss: 1.983046531677246]\n",
      "[Epoch 1/100] [Batch 476/512] [D loss: 0.9213565587997437] [G loss: 4.73425817489624]\n",
      "[Epoch 1/100] [Batch 477/512] [D loss: 0.18575060367584229] [G loss: 2.909842014312744]\n",
      "[Epoch 1/100] [Batch 478/512] [D loss: 0.6231144070625305] [G loss: 11.593791007995605]\n",
      "[Epoch 1/100] [Batch 479/512] [D loss: 1.8423614501953125] [G loss: 0.39609745144844055]\n",
      "[Epoch 1/100] [Batch 480/512] [D loss: 2.0223581790924072] [G loss: 8.720843315124512]\n",
      "[Epoch 1/100] [Batch 481/512] [D loss: 1.0794715881347656] [G loss: 0.5707924365997314]\n",
      "[Epoch 1/100] [Batch 482/512] [D loss: 0.6795233488082886] [G loss: 4.6253252029418945]\n",
      "[Epoch 1/100] [Batch 483/512] [D loss: 0.2898547649383545] [G loss: 2.9668169021606445]\n",
      "[Epoch 1/100] [Batch 484/512] [D loss: 0.5404866933822632] [G loss: 3.348142623901367]\n",
      "[Epoch 1/100] [Batch 485/512] [D loss: 0.7878752946853638] [G loss: 0.8183876276016235]\n",
      "[Epoch 1/100] [Batch 486/512] [D loss: 0.7101839184761047] [G loss: 4.740244388580322]\n",
      "[Epoch 1/100] [Batch 487/512] [D loss: 0.2524785101413727] [G loss: 4.400086402893066]\n",
      "[Epoch 1/100] [Batch 488/512] [D loss: 0.2779577672481537] [G loss: 1.8812144994735718]\n",
      "[Epoch 1/100] [Batch 489/512] [D loss: 0.39700955152511597] [G loss: 3.297489643096924]\n",
      "[Epoch 1/100] [Batch 490/512] [D loss: 0.36530375480651855] [G loss: 2.993814706802368]\n",
      "[Epoch 1/100] [Batch 491/512] [D loss: 0.316386342048645] [G loss: 2.6759517192840576]\n",
      "[Epoch 1/100] [Batch 492/512] [D loss: 0.16272351145744324] [G loss: 3.1814475059509277]\n",
      "[Epoch 1/100] [Batch 493/512] [D loss: 0.3427574038505554] [G loss: 3.857259750366211]\n",
      "[Epoch 1/100] [Batch 494/512] [D loss: 0.09311232715845108] [G loss: 3.9573733806610107]\n",
      "[Epoch 1/100] [Batch 495/512] [D loss: 0.18675947189331055] [G loss: 4.814389705657959]\n",
      "[Epoch 1/100] [Batch 496/512] [D loss: 0.26759910583496094] [G loss: 3.9491090774536133]\n",
      "[Epoch 1/100] [Batch 497/512] [D loss: 0.21963772177696228] [G loss: 4.278800964355469]\n",
      "[Epoch 1/100] [Batch 498/512] [D loss: 0.18432492017745972] [G loss: 6.135150909423828]\n",
      "[Epoch 1/100] [Batch 499/512] [D loss: 0.37025153636932373] [G loss: 0.7364224791526794]\n",
      "[Epoch 1/100] [Batch 500/512] [D loss: 1.4013009071350098] [G loss: 13.644092559814453]\n",
      "[Epoch 1/100] [Batch 501/512] [D loss: 3.0620310306549072] [G loss: 0.9095112085342407]\n",
      "[Epoch 1/100] [Batch 502/512] [D loss: 0.48632094264030457] [G loss: 1.6323930025100708]\n",
      "[Epoch 1/100] [Batch 503/512] [D loss: 1.1405457258224487] [G loss: 5.244685173034668]\n",
      "[Epoch 1/100] [Batch 504/512] [D loss: 1.182745099067688] [G loss: 1.6693518161773682]\n",
      "[Epoch 1/100] [Batch 505/512] [D loss: 0.6409335732460022] [G loss: 1.2424488067626953]\n",
      "[Epoch 1/100] [Batch 506/512] [D loss: 0.8338513374328613] [G loss: 5.187252998352051]\n",
      "[Epoch 1/100] [Batch 507/512] [D loss: 0.6494520902633667] [G loss: 3.263274669647217]\n",
      "[Epoch 1/100] [Batch 508/512] [D loss: 0.6132875680923462] [G loss: 1.6342017650604248]\n",
      "[Epoch 1/100] [Batch 509/512] [D loss: 0.6015316247940063] [G loss: 2.646765947341919]\n",
      "[Epoch 1/100] [Batch 510/512] [D loss: 0.32406437397003174] [G loss: 3.6911275386810303]\n",
      "[Epoch 1/100] [Batch 511/512] [D loss: 0.7922238707542419] [G loss: 1.3451186418533325]\n",
      "[Epoch 2/100] [Batch 0/512] [D loss: 0.5023040771484375] [G loss: 4.3500285148620605]\n",
      "[Epoch 2/100] [Batch 1/512] [D loss: 0.6743396520614624] [G loss: 1.5693817138671875]\n",
      "[Epoch 2/100] [Batch 2/512] [D loss: 0.5196223258972168] [G loss: 5.999373435974121]\n",
      "[Epoch 2/100] [Batch 3/512] [D loss: 0.6604501605033875] [G loss: 1.7806776762008667]\n",
      "[Epoch 2/100] [Batch 4/512] [D loss: 0.7854102253913879] [G loss: 4.612448692321777]\n",
      "[Epoch 2/100] [Batch 5/512] [D loss: 0.3161053955554962] [G loss: 3.644605875015259]\n",
      "[Epoch 2/100] [Batch 6/512] [D loss: 0.725384533405304] [G loss: 0.36107802391052246]\n",
      "[Epoch 2/100] [Batch 7/512] [D loss: 1.0687018632888794] [G loss: 7.167473793029785]\n",
      "[Epoch 2/100] [Batch 8/512] [D loss: 0.921484649181366] [G loss: 1.1830177307128906]\n",
      "[Epoch 2/100] [Batch 9/512] [D loss: 0.5904721617698669] [G loss: 4.788928031921387]\n",
      "[Epoch 2/100] [Batch 10/512] [D loss: 0.39282554388046265] [G loss: 2.9490556716918945]\n",
      "[Epoch 2/100] [Batch 11/512] [D loss: 0.23824605345726013] [G loss: 3.4959158897399902]\n",
      "[Epoch 2/100] [Batch 12/512] [D loss: 0.5656658411026001] [G loss: 3.2157504558563232]\n",
      "[Epoch 2/100] [Batch 13/512] [D loss: 0.24334663152694702] [G loss: 7.1033525466918945]\n",
      "[Epoch 2/100] [Batch 14/512] [D loss: 0.3649788498878479] [G loss: 1.514653205871582]\n",
      "[Epoch 2/100] [Batch 15/512] [D loss: 1.0609526634216309] [G loss: 11.603666305541992]\n",
      "[Epoch 2/100] [Batch 16/512] [D loss: 1.4494019746780396] [G loss: 0.43129420280456543]\n",
      "[Epoch 2/100] [Batch 17/512] [D loss: 1.1497042179107666] [G loss: 6.047249794006348]\n",
      "[Epoch 2/100] [Batch 18/512] [D loss: 0.9457166194915771] [G loss: 1.6292760372161865]\n",
      "[Epoch 2/100] [Batch 19/512] [D loss: 0.7266205549240112] [G loss: 7.554564952850342]\n",
      "[Epoch 2/100] [Batch 20/512] [D loss: 0.6583981513977051] [G loss: 2.634932041168213]\n",
      "[Epoch 2/100] [Batch 21/512] [D loss: 0.6475365161895752] [G loss: 1.97452974319458]\n",
      "[Epoch 2/100] [Batch 22/512] [D loss: 0.8923726677894592] [G loss: 3.9440078735351562]\n",
      "[Epoch 2/100] [Batch 23/512] [D loss: 1.1662178039550781] [G loss: 0.2596682906150818]\n",
      "[Epoch 2/100] [Batch 24/512] [D loss: 1.0920076370239258] [G loss: 5.823398113250732]\n",
      "[Epoch 2/100] [Batch 25/512] [D loss: 0.8367451429367065] [G loss: 1.1795809268951416]\n",
      "[Epoch 2/100] [Batch 26/512] [D loss: 0.49655675888061523] [G loss: 3.8528897762298584]\n",
      "[Epoch 2/100] [Batch 27/512] [D loss: 0.29868292808532715] [G loss: 3.5759308338165283]\n",
      "[Epoch 2/100] [Batch 28/512] [D loss: 0.4822668731212616] [G loss: 1.067225456237793]\n",
      "[Epoch 2/100] [Batch 29/512] [D loss: 0.6477880477905273] [G loss: 6.089019298553467]\n",
      "[Epoch 2/100] [Batch 30/512] [D loss: 0.8653749823570251] [G loss: 1.302505373954773]\n",
      "[Epoch 2/100] [Batch 31/512] [D loss: 0.6046793460845947] [G loss: 6.211711406707764]\n",
      "[Epoch 2/100] [Batch 32/512] [D loss: 0.30325576663017273] [G loss: 4.089983940124512]\n",
      "[Epoch 2/100] [Batch 33/512] [D loss: 0.2579222619533539] [G loss: 3.7632265090942383]\n",
      "[Epoch 2/100] [Batch 34/512] [D loss: 0.5825266242027283] [G loss: 1.223541021347046]\n",
      "[Epoch 2/100] [Batch 35/512] [D loss: 0.692975640296936] [G loss: 12.047268867492676]\n",
      "[Epoch 2/100] [Batch 36/512] [D loss: 1.897642970085144] [G loss: 0.2526647746562958]\n",
      "[Epoch 2/100] [Batch 37/512] [D loss: 1.6045265197753906] [G loss: 4.417165279388428]\n",
      "[Epoch 2/100] [Batch 38/512] [D loss: 0.32444313168525696] [G loss: 5.003958702087402]\n",
      "[Epoch 2/100] [Batch 39/512] [D loss: 0.4770216643810272] [G loss: 2.279715061187744]\n",
      "[Epoch 2/100] [Batch 40/512] [D loss: 0.5638656616210938] [G loss: 1.7884666919708252]\n",
      "[Epoch 2/100] [Batch 41/512] [D loss: 0.5729880928993225] [G loss: 6.102860450744629]\n",
      "[Epoch 2/100] [Batch 42/512] [D loss: 1.3086036443710327] [G loss: 0.28972741961479187]\n",
      "[Epoch 2/100] [Batch 43/512] [D loss: 1.9344538450241089] [G loss: 6.089398384094238]\n",
      "[Epoch 2/100] [Batch 44/512] [D loss: 1.1472444534301758] [G loss: 0.9497528672218323]\n",
      "[Epoch 2/100] [Batch 45/512] [D loss: 1.0910658836364746] [G loss: 0.8642163872718811]\n",
      "[Epoch 2/100] [Batch 46/512] [D loss: 0.9747923016548157] [G loss: 6.966491222381592]\n",
      "[Epoch 2/100] [Batch 47/512] [D loss: 0.8299180269241333] [G loss: 2.6569595336914062]\n",
      "[Epoch 2/100] [Batch 48/512] [D loss: 0.10972443968057632] [G loss: 2.2460904121398926]\n",
      "[Epoch 2/100] [Batch 49/512] [D loss: 0.7220352292060852] [G loss: 6.68825626373291]\n",
      "[Epoch 2/100] [Batch 50/512] [D loss: 0.9988963007926941] [G loss: 1.8823684453964233]\n",
      "[Epoch 2/100] [Batch 51/512] [D loss: 0.6501646041870117] [G loss: 4.655249118804932]\n",
      "[Epoch 2/100] [Batch 52/512] [D loss: 0.279087632894516] [G loss: 3.105569839477539]\n",
      "[Epoch 2/100] [Batch 53/512] [D loss: 0.190994530916214] [G loss: 3.7261409759521484]\n",
      "[Epoch 2/100] [Batch 54/512] [D loss: 0.7338908314704895] [G loss: 0.3867252469062805]\n",
      "[Epoch 2/100] [Batch 55/512] [D loss: 1.452203392982483] [G loss: 6.752202987670898]\n",
      "[Epoch 2/100] [Batch 56/512] [D loss: 1.0961997509002686] [G loss: 0.9567997455596924]\n",
      "[Epoch 2/100] [Batch 57/512] [D loss: 0.7838131189346313] [G loss: 5.161595344543457]\n",
      "[Epoch 2/100] [Batch 58/512] [D loss: 0.2553045451641083] [G loss: 4.704746723175049]\n",
      "[Epoch 2/100] [Batch 59/512] [D loss: 0.6505734920501709] [G loss: 0.6194891333580017]\n",
      "[Epoch 2/100] [Batch 60/512] [D loss: 0.7586507797241211] [G loss: 6.2162017822265625]\n",
      "[Epoch 2/100] [Batch 61/512] [D loss: 0.6181802153587341] [G loss: 0.8129802942276001]\n",
      "[Epoch 2/100] [Batch 62/512] [D loss: 1.4801571369171143] [G loss: 5.4031219482421875]\n",
      "[Epoch 2/100] [Batch 63/512] [D loss: 0.6860897541046143] [G loss: 1.5859700441360474]\n",
      "[Epoch 2/100] [Batch 64/512] [D loss: 0.6643990874290466] [G loss: 5.038473129272461]\n",
      "[Epoch 2/100] [Batch 65/512] [D loss: 0.9241231679916382] [G loss: 2.676332473754883]\n",
      "[Epoch 2/100] [Batch 66/512] [D loss: 0.723432719707489] [G loss: 9.452364921569824]\n",
      "[Epoch 2/100] [Batch 67/512] [D loss: 2.970750331878662] [G loss: 0.22884488105773926]\n",
      "[Epoch 2/100] [Batch 68/512] [D loss: 1.5966424942016602] [G loss: 2.4029359817504883]\n",
      "[Epoch 2/100] [Batch 69/512] [D loss: 0.9840153455734253] [G loss: 4.357907295227051]\n",
      "[Epoch 2/100] [Batch 70/512] [D loss: 1.0354865789413452] [G loss: 1.8265719413757324]\n",
      "[Epoch 2/100] [Batch 71/512] [D loss: 0.6702020168304443] [G loss: 2.170746088027954]\n",
      "[Epoch 2/100] [Batch 72/512] [D loss: 0.4895428419113159] [G loss: 1.649674892425537]\n",
      "[Epoch 2/100] [Batch 73/512] [D loss: 0.7290734052658081] [G loss: 4.104915618896484]\n",
      "[Epoch 2/100] [Batch 74/512] [D loss: 0.7015296220779419] [G loss: 1.9406734704971313]\n",
      "[Epoch 2/100] [Batch 75/512] [D loss: 0.5817410945892334] [G loss: 1.7906131744384766]\n",
      "[Epoch 2/100] [Batch 76/512] [D loss: 0.7169961929321289] [G loss: 1.7985482215881348]\n",
      "[Epoch 2/100] [Batch 77/512] [D loss: 0.7367227077484131] [G loss: 1.7874505519866943]\n",
      "[Epoch 2/100] [Batch 78/512] [D loss: 0.7962626814842224] [G loss: 4.631039619445801]\n",
      "[Epoch 2/100] [Batch 79/512] [D loss: 0.7475997805595398] [G loss: 1.824527382850647]\n",
      "[Epoch 2/100] [Batch 80/512] [D loss: 0.40753984451293945] [G loss: 2.791149139404297]\n",
      "[Epoch 2/100] [Batch 81/512] [D loss: 0.4842844009399414] [G loss: 1.986496925354004]\n",
      "[Epoch 2/100] [Batch 82/512] [D loss: 0.42535579204559326] [G loss: 1.8579617738723755]\n",
      "[Epoch 2/100] [Batch 83/512] [D loss: 0.8291741013526917] [G loss: 5.426652908325195]\n",
      "[Epoch 2/100] [Batch 84/512] [D loss: 1.551516056060791] [G loss: 0.44572609663009644]\n",
      "[Epoch 2/100] [Batch 85/512] [D loss: 0.6895555257797241] [G loss: 2.731187343597412]\n",
      "[Epoch 2/100] [Batch 86/512] [D loss: 0.6622928977012634] [G loss: 3.5242440700531006]\n",
      "[Epoch 2/100] [Batch 87/512] [D loss: 0.9452270269393921] [G loss: 1.4349478483200073]\n",
      "[Epoch 2/100] [Batch 88/512] [D loss: 0.5391107797622681] [G loss: 2.1610066890716553]\n",
      "[Epoch 2/100] [Batch 89/512] [D loss: 0.6450490951538086] [G loss: 4.103887557983398]\n",
      "[Epoch 2/100] [Batch 90/512] [D loss: 0.5292260050773621] [G loss: 2.719372034072876]\n",
      "[Epoch 2/100] [Batch 91/512] [D loss: 0.8097052574157715] [G loss: 1.5633622407913208]\n",
      "[Epoch 2/100] [Batch 92/512] [D loss: 0.7610304355621338] [G loss: 1.2678310871124268]\n",
      "[Epoch 2/100] [Batch 93/512] [D loss: 1.1427428722381592] [G loss: 3.601322650909424]\n",
      "[Epoch 2/100] [Batch 94/512] [D loss: 0.936620831489563] [G loss: 1.6522849798202515]\n",
      "[Epoch 2/100] [Batch 95/512] [D loss: 0.6851000785827637] [G loss: 2.362990140914917]\n",
      "[Epoch 2/100] [Batch 96/512] [D loss: 0.57221519947052] [G loss: 3.790966033935547]\n",
      "[Epoch 2/100] [Batch 97/512] [D loss: 0.919039249420166] [G loss: 1.6437995433807373]\n",
      "[Epoch 2/100] [Batch 98/512] [D loss: 0.9872933030128479] [G loss: 2.48709774017334]\n",
      "[Epoch 2/100] [Batch 99/512] [D loss: 0.8136686682701111] [G loss: 0.7644946575164795]\n",
      "[Epoch 2/100] [Batch 100/512] [D loss: 0.9334115982055664] [G loss: 3.670034408569336]\n",
      "[Epoch 2/100] [Batch 101/512] [D loss: 0.712605893611908] [G loss: 1.6818293333053589]\n",
      "[Epoch 2/100] [Batch 102/512] [D loss: 0.41499248147010803] [G loss: 3.067094087600708]\n",
      "[Epoch 2/100] [Batch 103/512] [D loss: 0.4129882752895355] [G loss: 2.058683156967163]\n",
      "[Epoch 2/100] [Batch 104/512] [D loss: 0.38164615631103516] [G loss: 3.160907745361328]\n",
      "[Epoch 2/100] [Batch 105/512] [D loss: 0.26804426312446594] [G loss: 1.885652780532837]\n",
      "[Epoch 2/100] [Batch 106/512] [D loss: 0.5290470719337463] [G loss: 4.40891695022583]\n",
      "[Epoch 2/100] [Batch 107/512] [D loss: 0.32729479670524597] [G loss: 5.256142616271973]\n",
      "[Epoch 2/100] [Batch 108/512] [D loss: 0.5677611231803894] [G loss: 0.8435593843460083]\n",
      "[Epoch 2/100] [Batch 109/512] [D loss: 1.1744651794433594] [G loss: 5.380008697509766]\n",
      "[Epoch 2/100] [Batch 110/512] [D loss: 0.4838283956050873] [G loss: 2.1702213287353516]\n",
      "[Epoch 2/100] [Batch 111/512] [D loss: 0.4287351369857788] [G loss: 2.389296531677246]\n",
      "[Epoch 2/100] [Batch 112/512] [D loss: 0.5067583322525024] [G loss: 1.5095558166503906]\n",
      "[Epoch 2/100] [Batch 113/512] [D loss: 0.4493425190448761] [G loss: 4.933846950531006]\n",
      "[Epoch 2/100] [Batch 114/512] [D loss: 1.185990333557129] [G loss: 0.4080905020236969]\n",
      "[Epoch 2/100] [Batch 115/512] [D loss: 1.0891199111938477] [G loss: 3.818519115447998]\n",
      "[Epoch 2/100] [Batch 116/512] [D loss: 0.7198720574378967] [G loss: 3.073906183242798]\n",
      "[Epoch 2/100] [Batch 117/512] [D loss: 0.7206970453262329] [G loss: 0.43774062395095825]\n",
      "[Epoch 2/100] [Batch 118/512] [D loss: 1.3365542888641357] [G loss: 5.772188663482666]\n",
      "[Epoch 2/100] [Batch 119/512] [D loss: 0.5345137119293213] [G loss: 3.800443649291992]\n",
      "[Epoch 2/100] [Batch 120/512] [D loss: 0.4404411017894745] [G loss: 2.6104791164398193]\n",
      "[Epoch 2/100] [Batch 121/512] [D loss: 0.15700538456439972] [G loss: 4.043672561645508]\n",
      "[Epoch 2/100] [Batch 122/512] [D loss: 1.0058763027191162] [G loss: 6.408894062042236]\n",
      "[Epoch 2/100] [Batch 123/512] [D loss: 2.0624473094940186] [G loss: 0.05687965452671051]\n",
      "[Epoch 2/100] [Batch 124/512] [D loss: 1.8624075651168823] [G loss: 4.44014835357666]\n",
      "[Epoch 2/100] [Batch 125/512] [D loss: 0.5181259512901306] [G loss: 4.45164680480957]\n",
      "[Epoch 2/100] [Batch 126/512] [D loss: 1.1636825799942017] [G loss: 0.8363530039787292]\n",
      "[Epoch 2/100] [Batch 127/512] [D loss: 1.6807297468185425] [G loss: 3.329054594039917]\n",
      "[Epoch 2/100] [Batch 128/512] [D loss: 0.6510947942733765] [G loss: 3.9857609272003174]\n",
      "[Epoch 2/100] [Batch 129/512] [D loss: 0.9768686294555664] [G loss: 1.336529016494751]\n",
      "[Epoch 2/100] [Batch 130/512] [D loss: 1.1342735290527344] [G loss: 3.5563199520111084]\n",
      "[Epoch 2/100] [Batch 131/512] [D loss: 0.6775021553039551] [G loss: 1.2614232301712036]\n",
      "[Epoch 2/100] [Batch 132/512] [D loss: 0.40284842252731323] [G loss: 5.4813690185546875]\n",
      "[Epoch 2/100] [Batch 133/512] [D loss: 0.9831053018569946] [G loss: 0.8395852446556091]\n",
      "[Epoch 2/100] [Batch 134/512] [D loss: 1.1147608757019043] [G loss: 7.1582841873168945]\n",
      "[Epoch 2/100] [Batch 135/512] [D loss: 1.2574338912963867] [G loss: 0.9419742822647095]\n",
      "[Epoch 2/100] [Batch 136/512] [D loss: 0.6912739276885986] [G loss: 3.8669469356536865]\n",
      "[Epoch 2/100] [Batch 137/512] [D loss: 0.9130071997642517] [G loss: 1.0677783489227295]\n",
      "[Epoch 2/100] [Batch 138/512] [D loss: 1.1155215501785278] [G loss: 4.907841205596924]\n",
      "[Epoch 2/100] [Batch 139/512] [D loss: 1.1410619020462036] [G loss: 0.4632839858531952]\n",
      "[Epoch 2/100] [Batch 140/512] [D loss: 1.4355950355529785] [G loss: 2.5247814655303955]\n",
      "[Epoch 2/100] [Batch 141/512] [D loss: 0.6937737464904785] [G loss: 1.959721565246582]\n",
      "[Epoch 2/100] [Batch 142/512] [D loss: 0.5310590267181396] [G loss: 1.9845881462097168]\n",
      "[Epoch 2/100] [Batch 143/512] [D loss: 0.30755579471588135] [G loss: 2.097862720489502]\n",
      "[Epoch 2/100] [Batch 144/512] [D loss: 0.3707720637321472] [G loss: 1.2470715045928955]\n",
      "[Epoch 2/100] [Batch 145/512] [D loss: 0.6332409381866455] [G loss: 6.010560989379883]\n",
      "[Epoch 2/100] [Batch 146/512] [D loss: 0.5915011167526245] [G loss: 1.8715102672576904]\n",
      "[Epoch 2/100] [Batch 147/512] [D loss: 0.34890374541282654] [G loss: 2.04879093170166]\n",
      "[Epoch 2/100] [Batch 148/512] [D loss: 0.5610669851303101] [G loss: 5.694114685058594]\n",
      "[Epoch 2/100] [Batch 149/512] [D loss: 0.49994751811027527] [G loss: 2.537619113922119]\n",
      "[Epoch 2/100] [Batch 150/512] [D loss: 0.6087322235107422] [G loss: 0.6735118627548218]\n",
      "[Epoch 2/100] [Batch 151/512] [D loss: 1.5540822744369507] [G loss: 6.461247444152832]\n",
      "[Epoch 2/100] [Batch 152/512] [D loss: 1.0717045068740845] [G loss: 0.8181348443031311]\n",
      "[Epoch 2/100] [Batch 153/512] [D loss: 0.5204207301139832] [G loss: 5.229480743408203]\n",
      "[Epoch 2/100] [Batch 154/512] [D loss: 0.47837138175964355] [G loss: 2.2667465209960938]\n",
      "[Epoch 2/100] [Batch 155/512] [D loss: 0.5120214223861694] [G loss: 5.737546920776367]\n",
      "[Epoch 2/100] [Batch 156/512] [D loss: 1.613891363143921] [G loss: 0.3421395719051361]\n",
      "[Epoch 2/100] [Batch 157/512] [D loss: 1.6854512691497803] [G loss: 5.028970241546631]\n",
      "[Epoch 2/100] [Batch 158/512] [D loss: 0.602231502532959] [G loss: 3.7256898880004883]\n",
      "[Epoch 2/100] [Batch 159/512] [D loss: 0.8428899645805359] [G loss: 0.9144219160079956]\n",
      "[Epoch 2/100] [Batch 160/512] [D loss: 0.8396598100662231] [G loss: 4.227500915527344]\n",
      "[Epoch 2/100] [Batch 161/512] [D loss: 0.6867184638977051] [G loss: 2.1449532508850098]\n",
      "[Epoch 2/100] [Batch 162/512] [D loss: 0.5198674201965332] [G loss: 2.996610164642334]\n",
      "[Epoch 2/100] [Batch 163/512] [D loss: 0.4081568717956543] [G loss: 3.609252452850342]\n",
      "[Epoch 2/100] [Batch 164/512] [D loss: 0.6855506896972656] [G loss: 1.1729387044906616]\n",
      "[Epoch 2/100] [Batch 165/512] [D loss: 1.9683423042297363] [G loss: 5.5014729499816895]\n",
      "[Epoch 2/100] [Batch 166/512] [D loss: 2.3019723892211914] [G loss: 0.5431314706802368]\n",
      "[Epoch 2/100] [Batch 167/512] [D loss: 0.9479507207870483] [G loss: 3.2513816356658936]\n",
      "[Epoch 2/100] [Batch 168/512] [D loss: 0.720388650894165] [G loss: 1.9196193218231201]\n",
      "[Epoch 2/100] [Batch 169/512] [D loss: 0.576556384563446] [G loss: 2.517752170562744]\n",
      "[Epoch 2/100] [Batch 170/512] [D loss: 0.26415368914604187] [G loss: 1.5477783679962158]\n",
      "[Epoch 2/100] [Batch 171/512] [D loss: 0.5341654419898987] [G loss: 4.473027229309082]\n",
      "[Epoch 2/100] [Batch 172/512] [D loss: 0.6405165195465088] [G loss: 0.8245896697044373]\n",
      "[Epoch 2/100] [Batch 173/512] [D loss: 0.8398644924163818] [G loss: 2.841651678085327]\n",
      "[Epoch 2/100] [Batch 174/512] [D loss: 0.748558759689331] [G loss: 1.2066723108291626]\n",
      "[Epoch 2/100] [Batch 175/512] [D loss: 0.6711385846138] [G loss: 4.856768608093262]\n",
      "[Epoch 2/100] [Batch 176/512] [D loss: 1.0011625289916992] [G loss: 0.5635882019996643]\n",
      "[Epoch 2/100] [Batch 177/512] [D loss: 0.8658291101455688] [G loss: 4.547808647155762]\n",
      "[Epoch 2/100] [Batch 178/512] [D loss: 1.065383791923523] [G loss: 0.7362860441207886]\n",
      "[Epoch 2/100] [Batch 179/512] [D loss: 0.556882381439209] [G loss: 2.365628480911255]\n",
      "[Epoch 2/100] [Batch 180/512] [D loss: 0.5012520551681519] [G loss: 2.370568037033081]\n",
      "[Epoch 2/100] [Batch 181/512] [D loss: 0.2669360637664795] [G loss: 3.327092170715332]\n",
      "[Epoch 2/100] [Batch 182/512] [D loss: 0.3818525969982147] [G loss: 1.3551501035690308]\n",
      "[Epoch 2/100] [Batch 183/512] [D loss: 0.5329301357269287] [G loss: 2.6554508209228516]\n",
      "[Epoch 2/100] [Batch 184/512] [D loss: 0.6057084202766418] [G loss: 1.9291218519210815]\n",
      "[Epoch 2/100] [Batch 185/512] [D loss: 0.7510017156600952] [G loss: 2.7723793983459473]\n",
      "[Epoch 2/100] [Batch 186/512] [D loss: 0.29999127984046936] [G loss: 2.6564321517944336]\n",
      "[Epoch 2/100] [Batch 187/512] [D loss: 0.3785426616668701] [G loss: 4.9726362228393555]\n",
      "[Epoch 2/100] [Batch 188/512] [D loss: 1.0812853574752808] [G loss: 0.4814112186431885]\n",
      "[Epoch 2/100] [Batch 189/512] [D loss: 1.0327997207641602] [G loss: 4.891186714172363]\n",
      "[Epoch 2/100] [Batch 190/512] [D loss: 0.574469804763794] [G loss: 1.3504537343978882]\n",
      "[Epoch 2/100] [Batch 191/512] [D loss: 0.5381609201431274] [G loss: 2.717759609222412]\n",
      "[Epoch 2/100] [Batch 192/512] [D loss: 0.40445756912231445] [G loss: 2.4126272201538086]\n",
      "[Epoch 2/100] [Batch 193/512] [D loss: 0.4185827374458313] [G loss: 1.6372092962265015]\n",
      "[Epoch 2/100] [Batch 194/512] [D loss: 0.430263876914978] [G loss: 4.639422416687012]\n",
      "[Epoch 2/100] [Batch 195/512] [D loss: 0.8628903031349182] [G loss: 0.7282177209854126]\n",
      "[Epoch 2/100] [Batch 196/512] [D loss: 1.8316090106964111] [G loss: 4.2636003494262695]\n",
      "[Epoch 2/100] [Batch 197/512] [D loss: 0.9686532020568848] [G loss: 2.4382717609405518]\n",
      "[Epoch 2/100] [Batch 198/512] [D loss: 0.9546973705291748] [G loss: 0.6096146106719971]\n",
      "[Epoch 2/100] [Batch 199/512] [D loss: 0.7292348742485046] [G loss: 5.756327152252197]\n",
      "[Epoch 2/100] [Batch 200/512] [D loss: 1.9750299453735352] [G loss: 0.8225253820419312]\n",
      "[Epoch 2/100] [Batch 201/512] [D loss: 0.6171615719795227] [G loss: 3.8890256881713867]\n",
      "[Epoch 2/100] [Batch 202/512] [D loss: 0.5357441902160645] [G loss: 1.8704572916030884]\n",
      "[Epoch 2/100] [Batch 203/512] [D loss: 0.5253663063049316] [G loss: 2.240739345550537]\n",
      "[Epoch 2/100] [Batch 204/512] [D loss: 0.477349191904068] [G loss: 2.2108302116394043]\n",
      "[Epoch 2/100] [Batch 205/512] [D loss: 0.35034093260765076] [G loss: 3.7842280864715576]\n",
      "[Epoch 2/100] [Batch 206/512] [D loss: 1.0177786350250244] [G loss: 0.49273839592933655]\n",
      "[Epoch 2/100] [Batch 207/512] [D loss: 1.017854928970337] [G loss: 4.210499286651611]\n",
      "[Epoch 2/100] [Batch 208/512] [D loss: 0.4266405701637268] [G loss: 3.19319486618042]\n",
      "[Epoch 2/100] [Batch 209/512] [D loss: 0.49753430485725403] [G loss: 0.9813174605369568]\n",
      "[Epoch 2/100] [Batch 210/512] [D loss: 1.0275064706802368] [G loss: 3.476179838180542]\n",
      "[Epoch 2/100] [Batch 211/512] [D loss: 0.42930668592453003] [G loss: 3.003811836242676]\n",
      "[Epoch 2/100] [Batch 212/512] [D loss: 0.7134527564048767] [G loss: 0.6952695846557617]\n",
      "[Epoch 2/100] [Batch 213/512] [D loss: 1.0758352279663086] [G loss: 3.834988832473755]\n",
      "[Epoch 2/100] [Batch 214/512] [D loss: 0.8998087644577026] [G loss: 0.8430072665214539]\n",
      "[Epoch 2/100] [Batch 215/512] [D loss: 0.467413991689682] [G loss: 2.5288922786712646]\n",
      "[Epoch 2/100] [Batch 216/512] [D loss: 0.3922617435455322] [G loss: 3.634603261947632]\n",
      "[Epoch 2/100] [Batch 217/512] [D loss: 0.5458229780197144] [G loss: 0.7589659094810486]\n",
      "[Epoch 2/100] [Batch 218/512] [D loss: 0.6528279185295105] [G loss: 5.274257659912109]\n",
      "[Epoch 2/100] [Batch 219/512] [D loss: 0.7654784321784973] [G loss: 1.0054278373718262]\n",
      "[Epoch 2/100] [Batch 220/512] [D loss: 0.7790096998214722] [G loss: 5.339924335479736]\n",
      "[Epoch 2/100] [Batch 221/512] [D loss: 1.2776674032211304] [G loss: 0.8295488357543945]\n",
      "[Epoch 2/100] [Batch 222/512] [D loss: 0.45712539553642273] [G loss: 2.8556180000305176]\n",
      "[Epoch 2/100] [Batch 223/512] [D loss: 0.43020862340927124] [G loss: 1.8162567615509033]\n",
      "[Epoch 2/100] [Batch 224/512] [D loss: 0.3849772810935974] [G loss: 4.3422346115112305]\n",
      "[Epoch 2/100] [Batch 225/512] [D loss: 0.5164589881896973] [G loss: 0.6669397354125977]\n",
      "[Epoch 2/100] [Batch 226/512] [D loss: 0.8146535158157349] [G loss: 4.487553596496582]\n",
      "[Epoch 2/100] [Batch 227/512] [D loss: 0.7103543281555176] [G loss: 0.7933018803596497]\n",
      "[Epoch 2/100] [Batch 228/512] [D loss: 0.8392183780670166] [G loss: 3.4360690116882324]\n",
      "[Epoch 2/100] [Batch 229/512] [D loss: 0.6814298629760742] [G loss: 0.707480251789093]\n",
      "[Epoch 2/100] [Batch 230/512] [D loss: 0.8044700026512146] [G loss: 4.885364055633545]\n",
      "[Epoch 2/100] [Batch 231/512] [D loss: 0.7496553659439087] [G loss: 1.392029047012329]\n",
      "[Epoch 2/100] [Batch 232/512] [D loss: 0.6656792759895325] [G loss: 3.377068042755127]\n",
      "[Epoch 2/100] [Batch 233/512] [D loss: 0.7983223795890808] [G loss: 1.4881808757781982]\n",
      "[Epoch 2/100] [Batch 234/512] [D loss: 0.9896131157875061] [G loss: 3.4678404331207275]\n",
      "[Epoch 2/100] [Batch 235/512] [D loss: 0.5507700443267822] [G loss: 0.9399357438087463]\n",
      "[Epoch 2/100] [Batch 236/512] [D loss: 0.6344342827796936] [G loss: 3.628164291381836]\n",
      "[Epoch 2/100] [Batch 237/512] [D loss: 0.44886314868927] [G loss: 1.3111834526062012]\n",
      "[Epoch 2/100] [Batch 238/512] [D loss: 0.6520774364471436] [G loss: 4.558244705200195]\n",
      "[Epoch 2/100] [Batch 239/512] [D loss: 0.47281062602996826] [G loss: 1.3014216423034668]\n",
      "[Epoch 2/100] [Batch 240/512] [D loss: 0.43193626403808594] [G loss: 2.839216709136963]\n",
      "[Epoch 2/100] [Batch 241/512] [D loss: 0.4089351296424866] [G loss: 2.685335636138916]\n",
      "[Epoch 2/100] [Batch 242/512] [D loss: 0.3186093866825104] [G loss: 2.0947866439819336]\n",
      "[Epoch 2/100] [Batch 243/512] [D loss: 0.6414451599121094] [G loss: 5.03741979598999]\n",
      "[Epoch 2/100] [Batch 244/512] [D loss: 1.9333299398422241] [G loss: 0.10903991758823395]\n",
      "[Epoch 2/100] [Batch 245/512] [D loss: 1.6001660823822021] [G loss: 3.1409263610839844]\n",
      "[Epoch 2/100] [Batch 246/512] [D loss: 0.5709890127182007] [G loss: 2.8363609313964844]\n",
      "[Epoch 2/100] [Batch 247/512] [D loss: 0.5735729336738586] [G loss: 1.7448242902755737]\n",
      "[Epoch 2/100] [Batch 248/512] [D loss: 0.606602668762207] [G loss: 2.74393367767334]\n",
      "[Epoch 2/100] [Batch 249/512] [D loss: 0.3518432378768921] [G loss: 2.8982882499694824]\n",
      "[Epoch 2/100] [Batch 250/512] [D loss: 0.33465391397476196] [G loss: 1.8384898900985718]\n",
      "[Epoch 2/100] [Batch 251/512] [D loss: 0.5138633251190186] [G loss: 5.189807891845703]\n",
      "[Epoch 2/100] [Batch 252/512] [D loss: 1.307397723197937] [G loss: 0.14446797966957092]\n",
      "[Epoch 2/100] [Batch 253/512] [D loss: 1.3018666505813599] [G loss: 4.417013645172119]\n",
      "[Epoch 2/100] [Batch 254/512] [D loss: 0.7134337425231934] [G loss: 1.1497960090637207]\n",
      "[Epoch 2/100] [Batch 255/512] [D loss: 0.9875702857971191] [G loss: 4.136588096618652]\n",
      "[Epoch 2/100] [Batch 256/512] [D loss: 0.9319761991500854] [G loss: 1.0705934762954712]\n",
      "[Epoch 2/100] [Batch 257/512] [D loss: 0.7498922944068909] [G loss: 1.9888876676559448]\n",
      "[Epoch 2/100] [Batch 258/512] [D loss: 0.5829647183418274] [G loss: 4.466765403747559]\n",
      "[Epoch 2/100] [Batch 259/512] [D loss: 1.1355258226394653] [G loss: 0.792192280292511]\n",
      "[Epoch 2/100] [Batch 260/512] [D loss: 0.7515360713005066] [G loss: 2.0550529956817627]\n",
      "[Epoch 2/100] [Batch 261/512] [D loss: 0.4479582607746124] [G loss: 2.8565073013305664]\n",
      "[Epoch 2/100] [Batch 262/512] [D loss: 0.38213449716567993] [G loss: 0.9637316465377808]\n",
      "[Epoch 2/100] [Batch 263/512] [D loss: 0.6714946031570435] [G loss: 4.038573265075684]\n",
      "[Epoch 2/100] [Batch 264/512] [D loss: 0.6287938356399536] [G loss: 2.0057950019836426]\n",
      "[Epoch 2/100] [Batch 265/512] [D loss: 0.31966185569763184] [G loss: 2.97127103805542]\n",
      "[Epoch 2/100] [Batch 266/512] [D loss: 0.39517492055892944] [G loss: 3.2751564979553223]\n",
      "[Epoch 2/100] [Batch 267/512] [D loss: 0.8707003593444824] [G loss: 0.3317367136478424]\n",
      "[Epoch 2/100] [Batch 268/512] [D loss: 1.6363072395324707] [G loss: 3.8716747760772705]\n",
      "[Epoch 2/100] [Batch 269/512] [D loss: 0.4228685796260834] [G loss: 2.6272292137145996]\n",
      "[Epoch 2/100] [Batch 270/512] [D loss: 0.5974547863006592] [G loss: 0.5572509169578552]\n",
      "[Epoch 2/100] [Batch 271/512] [D loss: 1.0940781831741333] [G loss: 4.367905616760254]\n",
      "[Epoch 2/100] [Batch 272/512] [D loss: 0.8475966453552246] [G loss: 0.5071117877960205]\n",
      "[Epoch 2/100] [Batch 273/512] [D loss: 1.0468789339065552] [G loss: 4.247349262237549]\n",
      "[Epoch 2/100] [Batch 274/512] [D loss: 1.3740270137786865] [G loss: 0.6849476099014282]\n",
      "[Epoch 2/100] [Batch 275/512] [D loss: 0.9950135350227356] [G loss: 5.475532054901123]\n",
      "[Epoch 2/100] [Batch 276/512] [D loss: 0.8756629228591919] [G loss: 1.3350988626480103]\n",
      "[Epoch 2/100] [Batch 277/512] [D loss: 0.7130932807922363] [G loss: 5.047205924987793]\n",
      "[Epoch 2/100] [Batch 278/512] [D loss: 0.7938125729560852] [G loss: 1.1846983432769775]\n",
      "[Epoch 2/100] [Batch 279/512] [D loss: 0.35619986057281494] [G loss: 2.2659518718719482]\n",
      "[Epoch 2/100] [Batch 280/512] [D loss: 0.32643842697143555] [G loss: 4.259176731109619]\n",
      "[Epoch 2/100] [Batch 281/512] [D loss: 0.5420445203781128] [G loss: 1.05255925655365]\n",
      "[Epoch 2/100] [Batch 282/512] [D loss: 0.5980951189994812] [G loss: 4.536344528198242]\n",
      "[Epoch 2/100] [Batch 283/512] [D loss: 0.7444139719009399] [G loss: 1.014574408531189]\n",
      "[Epoch 2/100] [Batch 284/512] [D loss: 0.48367151618003845] [G loss: 4.8141770362854]\n",
      "[Epoch 2/100] [Batch 285/512] [D loss: 0.9297451972961426] [G loss: 0.49047040939331055]\n",
      "[Epoch 2/100] [Batch 286/512] [D loss: 0.5434040427207947] [G loss: 3.0286033153533936]\n",
      "[Epoch 2/100] [Batch 287/512] [D loss: 0.6569250226020813] [G loss: 1.2948448657989502]\n",
      "[Epoch 2/100] [Batch 288/512] [D loss: 0.7098857760429382] [G loss: 3.39028263092041]\n",
      "[Epoch 2/100] [Batch 289/512] [D loss: 0.773561418056488] [G loss: 0.8949822187423706]\n",
      "[Epoch 2/100] [Batch 290/512] [D loss: 0.5738281011581421] [G loss: 3.075380802154541]\n",
      "[Epoch 2/100] [Batch 291/512] [D loss: 0.46944236755371094] [G loss: 2.0048465728759766]\n",
      "[Epoch 2/100] [Batch 292/512] [D loss: 0.2992415428161621] [G loss: 2.4146029949188232]\n",
      "[Epoch 2/100] [Batch 293/512] [D loss: 0.4346243739128113] [G loss: 2.2667222023010254]\n",
      "[Epoch 2/100] [Batch 294/512] [D loss: 0.306583970785141] [G loss: 3.843257188796997]\n",
      "[Epoch 2/100] [Batch 295/512] [D loss: 1.321463942527771] [G loss: 0.04115694388747215]\n",
      "[Epoch 2/100] [Batch 296/512] [D loss: 1.739566445350647] [G loss: 2.230088710784912]\n",
      "[Epoch 2/100] [Batch 297/512] [D loss: 0.5731117129325867] [G loss: 4.618410110473633]\n",
      "[Epoch 2/100] [Batch 298/512] [D loss: 1.0807452201843262] [G loss: 0.6070287823677063]\n",
      "[Epoch 2/100] [Batch 299/512] [D loss: 1.0002399682998657] [G loss: 2.9502944946289062]\n",
      "[Epoch 2/100] [Batch 300/512] [D loss: 0.8871270418167114] [G loss: 0.795284628868103]\n",
      "[Epoch 2/100] [Batch 301/512] [D loss: 0.8431219458580017] [G loss: 3.713266372680664]\n",
      "[Epoch 2/100] [Batch 302/512] [D loss: 0.4690715968608856] [G loss: 1.7356348037719727]\n",
      "[Epoch 2/100] [Batch 303/512] [D loss: 0.5970730781555176] [G loss: 3.55385684967041]\n",
      "[Epoch 2/100] [Batch 304/512] [D loss: 0.543414294719696] [G loss: 1.1641483306884766]\n",
      "[Epoch 2/100] [Batch 305/512] [D loss: 0.3749033212661743] [G loss: 2.5194668769836426]\n",
      "[Epoch 2/100] [Batch 306/512] [D loss: 0.7214338779449463] [G loss: 1.6462024450302124]\n",
      "[Epoch 2/100] [Batch 307/512] [D loss: 0.6381369829177856] [G loss: 1.6381347179412842]\n",
      "[Epoch 2/100] [Batch 308/512] [D loss: 0.69434654712677] [G loss: 6.116410255432129]\n",
      "[Epoch 2/100] [Batch 309/512] [D loss: 1.2310012578964233] [G loss: 1.1172975301742554]\n",
      "[Epoch 2/100] [Batch 310/512] [D loss: 0.4591860771179199] [G loss: 1.9962432384490967]\n",
      "[Epoch 2/100] [Batch 311/512] [D loss: 0.3826700747013092] [G loss: 2.802901268005371]\n",
      "[Epoch 2/100] [Batch 312/512] [D loss: 0.3484029173851013] [G loss: 1.5933878421783447]\n",
      "[Epoch 2/100] [Batch 313/512] [D loss: 0.6839507222175598] [G loss: 5.2793755531311035]\n",
      "[Epoch 2/100] [Batch 314/512] [D loss: 1.5663572549819946] [G loss: 0.2911524176597595]\n",
      "[Epoch 2/100] [Batch 315/512] [D loss: 1.010886549949646] [G loss: 3.429102897644043]\n",
      "[Epoch 2/100] [Batch 316/512] [D loss: 0.45534980297088623] [G loss: 2.4335103034973145]\n",
      "[Epoch 2/100] [Batch 317/512] [D loss: 0.24040134251117706] [G loss: 2.2159810066223145]\n",
      "[Epoch 2/100] [Batch 318/512] [D loss: 0.3986128270626068] [G loss: 2.1085870265960693]\n",
      "[Epoch 2/100] [Batch 319/512] [D loss: 0.49249255657196045] [G loss: 3.718930959701538]\n",
      "[Epoch 2/100] [Batch 320/512] [D loss: 0.7127113938331604] [G loss: 0.6954628825187683]\n",
      "[Epoch 2/100] [Batch 321/512] [D loss: 1.034105658531189] [G loss: 4.868598461151123]\n",
      "[Epoch 2/100] [Batch 322/512] [D loss: 1.0651911497116089] [G loss: 0.5942810773849487]\n",
      "[Epoch 2/100] [Batch 323/512] [D loss: 0.674059271812439] [G loss: 3.6564412117004395]\n",
      "[Epoch 2/100] [Batch 324/512] [D loss: 0.3755990266799927] [G loss: 2.0664010047912598]\n",
      "[Epoch 2/100] [Batch 325/512] [D loss: 0.6460587382316589] [G loss: 2.132053852081299]\n",
      "[Epoch 2/100] [Batch 326/512] [D loss: 0.40078631043434143] [G loss: 1.2100300788879395]\n",
      "[Epoch 2/100] [Batch 327/512] [D loss: 0.7265889048576355] [G loss: 5.313478469848633]\n",
      "[Epoch 2/100] [Batch 328/512] [D loss: 0.7965189814567566] [G loss: 0.7083508968353271]\n",
      "[Epoch 2/100] [Batch 329/512] [D loss: 1.1280571222305298] [G loss: 5.261137008666992]\n",
      "[Epoch 2/100] [Batch 330/512] [D loss: 0.6466758251190186] [G loss: 0.765292227268219]\n",
      "[Epoch 2/100] [Batch 331/512] [D loss: 1.0569891929626465] [G loss: 5.93926477432251]\n",
      "[Epoch 2/100] [Batch 332/512] [D loss: 0.6274195909500122] [G loss: 1.0352764129638672]\n",
      "[Epoch 2/100] [Batch 333/512] [D loss: 0.7244337201118469] [G loss: 3.1043334007263184]\n",
      "[Epoch 2/100] [Batch 334/512] [D loss: 1.0650144815444946] [G loss: 0.10227249562740326]\n",
      "[Epoch 2/100] [Batch 335/512] [D loss: 1.40444016456604] [G loss: 4.934538841247559]\n",
      "[Epoch 2/100] [Batch 336/512] [D loss: 0.6532123684883118] [G loss: 2.350996494293213]\n",
      "[Epoch 2/100] [Batch 337/512] [D loss: 0.8362472057342529] [G loss: 1.3244354724884033]\n",
      "[Epoch 2/100] [Batch 338/512] [D loss: 0.5470109581947327] [G loss: 2.1654281616210938]\n",
      "[Epoch 2/100] [Batch 339/512] [D loss: 0.22821016609668732] [G loss: 4.790740013122559]\n",
      "[Epoch 2/100] [Batch 340/512] [D loss: 0.8460622429847717] [G loss: 0.5598520636558533]\n",
      "[Epoch 2/100] [Batch 341/512] [D loss: 0.8564916849136353] [G loss: 9.768239974975586]\n",
      "[Epoch 2/100] [Batch 342/512] [D loss: 1.743268609046936] [G loss: 0.8217464685440063]\n",
      "[Epoch 2/100] [Batch 343/512] [D loss: 0.6063908934593201] [G loss: 2.3486955165863037]\n",
      "[Epoch 2/100] [Batch 344/512] [D loss: 0.6161617040634155] [G loss: 4.810064315795898]\n",
      "[Epoch 2/100] [Batch 345/512] [D loss: 0.664948046207428] [G loss: 1.181488037109375]\n",
      "[Epoch 2/100] [Batch 346/512] [D loss: 1.010451316833496] [G loss: 3.5738048553466797]\n",
      "[Epoch 2/100] [Batch 347/512] [D loss: 0.2996754050254822] [G loss: 2.934128999710083]\n",
      "[Epoch 2/100] [Batch 348/512] [D loss: 0.7983483076095581] [G loss: 2.888944149017334]\n",
      "[Epoch 2/100] [Batch 349/512] [D loss: 0.33286193013191223] [G loss: 2.068890333175659]\n",
      "[Epoch 2/100] [Batch 350/512] [D loss: 0.335224449634552] [G loss: 4.138904571533203]\n",
      "[Epoch 2/100] [Batch 351/512] [D loss: 0.6489055752754211] [G loss: 1.5899763107299805]\n",
      "[Epoch 2/100] [Batch 352/512] [D loss: 1.047171950340271] [G loss: 6.851619720458984]\n",
      "[Epoch 2/100] [Batch 353/512] [D loss: 1.3077977895736694] [G loss: 1.0264370441436768]\n",
      "[Epoch 2/100] [Batch 354/512] [D loss: 0.555760383605957] [G loss: 3.8010261058807373]\n",
      "[Epoch 2/100] [Batch 355/512] [D loss: 0.4602130651473999] [G loss: 2.026249408721924]\n",
      "[Epoch 2/100] [Batch 356/512] [D loss: 0.5556749105453491] [G loss: 1.6512010097503662]\n",
      "[Epoch 2/100] [Batch 357/512] [D loss: 0.6405655145645142] [G loss: 3.9038519859313965]\n",
      "[Epoch 2/100] [Batch 358/512] [D loss: 1.0633742809295654] [G loss: 0.45812931656837463]\n",
      "[Epoch 2/100] [Batch 359/512] [D loss: 1.4541016817092896] [G loss: 6.0194244384765625]\n",
      "[Epoch 2/100] [Batch 360/512] [D loss: 1.013514757156372] [G loss: 1.6929931640625]\n",
      "[Epoch 2/100] [Batch 361/512] [D loss: 0.6607773900032043] [G loss: 2.434962511062622]\n",
      "[Epoch 2/100] [Batch 362/512] [D loss: 0.49870437383651733] [G loss: 4.6312055587768555]\n",
      "[Epoch 2/100] [Batch 363/512] [D loss: 1.9305236339569092] [G loss: 0.08227930963039398]\n",
      "[Epoch 2/100] [Batch 364/512] [D loss: 0.992946982383728] [G loss: 3.4763872623443604]\n",
      "[Epoch 2/100] [Batch 365/512] [D loss: 0.6570088863372803] [G loss: 4.765816688537598]\n",
      "[Epoch 2/100] [Batch 366/512] [D loss: 1.3427079916000366] [G loss: 0.9048334360122681]\n",
      "[Epoch 2/100] [Batch 367/512] [D loss: 1.1399537324905396] [G loss: 4.104839324951172]\n",
      "[Epoch 2/100] [Batch 368/512] [D loss: 0.6325907707214355] [G loss: 1.3249657154083252]\n",
      "[Epoch 2/100] [Batch 369/512] [D loss: 0.6055381894111633] [G loss: 3.5428836345672607]\n",
      "[Epoch 2/100] [Batch 370/512] [D loss: 0.6734552979469299] [G loss: 2.270278215408325]\n",
      "[Epoch 2/100] [Batch 371/512] [D loss: 0.43254321813583374] [G loss: 1.7681519985198975]\n",
      "[Epoch 2/100] [Batch 372/512] [D loss: 0.44143572449684143] [G loss: 4.773960113525391]\n",
      "[Epoch 2/100] [Batch 373/512] [D loss: 0.756178617477417] [G loss: 0.21054081618785858]\n",
      "[Epoch 2/100] [Batch 374/512] [D loss: 1.3626620769500732] [G loss: 5.087258815765381]\n",
      "[Epoch 2/100] [Batch 375/512] [D loss: 0.9244716167449951] [G loss: 1.5463179349899292]\n",
      "[Epoch 2/100] [Batch 376/512] [D loss: 0.5248289704322815] [G loss: 2.0354461669921875]\n",
      "[Epoch 2/100] [Batch 377/512] [D loss: 0.500458836555481] [G loss: 4.625465393066406]\n",
      "[Epoch 2/100] [Batch 378/512] [D loss: 0.9193505644798279] [G loss: 0.8695964813232422]\n",
      "[Epoch 2/100] [Batch 379/512] [D loss: 1.3808008432388306] [G loss: 4.695250034332275]\n",
      "[Epoch 2/100] [Batch 380/512] [D loss: 0.8841193318367004] [G loss: 0.7363200187683105]\n",
      "[Epoch 2/100] [Batch 381/512] [D loss: 1.105883240699768] [G loss: 4.20970344543457]\n",
      "[Epoch 2/100] [Batch 382/512] [D loss: 0.857329249382019] [G loss: 0.9278993606567383]\n",
      "[Epoch 2/100] [Batch 383/512] [D loss: 0.962160587310791] [G loss: 3.9053549766540527]\n",
      "[Epoch 2/100] [Batch 384/512] [D loss: 0.6323531866073608] [G loss: 1.232560396194458]\n",
      "[Epoch 2/100] [Batch 385/512] [D loss: 0.4296420216560364] [G loss: 1.5064858198165894]\n",
      "[Epoch 2/100] [Batch 386/512] [D loss: 0.6142857074737549] [G loss: 3.614830493927002]\n",
      "[Epoch 2/100] [Batch 387/512] [D loss: 0.5311514139175415] [G loss: 1.156779170036316]\n",
      "[Epoch 2/100] [Batch 388/512] [D loss: 0.38500499725341797] [G loss: 3.3976073265075684]\n",
      "[Epoch 2/100] [Batch 389/512] [D loss: 0.4437383711338043] [G loss: 1.5941681861877441]\n",
      "[Epoch 2/100] [Batch 390/512] [D loss: 0.2773873805999756] [G loss: 2.097933292388916]\n",
      "[Epoch 2/100] [Batch 391/512] [D loss: 0.5762690305709839] [G loss: 3.9133670330047607]\n",
      "[Epoch 2/100] [Batch 392/512] [D loss: 0.5954597592353821] [G loss: 0.9217970371246338]\n",
      "[Epoch 2/100] [Batch 393/512] [D loss: 0.4979861378669739] [G loss: 2.409658908843994]\n",
      "[Epoch 2/100] [Batch 394/512] [D loss: 0.3619743585586548] [G loss: 4.697169780731201]\n",
      "[Epoch 2/100] [Batch 395/512] [D loss: 0.8912679553031921] [G loss: 0.4720553159713745]\n",
      "[Epoch 2/100] [Batch 396/512] [D loss: 1.4046299457550049] [G loss: 4.03763484954834]\n",
      "[Epoch 2/100] [Batch 397/512] [D loss: 0.32761064171791077] [G loss: 3.550619602203369]\n",
      "[Epoch 2/100] [Batch 398/512] [D loss: 0.6282038688659668] [G loss: 0.30673009157180786]\n",
      "[Epoch 2/100] [Batch 399/512] [D loss: 1.443697214126587] [G loss: 3.4348297119140625]\n",
      "[Epoch 2/100] [Batch 400/512] [D loss: 0.5180504322052002] [G loss: 3.34846830368042]\n",
      "[Epoch 2/100] [Batch 401/512] [D loss: 0.39008399844169617] [G loss: 1.7840826511383057]\n",
      "[Epoch 2/100] [Batch 402/512] [D loss: 0.3765857219696045] [G loss: 2.70912766456604]\n",
      "[Epoch 2/100] [Batch 403/512] [D loss: 0.2867239713668823] [G loss: 3.448643207550049]\n",
      "[Epoch 2/100] [Batch 404/512] [D loss: 0.9226831197738647] [G loss: 0.7260230183601379]\n",
      "[Epoch 2/100] [Batch 405/512] [D loss: 1.2551122903823853] [G loss: 7.791791915893555]\n",
      "[Epoch 2/100] [Batch 406/512] [D loss: 1.9917081594467163] [G loss: 0.14853276312351227]\n",
      "[Epoch 2/100] [Batch 407/512] [D loss: 0.8867273330688477] [G loss: 2.911348581314087]\n",
      "[Epoch 2/100] [Batch 408/512] [D loss: 0.5790930986404419] [G loss: 2.327246904373169]\n",
      "[Epoch 2/100] [Batch 409/512] [D loss: 0.5336384773254395] [G loss: 1.0672911405563354]\n",
      "[Epoch 2/100] [Batch 410/512] [D loss: 0.9741619825363159] [G loss: 3.6444740295410156]\n",
      "[Epoch 2/100] [Batch 411/512] [D loss: 0.5562450885772705] [G loss: 1.957155704498291]\n",
      "[Epoch 2/100] [Batch 412/512] [D loss: 0.5924383401870728] [G loss: 0.5572566986083984]\n",
      "[Epoch 2/100] [Batch 413/512] [D loss: 0.7776552438735962] [G loss: 3.387465476989746]\n",
      "[Epoch 2/100] [Batch 414/512] [D loss: 0.7295380234718323] [G loss: 1.101348638534546]\n",
      "[Epoch 2/100] [Batch 415/512] [D loss: 0.8556762337684631] [G loss: 3.211602210998535]\n",
      "[Epoch 2/100] [Batch 416/512] [D loss: 0.5609945058822632] [G loss: 1.7969197034835815]\n",
      "[Epoch 2/100] [Batch 417/512] [D loss: 0.5117955207824707] [G loss: 2.5401716232299805]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Define constants\n",
    "IMG_SIZE = 512  # Set to 512x512 for the new output size\n",
    "LATENT_DIM = 200  # Updated latent dimension\n",
    "BATCH_SIZE = 16  # Updated batch size\n",
    "EPOCHS = 100\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.init_size = IMG_SIZE // 32  # Adjusted for 512x512 images (512 / 32 = 16)\n",
    "        self.l1 = nn.Sequential(nn.Linear(LATENT_DIM, 512 * self.init_size ** 2))\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(512, 256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 512, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),   # 512x512 -> 256x256\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 256x256 -> 128x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1), # 128x128 -> 64x64\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1), # 64x64 -> 32x32\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1024, 4, stride=2, padding=1), # 32x32 -> 16x16\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 2048, 4, stride=2, padding=1), # 16x16 -> 8x8\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048 * 8 * 8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ConcatDataset([datasets.Flowers102(root='../../data/flowers', split='train', download=True, transform=transform),\n",
    "                   datasets.Flowers102(root='../../data/flowers', split='val', download=True, transform=transform),\n",
    "                   datasets.Flowers102(root='../../data/flowers', split='test', download=True, transform=transform)]),\n",
    "    batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Training\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.to(device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(batch_size, 1, requires_grad=False).to(device)\n",
    "        fake = torch.zeros(batch_size, 1, requires_grad=False).to(device)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.randn(batch_size, LATENT_DIM).to(device)\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss for real images\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        # Loss for fake images\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        # Total discriminator loss\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Loss for fake images with flipped labels\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch}/{EPOCHS}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "\n",
    "    # Save sample images\n",
    "    if epoch % 2 == 0:\n",
    "        save_image(gen_imgs.data[:25], f\"images/{epoch}_DCGAN_flowers2_512.png\", nrow=5, normalize=True)\n",
    "        # Save the model\n",
    "        torch.save(generator.state_dict(), f\"saved_model/saved_model_dcgan_flower2_512_{epoch}.pth\")\n",
    "\n",
    "# Save model after last iter\n",
    "save_image(gen_imgs.data[:25], f\"images/{epoch}_DCGAN_flowers2_512.png\", nrow=5, normalize=True)\n",
    "# Save the model\n",
    "torch.save(generator.state_dict(), f\"saved_model/saved_model_dcgan_flower2_512_{EPOCHS}.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
