{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code can use existing models and load them with weights created during training - useful for seeing G output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LATENT_DIM = 200  # Updated latent dimension\n",
    "G_IS_512 = 0  # Generator model is trained for 512x512 images\n",
    "\n",
    "# If G_IS_512 is 1, the generator model is trained for 512x512 images\n",
    "if G_IS_512:\n",
    "    IMG_SIZE = 512  # Set to 512x512 for the new output size\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Generator, self).__init__()\n",
    "            self.init_size = IMG_SIZE // 32  # Adjusted for 512x512 images (512 / 32 = 16)\n",
    "            self.l1 = nn.Sequential(nn.Linear(LATENT_DIM, 512 * self.init_size ** 2))\n",
    "            self.conv_blocks = nn.Sequential(\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(512, 256, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(256, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(32, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(16, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(16, 3, 3, stride=1, padding=1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        def forward(self, z):\n",
    "            out = self.l1(z)\n",
    "            out = out.view(out.shape[0], 512, self.init_size, self.init_size)\n",
    "            img = self.conv_blocks(out)\n",
    "            return img\n",
    "else:\n",
    "    IMG_SIZE = 256\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Generator, self).__init__()\n",
    "            self.init_size = IMG_SIZE // 16  # Adjusted for 256x256 images\n",
    "            self.l1 = nn.Sequential(nn.Linear(LATENT_DIM, 256 * self.init_size ** 2))\n",
    "            self.conv_blocks = nn.Sequential(\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(256, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(32, 0.8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(32, 3, 3, stride=1, padding=1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        def forward(self, z):\n",
    "            out = self.l1(z)\n",
    "            out = out.view(out.shape[0], 256, self.init_size, self.init_size)\n",
    "            img = self.conv_blocks(out)\n",
    "            return img\n",
    "        \n",
    "def load_generator_weights(generator, weight_path):\n",
    "    \"\"\"Load the generator weights from the given file path.\"\"\"\n",
    "    generator.load_state_dict(torch.load(weight_path))\n",
    "    generator.eval()  # Set the generator to evaluation mode\n",
    "\n",
    "def measure_memory_usage(generator, input_noise, device):\n",
    "    \"\"\"Measure the GPU memory usage for generating a single image.\"\"\"\n",
    "    torch.cuda.reset_peak_memory_stats(device)  # Reset peak memory stats\n",
    "    with torch.no_grad():  # No need to track gradients for inference\n",
    "        _ = generator(input_noise)\n",
    "\n",
    "    peak_memory = torch.cuda.max_memory_allocated(device)  # Peak memory usage on GPU\n",
    "    return peak_memory\n",
    "\n",
    "def measure_execution_time(generator, input_noise):\n",
    "    \"\"\"Measure the execution time for generating a single image.\"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for inference\n",
    "        _ = generator(input_noise)\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    return execution_time\n",
    "\n",
    "def main():\n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load your trained generator model\n",
    "    generator = Generator().to(device)  # Ensure model is on the GPU\n",
    "\n",
    "    # Path to your saved generator weights\n",
    "    weight_path = 'modele/saved_model_dcgan_flower2_256_100.pth'\n",
    "\n",
    "    # Load weights into the model\n",
    "    load_generator_weights(generator, weight_path)\n",
    "\n",
    "    # Define input noise for generator (latent space vector)\n",
    "    latent_dim = 200  # Updated latent dimension size\n",
    "    input_noise = torch.randn(1, latent_dim).to(device)  # Batch size of 1 for single image generation\n",
    "\n",
    "    # Measure memory usage on GPU\n",
    "    memory_used = measure_memory_usage(generator, input_noise, device)\n",
    "    print(f\"Peak memory used for generating a single image: {memory_used / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "    # Measure execution time\n",
    "    execution_time = measure_execution_time(generator, input_noise)\n",
    "    print(f\"Execution time for generating a single image: {execution_time:.6f} seconds\")\n",
    "\n",
    "    # Show the generated image\n",
    "    with torch.no_grad():\n",
    "        generated_image = generator(input_noise).cpu().squeeze(0).permute(1, 2, 0) / 2.0 + 0.5\n",
    "        plt.imshow(generated_image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
