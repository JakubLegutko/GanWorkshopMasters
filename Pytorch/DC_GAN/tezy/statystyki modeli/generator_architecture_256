digraph {
	graph [size="19.95,19.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2542041286032 [label="
 (1, 3, 256, 256)" fillcolor=darkolivegreen1]
	2542036326528 [label=TanhBackward0]
	2542036324608 -> 2542036326528
	2542036324608 [label=ConvolutionBackward0]
	2542036326960 -> 2542036324608
	2542036326960 [label=ReluBackward0]
	2542034700368 -> 2542036326960
	2542034700368 [label=CudnnBatchNormBackward0]
	2542034700080 -> 2542034700368
	2542034700080 [label=ConvolutionBackward0]
	2542034700416 -> 2542034700080
	2542034700416 [label=UpsampleNearest2DBackward0]
	2542034700464 -> 2542034700416
	2542034700464 [label=ReluBackward0]
	2542042737344 -> 2542034700464
	2542042737344 [label=CudnnBatchNormBackward0]
	2542042736240 -> 2542042737344
	2542042736240 [label=ConvolutionBackward0]
	2542042735616 -> 2542042736240
	2542042735616 [label=UpsampleNearest2DBackward0]
	2542042737248 -> 2542042735616
	2542042737248 [label=ReluBackward0]
	2542042736960 -> 2542042737248
	2542042736960 [label=CudnnBatchNormBackward0]
	2542042735952 -> 2542042736960
	2542042735952 [label=ConvolutionBackward0]
	2542042736288 -> 2542042735952
	2542042736288 [label=UpsampleNearest2DBackward0]
	2542042737392 -> 2542042736288
	2542042737392 [label=ReluBackward0]
	2542042736432 -> 2542042737392
	2542042736432 [label=CudnnBatchNormBackward0]
	2542042735472 -> 2542042736432
	2542042735472 [label=ConvolutionBackward0]
	2542042737872 -> 2542042735472
	2542042737872 [label=UpsampleNearest2DBackward0]
	2542042835216 -> 2542042737872
	2542042835216 [label=CudnnBatchNormBackward0]
	2542042833920 -> 2542042835216
	2542042833920 [label=ViewBackward0]
	2542042835504 -> 2542042833920
	2542042835504 [label=AddmmBackward0]
	2542042836800 -> 2542042835504
	2541973188496 [label="l1.0.bias
 (65536)" fillcolor=lightblue]
	2541973188496 -> 2542042836800
	2542042836800 [label=AccumulateGrad]
	2542042835888 -> 2542042835504
	2542042835888 [label=TBackward0]
	2542042836512 -> 2542042835888
	2542028918272 [label="l1.0.weight
 (65536, 200)" fillcolor=lightblue]
	2542028918272 -> 2542042836512
	2542042836512 [label=AccumulateGrad]
	2542042835984 -> 2542042835216
	2542045160688 [label="conv_blocks.0.weight
 (256)" fillcolor=lightblue]
	2542045160688 -> 2542042835984
	2542042835984 [label=AccumulateGrad]
	2542042835744 -> 2542042835216
	2541967385280 [label="conv_blocks.0.bias
 (256)" fillcolor=lightblue]
	2541967385280 -> 2542042835744
	2542042835744 [label=AccumulateGrad]
	2542042736720 -> 2542042735472
	2542041789840 [label="conv_blocks.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2542041789840 -> 2542042736720
	2542042736720 [label=AccumulateGrad]
	2542042736576 -> 2542042735472
	2542041791920 [label="conv_blocks.2.bias
 (256)" fillcolor=lightblue]
	2542041791920 -> 2542042736576
	2542042736576 [label=AccumulateGrad]
	2542042736528 -> 2542042736432
	2542041790720 [label="conv_blocks.3.weight
 (256)" fillcolor=lightblue]
	2542041790720 -> 2542042736528
	2542042736528 [label=AccumulateGrad]
	2542042735712 -> 2542042736432
	2542041792080 [label="conv_blocks.3.bias
 (256)" fillcolor=lightblue]
	2542041792080 -> 2542042735712
	2542042735712 [label=AccumulateGrad]
	2542042736048 -> 2542042735952
	2542036641008 [label="conv_blocks.6.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	2542036641008 -> 2542042736048
	2542042736048 [label=AccumulateGrad]
	2542042735664 -> 2542042735952
	2542036642448 [label="conv_blocks.6.bias
 (128)" fillcolor=lightblue]
	2542036642448 -> 2542042735664
	2542042735664 [label=AccumulateGrad]
	2542042736816 -> 2542042736960
	2542036643088 [label="conv_blocks.7.weight
 (128)" fillcolor=lightblue]
	2542036643088 -> 2542042736816
	2542042736816 [label=AccumulateGrad]
	2542042736912 -> 2542042736960
	2542036641088 [label="conv_blocks.7.bias
 (128)" fillcolor=lightblue]
	2542036641088 -> 2542042736912
	2542042736912 [label=AccumulateGrad]
	2542042737152 -> 2542042736240
	2542036643568 [label="conv_blocks.10.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2542036643568 -> 2542042737152
	2542042737152 [label=AccumulateGrad]
	2542042735568 -> 2542042736240
	2542036640688 [label="conv_blocks.10.bias
 (64)" fillcolor=lightblue]
	2542036640688 -> 2542042735568
	2542042735568 [label=AccumulateGrad]
	2542042736144 -> 2542042737344
	2542036640288 [label="conv_blocks.11.weight
 (64)" fillcolor=lightblue]
	2542036640288 -> 2542042736144
	2542042736144 [label=AccumulateGrad]
	2542042735760 -> 2542042737344
	2542036639808 [label="conv_blocks.11.bias
 (64)" fillcolor=lightblue]
	2542036639808 -> 2542042735760
	2542042735760 [label=AccumulateGrad]
	2542034701568 -> 2542034700080
	2542036640848 [label="conv_blocks.14.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	2542036640848 -> 2542034701568
	2542034701568 [label=AccumulateGrad]
	2542034701280 -> 2542034700080
	2542036643168 [label="conv_blocks.14.bias
 (32)" fillcolor=lightblue]
	2542036643168 -> 2542034701280
	2542034701280 [label=AccumulateGrad]
	2542034701712 -> 2542034700368
	2542036641248 [label="conv_blocks.15.weight
 (32)" fillcolor=lightblue]
	2542036641248 -> 2542034701712
	2542034701712 [label=AccumulateGrad]
	2542034700320 -> 2542034700368
	2542036639888 [label="conv_blocks.15.bias
 (32)" fillcolor=lightblue]
	2542036639888 -> 2542034700320
	2542034700320 [label=AccumulateGrad]
	2542036326336 -> 2542036324608
	2541966397664 [label="conv_blocks.17.weight
 (3, 32, 3, 3)" fillcolor=lightblue]
	2541966397664 -> 2542036326336
	2542036326336 [label=AccumulateGrad]
	2542036325952 -> 2542036324608
	2541966399024 [label="conv_blocks.17.bias
 (3)" fillcolor=lightblue]
	2541966399024 -> 2542036325952
	2542036325952 [label=AccumulateGrad]
	2542036326528 -> 2542041286032
}
