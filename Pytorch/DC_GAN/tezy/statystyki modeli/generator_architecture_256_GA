digraph {
	graph [size="19.95,19.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1826388421664 [label="
 (1, 3, 256, 256)" fillcolor=darkolivegreen1]
	1820288421120 [label=TanhBackward0]
	1820288421024 -> 1820288421120
	1820288421024 [label=ConvolutionBackward0]
	1820288421264 -> 1820288421024
	1820288421264 [label=ReluBackward0]
	1820288420400 -> 1820288421264
	1820288420400 [label=CudnnBatchNormBackward0]
	1820288420640 -> 1820288420400
	1820288420640 [label=ConvolutionBackward0]
	1820288419824 -> 1820288420640
	1820288419824 [label=UpsampleNearest2DBackward0]
	1820288421600 -> 1820288419824
	1820288421600 [label=ReluBackward0]
	1820288421408 -> 1820288421600
	1820288421408 [label=CudnnBatchNormBackward0]
	1820288420304 -> 1820288421408
	1820288420304 [label=ConvolutionBackward0]
	1820288366384 -> 1820288420304
	1820288366384 [label=UpsampleNearest2DBackward0]
	1820288368544 -> 1820288366384
	1820288368544 [label=ReluBackward0]
	1820288365568 -> 1820288368544
	1820288365568 [label=CudnnBatchNormBackward0]
	1820288365520 -> 1820288365568
	1820288365520 [label=ConvolutionBackward0]
	1820288366288 -> 1820288365520
	1820288366288 [label=UpsampleNearest2DBackward0]
	1820288367248 -> 1820288366288
	1820288367248 [label=ReluBackward0]
	1820288367152 -> 1820288367248
	1820288367152 [label=CudnnBatchNormBackward0]
	1820288367344 -> 1820288367152
	1820288367344 [label=ConvolutionBackward0]
	1820288368304 -> 1820288367344
	1820288368304 [label=UpsampleNearest2DBackward0]
	1820288366576 -> 1820288368304
	1820288366576 [label=CudnnBatchNormBackward0]
	1820288367536 -> 1820288366576
	1820288367536 [label=ViewBackward0]
	1820288366000 -> 1820288367536
	1820288366000 [label=AddmmBackward0]
	1820288365472 -> 1820288366000
	1820288508448 [label="l1.0.bias
 (65536)" fillcolor=lightblue]
	1820288508448 -> 1820288365472
	1820288365472 [label=AccumulateGrad]
	1820288367200 -> 1820288366000
	1820288367200 [label=TBackward0]
	1826386065296 -> 1820288367200
	1820288508368 [label="l1.0.weight
 (65536, 200)" fillcolor=lightblue]
	1820288508368 -> 1826386065296
	1826386065296 [label=AccumulateGrad]
	1820288367584 -> 1820288366576
	1820285499568 [label="conv_blocks.0.weight
 (256)" fillcolor=lightblue]
	1820285499568 -> 1820288367584
	1820288367584 [label=AccumulateGrad]
	1820288366144 -> 1820288366576
	1826386117792 [label="conv_blocks.0.bias
 (256)" fillcolor=lightblue]
	1826386117792 -> 1820288366144
	1820288366144 [label=AccumulateGrad]
	1820288367488 -> 1820288367344
	1826386118272 [label="conv_blocks.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1826386118272 -> 1820288367488
	1820288367488 [label=AccumulateGrad]
	1820288367440 -> 1820288367344
	1826386118352 [label="conv_blocks.2.bias
 (256)" fillcolor=lightblue]
	1826386118352 -> 1820288367440
	1820288367440 [label=AccumulateGrad]
	1820288366048 -> 1820288367152
	1826386118432 [label="conv_blocks.3.weight
 (256)" fillcolor=lightblue]
	1826386118432 -> 1820288366048
	1820288366048 [label=AccumulateGrad]
	1820288367632 -> 1820288367152
	1826386118512 [label="conv_blocks.3.bias
 (256)" fillcolor=lightblue]
	1826386118512 -> 1820288367632
	1820288367632 [label=AccumulateGrad]
	1820288366240 -> 1820288365520
	1826386118912 [label="conv_blocks.6.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	1826386118912 -> 1820288366240
	1820288366240 [label=AccumulateGrad]
	1820288366336 -> 1820288365520
	1826386118832 [label="conv_blocks.6.bias
 (128)" fillcolor=lightblue]
	1826386118832 -> 1820288366336
	1820288366336 [label=AccumulateGrad]
	1820288365280 -> 1820288365568
	1826386118992 [label="conv_blocks.7.weight
 (128)" fillcolor=lightblue]
	1826386118992 -> 1820288365280
	1820288365280 [label=AccumulateGrad]
	1820288366960 -> 1820288365568
	1826386119072 [label="conv_blocks.7.bias
 (128)" fillcolor=lightblue]
	1826386119072 -> 1820288366960
	1820288366960 [label=AccumulateGrad]
	1820288368400 -> 1820288420304
	1826386119472 [label="conv_blocks.10.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	1826386119472 -> 1820288368400
	1820288368400 [label=AccumulateGrad]
	1820288368208 -> 1820288420304
	1826386119552 [label="conv_blocks.10.bias
 (64)" fillcolor=lightblue]
	1826386119552 -> 1820288368208
	1820288368208 [label=AccumulateGrad]
	1820288421360 -> 1820288421408
	1826386119632 [label="conv_blocks.11.weight
 (64)" fillcolor=lightblue]
	1826386119632 -> 1820288421360
	1820288421360 [label=AccumulateGrad]
	1820288420784 -> 1820288421408
	1826386119712 [label="conv_blocks.11.bias
 (64)" fillcolor=lightblue]
	1826386119712 -> 1820288420784
	1820288420784 [label=AccumulateGrad]
	1820288420544 -> 1820288420640
	1826386120112 [label="conv_blocks.14.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	1826386120112 -> 1820288420544
	1820288420544 [label=AccumulateGrad]
	1820288420976 -> 1820288420640
	1826386120192 [label="conv_blocks.14.bias
 (32)" fillcolor=lightblue]
	1826386120192 -> 1820288420976
	1820288420976 [label=AccumulateGrad]
	1820288420256 -> 1820288420400
	1826386120272 [label="conv_blocks.15.weight
 (32)" fillcolor=lightblue]
	1826386120272 -> 1820288420256
	1820288420256 [label=AccumulateGrad]
	1820288420688 -> 1820288420400
	1826386120352 [label="conv_blocks.15.bias
 (32)" fillcolor=lightblue]
	1826386120352 -> 1820288420688
	1820288420688 [label=AccumulateGrad]
	1820288421312 -> 1820288421024
	1826386800784 [label="conv_blocks.17.weight
 (3, 32, 3, 3)" fillcolor=lightblue]
	1826386800784 -> 1820288421312
	1820288421312 [label=AccumulateGrad]
	1820288421696 -> 1820288421024
	1826386800864 [label="conv_blocks.17.bias
 (3)" fillcolor=lightblue]
	1826386800864 -> 1820288421696
	1820288421696 [label=AccumulateGrad]
	1820288421120 -> 1826388421664
}
