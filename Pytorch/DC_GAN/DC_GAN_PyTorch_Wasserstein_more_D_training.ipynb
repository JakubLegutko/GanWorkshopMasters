{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flowers102 dataset, but here not only are we using Wasserstein loss, but also we train the Discriminator 5 times more than the Generator - this should in theory make for a better Discriminator and allow the Generator to train faster, but Generator gets a 2.5x bump in learning rate to not get overpowered by the Discriminator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Define constants\n",
    "IMG_SIZE = 64\n",
    "LATENT_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "CRITIC_ITERATIONS = 5\n",
    "CLIP_VALUE = 0.01\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.init_size = IMG_SIZE // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(LATENT_DIM, 128 * self.init_size ** 2))\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "dataloader = DataLoader(\n",
    "    ConcatDataset([datasets.Flowers102(root='../../data/flowers', split='train', download=True, transform=transform),\n",
    "                   datasets.Flowers102(root='../../data/flowers', split='val', download=True, transform=transform),\n",
    "                   datasets.Flowers102(root='../../data/flowers', split='test', download=True, transform=transform)]),\n",
    "    batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Optimizers: Adam optimizers as suggested for WGAN\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.to(device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = torch.randn(batch_size, LATENT_DIM).to(device)\n",
    "        fake_imgs = generator(z).detach()\n",
    "\n",
    "        # Compute the discriminator loss\n",
    "        loss_D = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Clip weights of discriminator to enforce Lipschitz constraint\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-CLIP_VALUE, CLIP_VALUE)\n",
    "\n",
    "        # Train Generator every n_critic steps\n",
    "        if i % CRITIC_ITERATIONS == 0:\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Generate a batch of fake images\n",
    "            gen_imgs = generator(z)\n",
    "\n",
    "            # Compute the generator loss\n",
    "            loss_G = -torch.mean(discriminator(gen_imgs))\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "        # Print the progress\n",
    "        print(f\"[Epoch {epoch}/{EPOCHS}] [Batch {i}/{len(dataloader)}] [D loss: {loss_D.item()}] [G loss: {loss_G.item()}]\")\n",
    "\n",
    "    # Save sample images at intervals\n",
    "    if epoch % 10 == 0:\n",
    "        save_image(gen_imgs.data[:25], f\"images/{epoch}_stl_wasserstein.png\", nrow=5, normalize=True)\n",
    "        # Save the model\n",
    "        torch.save(generator.state_dict(), f\"saved_model_wasserstein_stl_{epoch}.pth\")\n",
    "save_image(gen_imgs.data[:25], f\"images/{epoch}_stl_wasserstein.png\", nrow=5, normalize=True)\n",
    "# Save the model\n",
    "torch.save(generator.state_dict(), f\"saved_model_wasserstein_stl_{epoch}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
