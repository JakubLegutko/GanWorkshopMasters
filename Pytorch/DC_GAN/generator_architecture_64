digraph {
	graph [size="12.75,12.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2541971246032 [label="
 (1, 3, 64, 64)" fillcolor=darkolivegreen1]
	2542044159280 [label=TanhBackward0]
	2542044157168 -> 2542044159280
	2542044157168 [label=ConvolutionBackward0]
	2542044158608 -> 2542044157168
	2542044158608 [label=ReluBackward0]
	2542044159184 -> 2542044158608
	2542044159184 [label=CudnnBatchNormBackward0]
	2542044158560 -> 2542044159184
	2542044158560 [label=ConvolutionBackward0]
	2542028754080 -> 2542044158560
	2542028754080 [label=UpsampleNearest2DBackward0]
	2542028754608 -> 2542028754080
	2542028754608 [label=ReluBackward0]
	2542041367792 -> 2542028754608
	2542041367792 [label=CudnnBatchNormBackward0]
	2542028754176 -> 2542041367792
	2542028754176 [label=ConvolutionBackward0]
	2542045231136 -> 2542028754176
	2542045231136 [label=UpsampleNearest2DBackward0]
	2542045231520 -> 2542045231136
	2542045231520 [label=CudnnBatchNormBackward0]
	2542045231328 -> 2542045231520
	2542045231328 [label=ViewBackward0]
	2542045231232 -> 2542045231328
	2542045231232 [label=AddmmBackward0]
	2542045231808 -> 2542045231232
	2542028191520 [label="l1.0.bias
 (32768)" fillcolor=lightblue]
	2542028191520 -> 2542045231808
	2542045231808 [label=AccumulateGrad]
	2542045231568 -> 2542045231232
	2542045231568 [label=TBackward0]
	2542045231760 -> 2542045231568
	2542028193680 [label="l1.0.weight
 (32768, 100)" fillcolor=lightblue]
	2542028193680 -> 2542045231760
	2542045231760 [label=AccumulateGrad]
	2542045231376 -> 2542045231520
	2542028192080 [label="conv_blocks.0.weight
 (128)" fillcolor=lightblue]
	2542028192080 -> 2542045231376
	2542045231376 [label=AccumulateGrad]
	2542045230896 -> 2542045231520
	2542042137680 [label="conv_blocks.0.bias
 (128)" fillcolor=lightblue]
	2542042137680 -> 2542045230896
	2542045230896 [label=AccumulateGrad]
	2542045231472 -> 2542028754176
	2542042136640 [label="conv_blocks.2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2542042136640 -> 2542045231472
	2542045231472 [label=AccumulateGrad]
	2542045231904 -> 2542028754176
	2542042138240 [label="conv_blocks.2.bias
 (128)" fillcolor=lightblue]
	2542042138240 -> 2542045231904
	2542045231904 [label=AccumulateGrad]
	2542045230992 -> 2542041367792
	2542041874080 [label="conv_blocks.3.weight
 (128)" fillcolor=lightblue]
	2542041874080 -> 2542045230992
	2542045230992 [label=AccumulateGrad]
	2542045231424 -> 2542041367792
	2540025301888 [label="conv_blocks.3.bias
 (128)" fillcolor=lightblue]
	2540025301888 -> 2542045231424
	2542045231424 [label=AccumulateGrad]
	2542028754512 -> 2542044158560
	2542044181184 [label="conv_blocks.6.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2542044181184 -> 2542028754512
	2542028754512 [label=AccumulateGrad]
	2542028754560 -> 2542044158560
	2542044181664 [label="conv_blocks.6.bias
 (64)" fillcolor=lightblue]
	2542044181664 -> 2542028754560
	2542028754560 [label=AccumulateGrad]
	2542044157216 -> 2542044159184
	2542044184064 [label="conv_blocks.7.weight
 (64)" fillcolor=lightblue]
	2542044184064 -> 2542044157216
	2542044157216 [label=AccumulateGrad]
	2542044159328 -> 2542044159184
	2542044181984 [label="conv_blocks.7.bias
 (64)" fillcolor=lightblue]
	2542044181984 -> 2542044159328
	2542044159328 [label=AccumulateGrad]
	2542044158992 -> 2542044157168
	2542044181344 [label="conv_blocks.9.weight
 (3, 64, 3, 3)" fillcolor=lightblue]
	2542044181344 -> 2542044158992
	2542044158992 [label=AccumulateGrad]
	2542044158176 -> 2542044157168
	2542044181024 [label="conv_blocks.9.bias
 (3)" fillcolor=lightblue]
	2542044181024 -> 2542044158176
	2542044158176 [label=AccumulateGrad]
	2542044159280 -> 2541971246032
}
