digraph {
	graph [size="23.55,23.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1463365892432 [label="
 (1, 3, 512, 512)" fillcolor=darkolivegreen1]
	1460821767840 [label=TanhBackward0]
	1460098179568 -> 1460821767840
	1460098179568 [label=ConvolutionBackward0]
	1463360424880 -> 1460098179568
	1463360424880 [label=ReluBackward0]
	1463360377232 -> 1463360424880
	1463360377232 [label=CudnnBatchNormBackward0]
	1463360469648 -> 1463360377232
	1463360469648 [label=ConvolutionBackward0]
	1463360311552 -> 1463360469648
	1463360311552 [label=UpsampleNearest2DBackward0]
	1463359623376 -> 1463360311552
	1463359623376 [label=ReluBackward0]
	1460098692384 -> 1463359623376
	1460098692384 [label=CudnnBatchNormBackward0]
	1460282175648 -> 1460098692384
	1460282175648 [label=ConvolutionBackward0]
	1460823156864 -> 1460282175648
	1460823156864 [label=UpsampleNearest2DBackward0]
	1460823155664 -> 1460823156864
	1460823155664 [label=ReluBackward0]
	1460823156384 -> 1460823155664
	1460823156384 [label=CudnnBatchNormBackward0]
	1460823156480 -> 1460823156384
	1460823156480 [label=ConvolutionBackward0]
	1460823155424 -> 1460823156480
	1460823155424 [label=UpsampleNearest2DBackward0]
	1460823156672 -> 1460823155424
	1460823156672 [label=ReluBackward0]
	1460823157056 -> 1460823156672
	1460823157056 [label=CudnnBatchNormBackward0]
	1460823157296 -> 1460823157056
	1460823157296 [label=ConvolutionBackward0]
	1460823157632 -> 1460823157296
	1460823157632 [label=UpsampleNearest2DBackward0]
	1460823198016 -> 1460823157632
	1460823198016 [label=ReluBackward0]
	1460823197536 -> 1460823198016
	1460823197536 [label=CudnnBatchNormBackward0]
	1460823195760 -> 1460823197536
	1460823195760 [label=ConvolutionBackward0]
	1460823197056 -> 1460823195760
	1460823197056 [label=UpsampleNearest2DBackward0]
	1460823195856 -> 1460823197056
	1460823195856 [label=CudnnBatchNormBackward0]
	1460823196864 -> 1460823195856
	1460823196864 [label=ViewBackward0]
	1460823197104 -> 1460823196864
	1460823197104 [label=AddmmBackward0]
	1460823197968 -> 1460823197104
	1460821734880 [label="l1.0.bias
 (131072)" fillcolor=lightblue]
	1460821734880 -> 1460823197968
	1460823197968 [label=AccumulateGrad]
	1460823196912 -> 1460823197104
	1460823196912 [label=TBackward0]
	1459364934368 -> 1460823196912
	1460098713536 [label="l1.0.weight
 (131072, 200)" fillcolor=lightblue]
	1460098713536 -> 1459364934368
	1459364934368 [label=AccumulateGrad]
	1460823197584 -> 1460823195856
	1463366025440 [label="conv_blocks.0.weight
 (512)" fillcolor=lightblue]
	1463366025440 -> 1460823197584
	1460823197584 [label=AccumulateGrad]
	1460823196480 -> 1460823195856
	1463366025680 [label="conv_blocks.0.bias
 (512)" fillcolor=lightblue]
	1463366025680 -> 1460823196480
	1460823196480 [label=AccumulateGrad]
	1460823197920 -> 1460823195760
	1463366025520 [label="conv_blocks.2.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	1463366025520 -> 1460823197920
	1460823197920 [label=AccumulateGrad]
	1460823197872 -> 1460823195760
	1463366026160 [label="conv_blocks.2.bias
 (256)" fillcolor=lightblue]
	1463366026160 -> 1460823197872
	1460823197872 [label=AccumulateGrad]
	1460823197776 -> 1460823197536
	1463366026880 [label="conv_blocks.3.weight
 (256)" fillcolor=lightblue]
	1463366026880 -> 1460823197776
	1460823197776 [label=AccumulateGrad]
	1460823196672 -> 1460823197536
	1463366025840 [label="conv_blocks.3.bias
 (256)" fillcolor=lightblue]
	1463366025840 -> 1460823196672
	1460823196672 [label=AccumulateGrad]
	1460823155616 -> 1460823157296
	1463366026640 [label="conv_blocks.6.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	1463366026640 -> 1460823155616
	1460823155616 [label=AccumulateGrad]
	1460823155472 -> 1460823157296
	1463366026320 [label="conv_blocks.6.bias
 (128)" fillcolor=lightblue]
	1463366026320 -> 1460823155472
	1460823155472 [label=AccumulateGrad]
	1460823157200 -> 1460823157056
	1463366026080 [label="conv_blocks.7.weight
 (128)" fillcolor=lightblue]
	1463366026080 -> 1460823157200
	1460823157200 [label=AccumulateGrad]
	1460823157104 -> 1460823157056
	1463366025920 [label="conv_blocks.7.bias
 (128)" fillcolor=lightblue]
	1463366025920 -> 1460823157104
	1460823157104 [label=AccumulateGrad]
	1460823155040 -> 1460823156480
	1463366016352 [label="conv_blocks.10.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	1463366016352 -> 1460823155040
	1460823155040 [label=AccumulateGrad]
	1460823156768 -> 1460823156480
	1463366014512 [label="conv_blocks.10.bias
 (64)" fillcolor=lightblue]
	1463366014512 -> 1460823156768
	1460823156768 [label=AccumulateGrad]
	1460823155136 -> 1460823156384
	1463366013712 [label="conv_blocks.11.weight
 (64)" fillcolor=lightblue]
	1463366013712 -> 1460823155136
	1460823155136 [label=AccumulateGrad]
	1460823156960 -> 1460823156384
	1463366016672 [label="conv_blocks.11.bias
 (64)" fillcolor=lightblue]
	1463366016672 -> 1460823156960
	1460823156960 [label=AccumulateGrad]
	1460823156816 -> 1460282175648
	1463366013072 [label="conv_blocks.14.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	1463366013072 -> 1460823156816
	1460823156816 [label=AccumulateGrad]
	1460823156432 -> 1460282175648
	1463366013312 [label="conv_blocks.14.bias
 (32)" fillcolor=lightblue]
	1463366013312 -> 1460823156432
	1460823156432 [label=AccumulateGrad]
	1460098692720 -> 1460098692384
	1463366014112 [label="conv_blocks.15.weight
 (32)" fillcolor=lightblue]
	1463366014112 -> 1460098692720
	1460098692720 [label=AccumulateGrad]
	1460098692864 -> 1460098692384
	1463366014672 [label="conv_blocks.15.bias
 (32)" fillcolor=lightblue]
	1463366014672 -> 1460098692864
	1460098692864 [label=AccumulateGrad]
	1463360312224 -> 1463360469648
	1463366013872 [label="conv_blocks.18.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	1463366013872 -> 1463360312224
	1463360312224 [label=AccumulateGrad]
	1460080101984 -> 1463360469648
	1463366013152 [label="conv_blocks.18.bias
 (16)" fillcolor=lightblue]
	1463366013152 -> 1460080101984
	1460080101984 [label=AccumulateGrad]
	1463360469168 -> 1463360377232
	1463366013392 [label="conv_blocks.19.weight
 (16)" fillcolor=lightblue]
	1463366013392 -> 1463360469168
	1463360469168 [label=AccumulateGrad]
	1463360379344 -> 1463360377232
	1463366014192 [label="conv_blocks.19.bias
 (16)" fillcolor=lightblue]
	1463366014192 -> 1463360379344
	1463360379344 [label=AccumulateGrad]
	1463360422432 -> 1460098179568
	1463365965120 [label="conv_blocks.21.weight
 (3, 16, 3, 3)" fillcolor=lightblue]
	1463365965120 -> 1463360422432
	1463360422432 [label=AccumulateGrad]
	1463360425792 -> 1460098179568
	1463365965680 [label="conv_blocks.21.bias
 (3)" fillcolor=lightblue]
	1463365965680 -> 1463360425792
	1463360425792 [label=AccumulateGrad]
	1460821767840 -> 1463365892432
}
