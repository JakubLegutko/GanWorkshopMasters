digraph {
	graph [size="27.15,27.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2073892859968 [label="
 (1, 3, 1024, 1024)" fillcolor=darkolivegreen1]
	2081337611696 [label=TanhBackward0]
	2081337610688 -> 2081337611696
	2081337610688 [label=ConvolutionBackward0]
	2081337612224 -> 2081337610688
	2081337612224 [label=ReluBackward0]
	2081337610928 -> 2081337612224
	2081337610928 [label=CudnnBatchNormBackward0]
	2081337611168 -> 2081337610928
	2081337611168 [label=ConvolutionBackward0]
	2081337613904 -> 2081337611168
	2081337613904 [label=UpsampleNearest2DBackward0]
	2081337611408 -> 2081337613904
	2081337611408 [label=ReluBackward0]
	2081337614096 -> 2081337611408
	2081337614096 [label=CudnnBatchNormBackward0]
	2081337613088 -> 2081337614096
	2081337613088 [label=ConvolutionBackward0]
	2081337612320 -> 2081337613088
	2081337612320 [label=UpsampleNearest2DBackward0]
	2081337610880 -> 2081337612320
	2081337610880 [label=ReluBackward0]
	2081337610976 -> 2081337610880
	2081337610976 [label=CudnnBatchNormBackward0]
	2081337610544 -> 2081337610976
	2081337610544 [label=ConvolutionBackward0]
	2081337612512 -> 2081337610544
	2081337612512 [label=UpsampleNearest2DBackward0]
	2081337613040 -> 2081337612512
	2081337613040 [label=ReluBackward0]
	2081337905456 -> 2081337613040
	2081337905456 [label=CudnnBatchNormBackward0]
	2081337906080 -> 2081337905456
	2081337906080 [label=ConvolutionBackward0]
	2081337678528 -> 2081337906080
	2081337678528 [label=UpsampleNearest2DBackward0]
	2081337676128 -> 2081337678528
	2081337676128 [label=ReluBackward0]
	2081337676272 -> 2081337676128
	2081337676272 [label=CudnnBatchNormBackward0]
	2081337677952 -> 2081337676272
	2081337677952 [label=ConvolutionBackward0]
	2081337679152 -> 2081337677952
	2081337679152 [label=UpsampleNearest2DBackward0]
	2081337677712 -> 2081337679152
	2081337677712 [label=ReluBackward0]
	2081337676560 -> 2081337677712
	2081337676560 [label=CudnnBatchNormBackward0]
	2081337679200 -> 2081337676560
	2081337679200 [label=ConvolutionBackward0]
	2081337677328 -> 2081337679200
	2081337677328 [label=UpsampleNearest2DBackward0]
	2081337678336 -> 2081337677328
	2081337678336 [label=CudnnBatchNormBackward0]
	2081337679776 -> 2081337678336
	2081337679776 [label=ViewBackward0]
	2081337678960 -> 2081337679776
	2081337678960 [label=AddmmBackward0]
	2081337678240 -> 2081337678960
	2073270802768 [label="l1.0.bias
 (65536)" fillcolor=lightblue]
	2073270802768 -> 2081337678240
	2081337678240 [label=AccumulateGrad]
	2081337679008 -> 2081337678960
	2081337679008 [label=TBackward0]
	2081337676080 -> 2081337679008
	2081318071488 [label="l1.0.weight
 (65536, 200)" fillcolor=lightblue]
	2081318071488 -> 2081337676080
	2081337676080 [label=AccumulateGrad]
	2081337675840 -> 2081337678336
	2072539151792 [label="conv_blocks.0.weight
 (256)" fillcolor=lightblue]
	2072539151792 -> 2081337675840
	2081337675840 [label=AccumulateGrad]
	2081337677232 -> 2081337678336
	2073266292032 [label="conv_blocks.0.bias
 (256)" fillcolor=lightblue]
	2073266292032 -> 2081337677232
	2081337677232 [label=AccumulateGrad]
	2081337677376 -> 2081337679200
	2073264686320 [label="conv_blocks.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2073264686320 -> 2081337677376
	2081337677376 [label=AccumulateGrad]
	2081337677808 -> 2081337679200
	2072542659344 [label="conv_blocks.2.bias
 (256)" fillcolor=lightblue]
	2072542659344 -> 2081337677808
	2081337677808 [label=AccumulateGrad]
	2081337679104 -> 2081337676560
	2072542648496 [label="conv_blocks.3.weight
 (256)" fillcolor=lightblue]
	2072542648496 -> 2081337679104
	2081337679104 [label=AccumulateGrad]
	2081337678720 -> 2081337676560
	2081337590304 [label="conv_blocks.3.bias
 (256)" fillcolor=lightblue]
	2081337590304 -> 2081337678720
	2081337678720 [label=AccumulateGrad]
	2081337679728 -> 2081337677952
	2081337590624 [label="conv_blocks.6.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2081337590624 -> 2081337679728
	2081337679728 [label=AccumulateGrad]
	2081337677760 -> 2081337677952
	2081337590704 [label="conv_blocks.6.bias
 (256)" fillcolor=lightblue]
	2081337590704 -> 2081337677760
	2081337677760 [label=AccumulateGrad]
	2081337677472 -> 2081337676272
	2081337590784 [label="conv_blocks.7.weight
 (256)" fillcolor=lightblue]
	2081337590784 -> 2081337677472
	2081337677472 [label=AccumulateGrad]
	2081337679536 -> 2081337676272
	2081337590864 [label="conv_blocks.7.bias
 (256)" fillcolor=lightblue]
	2081337590864 -> 2081337679536
	2081337679536 [label=AccumulateGrad]
	2081337678624 -> 2081337906080
	2081337591264 [label="conv_blocks.10.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	2081337591264 -> 2081337678624
	2081337678624 [label=AccumulateGrad]
	2081337678192 -> 2081337906080
	2081337591344 [label="conv_blocks.10.bias
 (128)" fillcolor=lightblue]
	2081337591344 -> 2081337678192
	2081337678192 [label=AccumulateGrad]
	2081337679824 -> 2081337905456
	2081337591424 [label="conv_blocks.11.weight
 (128)" fillcolor=lightblue]
	2081337591424 -> 2081337679824
	2081337679824 [label=AccumulateGrad]
	2081337678576 -> 2081337905456
	2081337591504 [label="conv_blocks.11.bias
 (128)" fillcolor=lightblue]
	2081337591504 -> 2081337678576
	2081337678576 [label=AccumulateGrad]
	2081337612800 -> 2081337610544
	2081337591904 [label="conv_blocks.14.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2081337591904 -> 2081337612800
	2081337612800 [label=AccumulateGrad]
	2081337614240 -> 2081337610544
	2081337591984 [label="conv_blocks.14.bias
 (64)" fillcolor=lightblue]
	2081337591984 -> 2081337614240
	2081337614240 [label=AccumulateGrad]
	2081337611264 -> 2081337610976
	2081337592064 [label="conv_blocks.15.weight
 (64)" fillcolor=lightblue]
	2081337592064 -> 2081337611264
	2081337611264 [label=AccumulateGrad]
	2081337613328 -> 2081337610976
	2081337592144 [label="conv_blocks.15.bias
 (64)" fillcolor=lightblue]
	2081337592144 -> 2081337613328
	2081337613328 [label=AccumulateGrad]
	2081337612032 -> 2081337613088
	2081337592544 [label="conv_blocks.18.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	2081337592544 -> 2081337612032
	2081337612032 [label=AccumulateGrad]
	2081337612080 -> 2081337613088
	2081337592624 [label="conv_blocks.18.bias
 (32)" fillcolor=lightblue]
	2081337592624 -> 2081337612080
	2081337612080 [label=AccumulateGrad]
	2081337611936 -> 2081337614096
	2081337592704 [label="conv_blocks.19.weight
 (32)" fillcolor=lightblue]
	2081337592704 -> 2081337611936
	2081337611936 [label=AccumulateGrad]
	2081337611744 -> 2081337614096
	2081337592784 [label="conv_blocks.19.bias
 (32)" fillcolor=lightblue]
	2081337592784 -> 2081337611744
	2081337611744 [label=AccumulateGrad]
	2081337613856 -> 2081337611168
	2081337593184 [label="conv_blocks.22.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	2081337593184 -> 2081337613856
	2081337613856 [label=AccumulateGrad]
	2081337611552 -> 2081337611168
	2081337593264 [label="conv_blocks.22.bias
 (16)" fillcolor=lightblue]
	2081337593264 -> 2081337611552
	2081337611552 [label=AccumulateGrad]
	2081337610736 -> 2081337610928
	2081337593344 [label="conv_blocks.23.weight
 (16)" fillcolor=lightblue]
	2081337593344 -> 2081337610736
	2081337610736 [label=AccumulateGrad]
	2081337611360 -> 2081337610928
	2081337593424 [label="conv_blocks.23.bias
 (16)" fillcolor=lightblue]
	2081337593424 -> 2081337611360
	2081337611360 [label=AccumulateGrad]
	2081337610496 -> 2081337610688
	2073382768704 [label="conv_blocks.25.weight
 (3, 16, 3, 3)" fillcolor=lightblue]
	2073382768704 -> 2081337610496
	2081337610496 [label=AccumulateGrad]
	2081337614000 -> 2081337610688
	2073382768784 [label="conv_blocks.25.bias
 (3)" fillcolor=lightblue]
	2073382768784 -> 2081337614000
	2081337614000 [label=AccumulateGrad]
	2081337611696 -> 2073892859968
}
