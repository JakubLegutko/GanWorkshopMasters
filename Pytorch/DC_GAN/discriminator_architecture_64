digraph {
	graph [size="14.25,14.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2541971246592 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	2542028754320 [label=SigmoidBackward0]
	2542028754272 -> 2542028754320
	2542028754272 [label=AddmmBackward0]
	2542044159088 -> 2542028754272
	2542041894720 [label="model.12.bias
 (1)" fillcolor=lightblue]
	2542041894720 -> 2542044159088
	2542044159088 [label=AccumulateGrad]
	2542044158944 -> 2542028754272
	2542044158944 [label=ViewBackward0]
	2536154515728 -> 2542044158944
	2536154515728 [label=LeakyReluBackward1]
	2536154516592 -> 2536154515728
	2536154516592 [label=CudnnBatchNormBackward0]
	2536154516064 -> 2536154516592
	2536154516064 [label=ConvolutionBackward0]
	2536154514912 -> 2536154516064
	2536154514912 [label=LeakyReluBackward1]
	2536154515008 -> 2536154514912
	2536154515008 [label=CudnnBatchNormBackward0]
	2536154515968 -> 2536154515008
	2536154515968 [label=ConvolutionBackward0]
	2536154515248 -> 2536154515968
	2536154515248 [label=LeakyReluBackward1]
	2536154516640 -> 2536154515248
	2536154516640 [label=CudnnBatchNormBackward0]
	2536154515920 -> 2536154516640
	2536154515920 [label=ConvolutionBackward0]
	2536154515824 -> 2536154515920
	2536154515824 [label=LeakyReluBackward1]
	2536154514576 -> 2536154515824
	2536154514576 [label=ConvolutionBackward0]
	2536154513664 -> 2536154514576
	2542044183744 [label="model.0.weight
 (64, 3, 4, 4)" fillcolor=lightblue]
	2542044183744 -> 2536154513664
	2536154513664 [label=AccumulateGrad]
	2536154514336 -> 2536154514576
	2542044183664 [label="model.0.bias
 (64)" fillcolor=lightblue]
	2542044183664 -> 2536154514336
	2536154514336 [label=AccumulateGrad]
	2536154514288 -> 2536154515920
	2542044183024 [label="model.2.weight
 (128, 64, 4, 4)" fillcolor=lightblue]
	2542044183024 -> 2536154514288
	2536154514288 [label=AccumulateGrad]
	2536154515632 -> 2536154515920
	2542044181504 [label="model.2.bias
 (128)" fillcolor=lightblue]
	2542044181504 -> 2536154515632
	2536154515632 [label=AccumulateGrad]
	2536154516496 -> 2536154516640
	2542044181584 [label="model.3.weight
 (128)" fillcolor=lightblue]
	2542044181584 -> 2536154516496
	2536154516496 [label=AccumulateGrad]
	2536154516976 -> 2536154516640
	2542044181104 [label="model.3.bias
 (128)" fillcolor=lightblue]
	2542044181104 -> 2536154516976
	2536154516976 [label=AccumulateGrad]
	2536154516448 -> 2536154515968
	2542044183904 [label="model.5.weight
 (256, 128, 4, 4)" fillcolor=lightblue]
	2542044183904 -> 2536154516448
	2536154516448 [label=AccumulateGrad]
	2536154517072 -> 2536154515968
	2542044182384 [label="model.5.bias
 (256)" fillcolor=lightblue]
	2542044182384 -> 2536154517072
	2536154517072 [label=AccumulateGrad]
	2536154514384 -> 2536154515008
	2542044182624 [label="model.6.weight
 (256)" fillcolor=lightblue]
	2542044182624 -> 2536154514384
	2536154514384 [label=AccumulateGrad]
	2536154513808 -> 2536154515008
	2542044182544 [label="model.6.bias
 (256)" fillcolor=lightblue]
	2542044182544 -> 2536154513808
	2536154513808 [label=AccumulateGrad]
	2536154514960 -> 2536154516064
	2542041894240 [label="model.8.weight
 (512, 256, 4, 4)" fillcolor=lightblue]
	2542041894240 -> 2536154514960
	2536154514960 [label=AccumulateGrad]
	2536154516832 -> 2536154516064
	2542041894080 [label="model.8.bias
 (512)" fillcolor=lightblue]
	2542041894080 -> 2536154516832
	2536154516832 [label=AccumulateGrad]
	2536154515872 -> 2536154516592
	2542041892080 [label="model.9.weight
 (512)" fillcolor=lightblue]
	2542041892080 -> 2536154515872
	2536154515872 [label=AccumulateGrad]
	2536154514768 -> 2536154516592
	2542041892800 [label="model.9.bias
 (512)" fillcolor=lightblue]
	2542041892800 -> 2536154514768
	2536154514768 [label=AccumulateGrad]
	2542044157120 -> 2542028754272
	2542044157120 [label=TBackward0]
	2536154516304 -> 2542044157120
	2542041894560 [label="model.12.weight
 (1, 8192)" fillcolor=lightblue]
	2542041894560 -> 2536154516304
	2536154516304 [label=AccumulateGrad]
	2542028754320 -> 2541971246592
}
