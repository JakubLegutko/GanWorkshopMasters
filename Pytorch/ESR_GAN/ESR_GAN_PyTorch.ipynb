{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1809.00219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Super-resolution of CelebA using Generative Adversarial Networks.\n",
    "The dataset can be downloaded from: https://www.dropbox.com/sh/8oqt9vytwxb3s4r/AADIKlz8PR9zr6Y20qbkunrba/Img/img_align_celeba.zip?dl=0\n",
    "(if not available there see if options are listed at http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n",
    "Instrustion on running the script:\n",
    "1. Download the dataset from the provided link\n",
    "2. Save the folder 'img_align_celeba' to '../../data/'\n",
    "4. Run the sript using command 'python3 esrgan.py'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models import *\n",
    "from datasets import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "os.makedirs(\"images/training\", exist_ok=True)\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Create Args class, fill with default values instead of using parser\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.n_epochs = 200\n",
    "        self.dataset_name = \"img_align_celeba\"\n",
    "        self.batch_size = 4\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.decay_epoch = 100\n",
    "        self.n_cpu = 8\n",
    "        self.hr_height = 256\n",
    "        self.hr_width = 256\n",
    "        self.channels = 3\n",
    "        self.sample_interval = 100\n",
    "        self.checkpoint_interval = 5000\n",
    "        self.residual_blocks = 23\n",
    "        self.warmup_batches = 500\n",
    "        self.lambda_adv = 5e-3\n",
    "        self.lambda_pixel = 1e-2\n",
    "opt = Args()\n",
    "print(opt)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hr_shape = (opt.hr_height, opt.hr_width)\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = GeneratorRRDB(opt.channels, filters=64, num_res_blocks=opt.residual_blocks).to(device)\n",
    "discriminator = Discriminator(input_shape=(opt.channels, *hr_shape)).to(device)\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "\n",
    "# Set feature extractor to inference mode\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "criterion_content = torch.nn.L1Loss().to(device)\n",
    "criterion_pixel = torch.nn.L1Loss().to(device)\n",
    "\n",
    "if opt.epoch != 0:\n",
    "    # Load pretrained models\n",
    "    generator.load_state_dict(torch.load(\"saved_models/generator_%d.pth\" % opt.epoch))\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/discriminator_%d.pth\" % opt.epoch))\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(\"../../data/%s\" % opt.dataset_name, hr_shape=hr_shape),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu,\n",
    ")\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(opt.epoch, opt.n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "\n",
    "        # Configure model input\n",
    "        imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
    "        imgs_hr = Variable(imgs[\"hr\"].type(Tensor))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a high resolution image from low resolution input\n",
    "        gen_hr = generator(imgs_lr)\n",
    "\n",
    "        # Measure pixel-wise loss against ground truth\n",
    "        loss_pixel = criterion_pixel(gen_hr, imgs_hr)\n",
    "\n",
    "        if batches_done < opt.warmup_batches:\n",
    "            # Warm-up (pixel-wise loss only)\n",
    "            loss_pixel.backward()\n",
    "            optimizer_G.step()\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [G pixel: %f]\"\n",
    "                % (epoch, opt.n_epochs, i, len(dataloader), loss_pixel.item())\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Extract validity predictions from discriminator\n",
    "        pred_real = discriminator(imgs_hr).detach()\n",
    "        pred_fake = discriminator(gen_hr)\n",
    "\n",
    "        # Adversarial loss (relativistic average GAN)\n",
    "        loss_GAN = criterion_GAN(pred_fake - pred_real.mean(0, keepdim=True), valid)\n",
    "\n",
    "        # Content loss\n",
    "        gen_features = feature_extractor(gen_hr)\n",
    "        real_features = feature_extractor(imgs_hr).detach()\n",
    "        loss_content = criterion_content(gen_features, real_features)\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_G = loss_content + opt.lambda_adv * loss_GAN + opt.lambda_pixel * loss_pixel\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        pred_real = discriminator(imgs_hr)\n",
    "        pred_fake = discriminator(gen_hr.detach())\n",
    "\n",
    "        # Adversarial loss for real and fake images (relativistic average GAN)\n",
    "        loss_real = criterion_GAN(pred_real - pred_fake.mean(0, keepdim=True), valid)\n",
    "        loss_fake = criterion_GAN(pred_fake - pred_real.mean(0, keepdim=True), fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, content: %f, adv: %f, pixel: %f]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                opt.n_epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G.item(),\n",
    "                loss_content.item(),\n",
    "                loss_GAN.item(),\n",
    "                loss_pixel.item(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            # Save image grid with upsampled inputs and ESRGAN outputs\n",
    "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "            img_grid = denormalize(torch.cat((imgs_lr, gen_hr), -1))\n",
    "            save_image(img_grid, \"images/training/%d.png\" % batches_done, nrow=1, normalize=False)\n",
    "\n",
    "        if batches_done % opt.checkpoint_interval == 0:\n",
    "            # Save model checkpoints\n",
    "            torch.save(generator.state_dict(), \"saved_models/generator_%d.pth\" % epoch)\n",
    "            torch.save(discriminator.state_dict(), \"saved_models/discriminator_%d.pth\" %epoch)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
